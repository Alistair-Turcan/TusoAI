{
    "2": {
        "0": [
            {
                "code": "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass SphericalRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(SphericalRNN, self).__init__()\n        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1, 3 * 60 * 60)\n        out, _ = self.rnn(x)\n        out = self.fc(out[:, -1, :])\n        return out\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.int64).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = SphericalRNN(input_size=3 * 60 * 60, hidden_size=128, num_classes=len(np.unique(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, val_preds = torch.max(val_outputs, 1)\n\n    return val_preds.cpu().numpy().tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8292_recurrent_neural_net.py",
                "accuracy": 0.0326,
                "model_info": "",
                "lineage": "spherical_initial_8292_recurrent_neural_net"
            }
        ],
        "1": [
            {
                "code": "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass SphericalRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(SphericalRNN, self).__init__()\n        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_size * 2, num_classes)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1, 3 * 60 * 60)\n        out, _ = self.rnn(x)\n        out = self.fc(out[:, -1, :])\n        return out\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.int64).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = SphericalRNN(input_size=3 * 60 * 60, hidden_size=128, num_classes=len(np.unique(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    print(f'Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, val_preds = torch.max(val_outputs, 1)\n\n    return val_preds.cpu().numpy().tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8292_recurrent_neural_netXX.py",
                "accuracy": 0.0462,
                "model_info": "Trainable parameters: 8419940",
                "lineage": "121"
            }
        ],
        "2": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(pretrained=True)\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    print(f'Validation Predictions: {val_preds.tolist()}')\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXX.py",
                "accuracy": 0.2602,
                "model_info": "Epoch: 0, Loss: 4.689888954162598\nEpoch: 0, Loss: 4.687612533569336\nEpoch: 0, Loss: 4.657149791717529\nEpoch: 0, Loss: 4.634641647338867\nEpoch: 0, Loss: 4.611736297607422\nEpoch: 0, Loss: 4.588863849639893\nEpoch: 0, Loss: 4.562797546386719\nEpoch: 0, Loss: 4.537940502166748\nEpoch: 0, Loss: 4.477558135986328\nEpoch: 0, Loss: 4.482773780822754\nEpoch: 0, Loss: 4.443801403045654\nEpoch: 0, Loss: 4.437946796417236\nEpoch: 0, Loss: 4.376118183135986\nEpoch: 0, Loss: 4.379123210906982\nEpoch: 0, Loss: 4.385481834411621\nEpoch: 0, Loss: 4.289950370788574\nEpoch: 0, Loss: 4.345996379852295\nEpoch: 0, Loss: 4.259845733642578\nEpoch: 0, Loss: 4.22699499130249\nEpoch: 0, Loss: 4.20697546005249\nEpoch: 0, Loss: 4.187171936035156\nEpoch: 0, Loss: 4.190734386444092\nEpoch: 0, Loss: 4.195841312408447\nEpoch: 0, Loss: 4.154918193817139\nEpoch: 0, Loss: 4.1224236488342285\nEpoch: 0, Loss: 4.068457126617432\nEpoch: 0, Loss: 4.063746929168701\nEpoch: 0, Loss: 4.0283002853393555\nEpoch: 0, Loss: 3.9984445571899414\nEpoch: 0, Loss: 3.963829517364502\nEpoch: 0, Loss: 3.9438295364379883\nEpoch: 0, Loss: 3.92451810836792\nEpoch: 0, Loss: 3.868098497390747\nEpoch: 0, Loss: 3.8540422916412354\nEpoch: 0, Loss: 3.8808023929595947\nEpoch: 0, Loss: 3.893817901611328\nEpoch: 0, Loss: 3.8172333240509033\nEpoch: 0, Loss: 3.8005387783050537\nEpoch: 0, Loss: 3.7141013145446777\nEpoch: 0, Loss: 3.8263816833496094\nEpoch: 1, Loss: 3.5893139839172363\nEpoch: 1, Loss: 3.504274606704712\nEpoch: 1, Loss: 3.4267895221710205\nEpoch: 1, Loss: 3.5394182205200195\nEpoch: 1, Loss: 3.4551424980163574\nEpoch: 1, Loss: 3.50142765045166\nEpoch: 1, Loss: 3.44101619720459\nEpoch: 1, Loss: 3.3821423053741455\nEpoch: 1, Loss: 3.475639581680298\nEpoch: 1, Loss: 3.333574056625366\nEpoch: 1, Loss: 3.388227939605713\nEpoch: 1, Loss: 3.3293421268463135\nEpoch: 1, Loss: 3.3076791763305664\nEpoch: 1, Loss: 3.320298433303833\nEpoch: 1, Loss: 3.2657411098480225\nEpoch: 1, Loss: 3.2828123569488525\nEpoch: 1, Loss: 3.2045929431915283\nEpoch: 1, Loss: 3.2839736938476562\nEpoch: 1, Lo",
                "lineage": "221"
            }
        ]
    },
    "3": {
        "0": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass GNNModel(nn.Module):\n    def __init__(self, num_classes):\n        super(GNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(32 * 15 * 15, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n        self.pool = nn.MaxPool2d(2)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    model = GNNModel(num_classes=len(np.unique(train_label))).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss()\n    \n    train_dataset = TensorDataset(torch.tensor(train_data, dtype=torch.float32).to(device), torch.tensor(train_label, dtype=torch.long).to(device))\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    for epoch in range(10):\n        model.train()\n        for batch in train_loader:\n            optimizer.zero_grad()\n            output = model(batch[0])\n            loss = criterion(output, batch[1])\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    val_preds = []\n    with torch.no_grad():\n        for data in val_data:\n            data_tensor = torch.tensor(data, dtype=torch.float32).to(device).unsqueeze(0)\n            output = model(data_tensor)\n            val_preds.append(torch.argmax(output, dim=1).item())\n\n    return val_preds",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8293_graph_neural_network.py",
                "accuracy": 0.0797,
                "model_info": "",
                "lineage": "spherical_initial_8293_graph_neural_network"
            }
        ],
        "1": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass GNNModel(nn.Module):\n    def __init__(self, num_classes):\n        super(GNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n        self.pool = nn.MaxPool2d(2)\n        self.attention = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        attention_weights = self.attention(x)\n        x = x * attention_weights\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    model = GNNModel(num_classes=len(np.unique(train_label))).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss()\n    \n    train_dataset = TensorDataset(torch.tensor(train_data, dtype=torch.float32).to(device), torch.tensor(train_label, dtype=torch.long).to(device))\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    for epoch in range(10):\n        model.train()\n        for batch in train_loader:\n            optimizer.zero_grad()\n            output = model(batch[0])\n            loss = criterion(output, batch[1])\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    val_preds = []\n    with torch.no_grad():\n        for data in val_data:\n            data_tensor = torch.tensor(data, dtype=torch.float32).to(device).unsqueeze(0)\n            output = model(data_tensor)\n            val_preds.append(torch.argmax(output, dim=1).item())\n\n    return val_preds",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8293_graph_neural_networkX.py",
                "accuracy": 0.0602,
                "model_info": "",
                "lineage": "131"
            }
        ]
    },
    "4": {
        "0": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(pretrained=True)\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_mo.py",
                "accuracy": 0.2649,
                "model_info": "",
                "lineage": "spherical_initial_8294_transformer_based_mo"
            }
        ],
        "1": []
    },
    "0": {
        "2": [],
        "3": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moX.py",
                "accuracy": 0.262,
                "model_info": "",
                "lineage": "301"
            }
        ],
        "4": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    transform = transforms.Compose([\n        transforms.Lambda(lambda x: x.permute(0, 2, 3, 1)),\n        transforms.RandomPerspective(distortion_scale=0.5, p=1.0),\n        transforms.Lambda(lambda x: x.permute(0, 3, 1, 2)),\n    ])\n\n    model = resnet50(pretrained=True)\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = transform(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moX.py",
                "accuracy": 0.1949,
                "model_info": "",
                "lineage": "401"
            }
        ],
        "5": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\nclass SphericalResNet(nn.Module):\n    def __init__(self, num_classes):\n        super(SphericalResNet, self).__init__()\n        self.base_model = resnet50(pretrained=True)\n        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, num_classes)\n\n    def forward(self, x):\n        x = self.base_model(x)\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = SphericalResNet(num_classes=len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moX.py",
                "accuracy": 0.2628,
                "model_info": "",
                "lineage": "501"
            }
        ],
        "6": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moX.py",
                "accuracy": 0.1118,
                "model_info": "",
                "lineage": "601"
            }
        ],
        "7": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moX.py",
                "accuracy": 0.274,
                "model_info": "",
                "lineage": "701"
            }
        ],
        "8": [],
        "9": [],
        "10": [],
        "11": [],
        "12": [],
        "13": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXX.py",
                "accuracy": 0.2796,
                "model_info": "Top-k feature importances: [[ 820  648 1811 1087 1317]\n [ 816  768  370  163 1337]\n [ 162 1971 1224 1265  989]\n [ 594  196   56  501  514]\n [1875 1444  992 1776 1161]\n [1620 1028 1841  461  774]\n [ 295 1267  376  193 1341]\n [1509  409 1674 2030 1069]\n [1641  154 1593 1525 1772]\n [ 392 1555 1479   80  277]\n [1807  243 1063  550  507]\n [1705  747 1256  497  528]\n [1559 1293  468   92 1032]\n [1753  838  806  269  977]\n [1766  486  504 2046  118]\n [ 959 1147 1120   12 1570]\n [1844  124 2015 1374  206]\n [1784 1468  431   68  730]\n [ 386  284   78 1012 1749]\n [1754 1808 1797 1375 1244]\n [1137  908 1172   26 1713]\n [1142 1657  520 1422 1053]\n [1032 1202 1477 1970 1838]\n [ 948 1974  196 1061  538]\n [ 213 1759  890 1445 1164]\n [ 133 1785 1210  761 1360]\n [1683  651 1819  533 1274]\n [ 584   23  346 1802 1585]\n [ 649  201  770  834  544]\n [1371 1872  169  225   47]\n [ 840 1843 1027 1666  377]\n [ 167  794  804 1786 1656]\n [1167 1149 1621  697  674]\n [ 473  164 2031 1885 1469]\n [ 383 1601 1157  197  116]\n [ 503  896  156   26  575]\n [ 224  358  652 1956  128]\n [ 977 1754 1624  875 1520]\n [1067 1708  594 1380 1821]\n [ 962  717 1636 1777  464]\n [ 799 1151  239  264  935]\n [1500 1612  101  642 1414]\n [ 899 2028 1881  323 1752]\n [1687  307  593 1394 1729]\n [1315 1813   14   59  241]\n [ 869  331 1714 1686 1274]\n [ 402 1679  142   47 1058]\n [ 653 1261 1299  679  688]\n [1930  685  143 1318  922]\n [1980 1516  405 1461  939]\n [1051  618  879   17 1631]\n [1088  970 1298  386   48]\n [ 257 1373  948 1309  565]\n [1861 1427  674  997 1292]\n [ 173  558  315  666 1633]\n [ 981 1508  944  988  486]\n [1503 1287 1221 1060  688]\n [ 753  277 1119 1147 1021]\n [ 968 1353  956 1133 1741]\n [ 668  473 1845  788   72]\n [1961  939 1397  388  956]\n [1816 1455  835   74 1790]\n [1702 1807 1225  755 1673]\n [1117  610  520  353  933]\n [1567   34  296 1859  549]\n [ 192  941  417 2009 1496]\n [1078  177 1087  759  844]\n [ 981 1508  840  218  677]\n [1016  121 1133  713  149]\n [ 726 1703 1975 1284  425]\n [ 890 1898 1",
                "lineage": "1301"
            }
        ],
        "14": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1.0, gamma=2.0):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n        return F_loss.mean()\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = FocalLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXX.py",
                "accuracy": 0.2726,
                "model_info": "Top-k feature importances: [[ 820  648 1317 1283 1811]\n [ 816  768  370  163  463]\n [ 162 1971 1224  147  822]\n [ 594  501  514  196 1128]\n [1444 1875 1776  992 1887]\n [1620  461 1028 1841  774]\n [ 295  193  376 1267 1341]\n [1509  409 1674 1795 1009]\n [1641  154 1593 1525 1044]\n [ 392 1555   80  667  187]\n [1807  243 1063  539  237]\n [ 497  747 1705 1256  528]\n [1559 1293  468 1032 1287]\n [1753  806  838  269  977]\n [1766  118 2046  486  504]\n [ 959   12 1147 1120 1821]\n [1844  124 2015  206 1559]\n [1784 1468  431   68  730]\n [ 386  284 1749   78 1812]\n [1754 1797 1375 1808   56]\n [1713 1137   26   28  541]\n [1657 1454 1422 1142 1053]\n [1838 1032 1202 1477  356]\n [1974  948 1442  196  538]\n [ 213 1445 1759  890 1164]\n [1785 1210 1591  761  133]\n [ 651  533 1683 1819 1274]\n [ 584  346 1585 1181 1802]\n [ 649  201  770  834 1551]\n [1371 1872  169   47 1091]\n [ 840 1027 1843 1666  377]\n [ 167 1786  794 1656 1926]\n [1149  697  674  321 1167]\n [ 473 2031  164 1469  839]\n [ 383 1157  116  288  197]\n [ 503  896  156   26 1224]\n [ 224  358  128  593  652]\n [ 977  875 1624 1078  363]\n [2017 1708  594 1067 1380]\n [ 717  962 1636 1770 1597]\n [ 799 1151  935 1130  239]\n [1500 1612  101 1509  530]\n [ 899  323  975 2028 1752]\n [ 307  593 1729 1017  125]\n [1315   59 1813  241   14]\n [ 869  331 1686  954 1891]\n [ 142 1679  402   47 1058]\n [1261  653  679 1882  688]\n [1930  685  143  922 1318]\n [1516  405 1461  939 1980]\n [ 879  618 1051  934 1219]\n [1088  970  386 1298   48]\n [1373  257 1309  948  688]\n [1861 1427  997  674  387]\n [ 315  173  558  666 1568]\n [ 981 1508  944  486  988]\n [1503 1221 1287 1060  565]\n [ 753  277 1055 1147 1119]\n [ 968 1133  696  956 1353]\n [ 668  473 1845 1322 1565]\n [1961  939 1316 1397 1806]\n [ 835 1455 1790 1844 1816]\n [1702 1225 1807 1673  755]\n [1117  610  520 1509  353]\n [1567   34  296 1859  549]\n [ 192 2009  417  941  381]\n [1078  177  759 1087 1300]\n [ 981  840 1508 1436  218]\n [ 121 1133 1016  713  388]\n [ 726 1703 1975 1284  425]\n [1898  890 1",
                "lineage": "1401"
            }
        ],
        "15": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    print(\"Assumptions related to feature distributions: Normalized spherical images, consistent lighting conditions expected.\")\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXX.py",
                "accuracy": 0.2631,
                "model_info": "Top-k feature importances: [[ 820 1087  648   65 1811]\n [ 816  768  370  755 1337]\n [ 162  142  147 1340 1534]\n [ 594   56  196 1627  999]\n [1875 1776 1444  626 1887]\n [1620 1841 1439  230 1028]\n [ 295  376 1341 1267  193]\n [1509  409  546 1199 1674]\n [1641 1593 1525  154 1390]\n [ 392 1210   80 2004 1555]\n [1807  243 1063 1915  507]\n [1705  497 1218 1256  747]\n [1293 1559  468 1032  736]\n [1753  838  269  806  977]\n [ 118  888 1623 1766  504]\n [ 959 1883 1120   12 1821]\n [ 124 2015  206 1844 1531]\n [1784  730   68  431  166]\n [ 386  284 1749   78  918]\n [1754 1808 1375  696 1797]\n [  26 1889 1137  274   28]\n [ 520  395 1341 1142 1053]\n [ 189 1477 1032 1970  789]\n [ 948 1974 1061 1442  196]\n [ 213  890 1759  642 1635]\n [ 133 1785 1591  283 1494]\n [1683  651  533 1740 1819]\n [ 584  626 1802  346  924]\n [ 649  201 1551  733  544]\n [1371  169  225 1872 1935]\n [ 840 1666 1027 1843  405]\n [ 167 1977    8 1548  794]\n [1149  697  674  937 1931]\n [ 473  164 2031 1885  839]\n [ 383  116  412 1157  288]\n [  26  896  156  503  733]\n [ 224 1956  425  128  652]\n [1350 1078  363  328  875]\n [1708 1067  594 1689 2017]\n [ 962 1636  717 1777 1420]\n [ 799 1803 1284 1128  239]\n [1500 1612 1339 1509 1965]\n [ 899 1744  323 1881  975]\n [1017  756 1394  630  593]\n [1315 1872 1813  241  846]\n [ 869 1686 1714  954 1260]\n [ 402 1579  142 1679 1306]\n [ 653 1261  819  208  286]\n [ 450  685 1103 1318 1930]\n [ 939  405 1516 1461 1647]\n [ 618 1051 1182 1631  401]\n [1088  970 1298   48    2]\n [1373 1309  518  257  688]\n [ 997 1861  656  674  387]\n [ 173  315  558  666  508]\n [ 486  981  944  559 1124]\n [1503 1060 1287  668  565]\n [ 753 1119 1021 1147 1055]\n [1311  968 1353 1133 1741]\n [ 668 1845  473 1593 1765]\n [1806 1961  939 1316  956]\n [ 189  426  906 1934 1455]\n [1225 1702 1673  530 1807]\n [1117  610 1509   42  353]\n [1567  549   34  296 1622]\n [ 192 2009  941 1859  224]\n [ 177 1721  353 1078  759]\n [ 981  840 1508  560  263]\n [ 121 1016 1133  388  149]\n [ 726 1975 1703 1284  574]\n [1302  890  ",
                "lineage": "1501"
            }
        ],
        "16": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    noise_augmentation = transforms.Compose([\n        transforms.Lambda(lambda x: x + 0.1 * torch.randn_like(x)),\n        transforms.Normalize((0.5,), (0.5,))\n    ])\n    \n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = noise_augmentation(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = noise_augmentation(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXX.py",
                "accuracy": 0.0016,
                "model_info": "Top-k feature importances: [[ 400   22 1811  914 1283]\n [ 453  768  816  755 1905]\n [ 274  162 1971 1734  199]\n [ 594 1094  262  501  686]\n [1161  626 1776 1875  862]\n [ 179  461  133 1439 1592]\n [ 295 1486 1337  549  849]\n [1509 2030    6 1807  707]\n [1641 1885  116  433 1865]\n [ 392  681 1132 1424 1555]\n [1807 1201  567  338  243]\n [ 747 1689  866 1256  206]\n [ 904 1677 1919 1196  770]\n [1650 1013  686  244 1948]\n [  20 1766 2046 1714 1147]\n [  12 1570 1784 1173 1787]\n [2015  206  778  901  277]\n [1991  701 1784  299 1900]\n [1281  918 1186   13  284]\n [1165 1754   56  114  626]\n [1883 1359 1889 1734 1632]\n [1657  469 1454  252 1567]\n [1954 1046 1194  856  383]\n [ 572 1617  348  907  538]\n [ 444  890 1164 1417  248]\n [1314 1753  461  516  793]\n [1683 2014 1740  239  165]\n [1751  982  942 1667  552]\n [ 834  733 1389 1529 1431]\n [2014  979 1872 1844  476]\n [ 840  377 1027 1843 1102]\n [ 167 1095 1977  804   76]\n [ 204  697  714 1149  791]\n [1469  164  473 1195  870]\n [1592  116  583 1127  398]\n [ 896   26 1224  508  256]\n [1076  359 1149  128  593]\n [ 701 1624 1503  977 1087]\n [ 594 1380  471 1821 1060]\n [ 717 1409  323 1636 1823]\n [1287  936  264  574 1356]\n [1500 1965 2021 1919  900]\n [ 899  323  169  396  975]\n [1017 1567   26  437 1881]\n [ 538 1003  508 1599   61]\n [1274 1405 1240 1976  954]\n [ 142 1435 2043  859 1679]\n [1697 1261  653  359 1822]\n [ 143 1864  608 1367  540]\n [ 669 1516 1073 1480  939]\n [1351  576 1872  270 1916]\n [1298 1088  537   56 1776]\n [ 565  535 1373 1815  324]\n [1365 1861  997  412 1427]\n [1996 1093 1043  315  623]\n [1508 1418 1518  258  622]\n [1503   16  470  565 1669]\n [ 753  637  900 1923 1427]\n [1898  968  956  346 1045]\n [1261 1765 1565 1747  505]\n [1316  939 1184 1961   32]\n [ 567 1816  752 1724 1606]\n [ 530  755  695  193 1673]\n [ 520  174  412   42 1117]\n [1567 1301 1294 1859 1279]\n [ 941  746  788 1692 1074]\n [ 177 1078 1634  844  759]\n [ 840 1508  742  691 1666]\n [1869 1028 1785   77 1386]\n [ 726  278  625 1533 1975]\n [ 890 1898 1",
                "lineage": "1601"
            }
        ],
        "17": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(20):\n        epoch_loss = 0\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n        print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader)}')\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(20):\n        epoch_loss = 0\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n        print(f'Epoch {epoch+21}, Loss: {epoch_loss/len(train_loader)}')\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXX.py",
                "accuracy": 0.2679,
                "model_info": "Epoch 1, Loss: 4.58534551858902\nEpoch 2, Loss: 4.470007359981537\nEpoch 3, Loss: 4.3738735795021055\nEpoch 4, Loss: 4.291527676582336\nEpoch 5, Loss: 4.217631840705872\nEpoch 6, Loss: 4.149181854724884\nEpoch 7, Loss: 4.07610319852829\nEpoch 8, Loss: 4.023213440179825\nEpoch 9, Loss: 3.971112084388733\nEpoch 10, Loss: 3.928123438358307\nEpoch 11, Loss: 3.8727747738361358\nEpoch 12, Loss: 3.8316405534744264\nEpoch 13, Loss: 3.8088862180709837\nEpoch 14, Loss: 3.7594561636447907\nEpoch 15, Loss: 3.722771221399307\nEpoch 16, Loss: 3.693188172578812\nEpoch 17, Loss: 3.6729653418064117\nEpoch 18, Loss: 3.632574701309204\nEpoch 19, Loss: 3.603979378938675\nEpoch 20, Loss: 3.5779686987400057\nEpoch 21, Loss: 3.1104391872882844\nEpoch 22, Loss: 2.4097355365753175\nEpoch 23, Loss: 1.8804281920194625\nEpoch 24, Loss: 1.4026267111301423\nEpoch 25, Loss: 1.0304158940911292\nEpoch 26, Loss: 0.7376867681741714\nEpoch 27, Loss: 0.4995076574385166\nEpoch 28, Loss: 0.3392224170267582\nEpoch 29, Loss: 0.24053021296858787\nEpoch 30, Loss: 0.17103380300104618\nEpoch 31, Loss: 0.13788040690124034\nEpoch 32, Loss: 0.11645272113382817\nEpoch 33, Loss: 0.08957240106537938\nEpoch 34, Loss: 0.09123813100159169\nEpoch 35, Loss: 0.05582613935694099\nEpoch 36, Loss: 0.05819741189479828\nEpoch 37, Loss: 0.05506763220764697\nEpoch 38, Loss: 0.05681064883247018\nEpoch 39, Loss: 0.04986871718429029\nEpoch 40, Loss: 0.06969417827203869\nTop-k feature importances: [[ 820 1087  648   65 1811]\n [ 816  370  768  755 1337]\n [ 162  147 1340  142 1534]\n [ 594   56  999 1652  196]\n [1875 1444 1776 1708 1332]\n [1620 1841 1439 1028  230]\n [ 295  376 1341 1267  193]\n [1509  409  546 1199 1674]\n [1641 1593 1525  154 1390]\n [ 392   80 1700 1210 1555]\n [ 243 1807 1063  507 1653]\n [1705  497 1256 1218  747]\n [1293 1559  468 1032 1508]\n [1753  838  977  269 1501]\n [ 118  888 1623 1766  504]\n [ 959 1883 1120   12 1821]\n [ 124 1844 2015  206 1531]\n [1784  730   68  431  166]\n [ 284  386 1749   78  298]\n [1754 1808 1375 1797  696]\n [  26   28  274 1172 113",
                "lineage": "1701"
            }
        ],
        "18": [],
        "19": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    domain_specific_transform = transforms.Compose([\n        transforms.RandomRotation(30),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n    ])\n    \n    augmented_train_data = [domain_specific_transform(image) for image in train_tensor]\n    augmented_train_dataset = TensorDataset(torch.stack(augmented_train_data), label_tensor)\n    augmented_train_loader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in augmented_train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXX.py",
                "accuracy": 0.2516,
                "model_info": "Top-k feature importances: [[ 820 1087  580  648 1283]\n [ 816  768  370  616  463]\n [ 162 1534 1971 1557 1224]\n [ 594  514  501  489 1128]\n [1444 1450 1875  992 1776]\n [1620 1028  774 1542 1580]\n [ 295  376 1749 1267  849]\n [ 409 1509 1674 1069 1708]\n [1641  154 1593  784 1665]\n [ 392 1479 1426 1066  667]\n [1807 1063  243  521  229]\n [1705 1256  566 1252  497]\n [1559 1293  736  468  974]\n [1753  838  875  269  806]\n [ 486 1766  118 1744  504]\n [1147  959  430 1570  109]\n [ 124 1374 2015 1844 1028]\n [1784 1468  431  872 1345]\n [ 386  284 1012 1812   78]\n [1808 1754 1375 1797 1244]\n [1172  908   31  541   28]\n [1657 1142   24  520 1422]\n [1032 1202 1477  356 1970]\n [ 948 1974  538  196 1061]\n [ 213 1759 1164 1445  890]\n [1785  133  761 1210 1591]\n [ 651 1819 1445 1683 1274]\n [ 584   23 1642 1585  346]\n [ 649  834  201  770  447]\n [1371 1633  169 1872  225]\n [ 559  840 1843 1725 1600]\n [ 167 1977  804 1786 1656]\n [1167  321  946  674  937]\n [ 473  164 2031 1469 1885]\n [ 383 1157 1072  537 1139]\n [ 503  156   26  896 1908]\n [ 224 1956 1336  358  652]\n [1624 1754 1350  468  875]\n [1821 1380  594 1067 1708]\n [ 962 1636 1777  671  717]\n [ 799  239 1151  264 1130]\n [1500 1612  101  642 1414]\n [ 899 1881 2028  323 1106]\n [ 307 1687  125 1729  593]\n [1315   59 1738 1813 2046]\n [ 869 1260 1882  331 1891]\n [ 402  142 1679  543 2004]\n [ 653 1118 1261 1299  286]\n [1930  685 1103 1318  458]\n [1980 1516  939 1461 1480]\n [1051 1631  454 1417 1173]\n [1088  970 1298   56   48]\n [ 948  257 1309 1373  688]\n [1427 1861 1292  674 1365]\n [ 173  393  558 1568  315]\n [ 981  988  944  486  304]\n [1287 1503 1221  873 1388]\n [ 277  753 1055 1119  637]\n [ 956 1353 1311  968 1778]\n [ 668  788  473 1845 1322]\n [ 956 1397 1961  939 1034]\n [ 835 1816  711 1790 1455]\n [1807 1702 1557  755  848]\n [1117  933  610  593  520]\n [1567   34  549  264 1859]\n [ 192  941 2009  417 1496]\n [1078  177  759 1087  844]\n [ 981 1508  677  840  700]\n [1016  149  121  930  713]\n [ 726 1703  883 1284  574]\n [ 890 1823 1",
                "lineage": "1901"
            }
        ],
        "20": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXX.py",
                "accuracy": 0.2611,
                "model_info": "Epoch 1, Loss: 4.6346659660339355\nEpoch 1, Loss: 4.631038188934326\nEpoch 1, Loss: 4.628809928894043\nEpoch 1, Loss: 4.617737293243408\nEpoch 1, Loss: 4.6361260414123535\nEpoch 1, Loss: 4.621432304382324\nEpoch 1, Loss: 4.612789154052734\nEpoch 1, Loss: 4.628393173217773\nEpoch 1, Loss: 4.615180969238281\nEpoch 1, Loss: 4.600841045379639\nEpoch 1, Loss: 4.6015753746032715\nEpoch 1, Loss: 4.605014324188232\nEpoch 1, Loss: 4.60162353515625\nEpoch 1, Loss: 4.609500408172607\nEpoch 1, Loss: 4.595015525817871\nEpoch 1, Loss: 4.5895466804504395\nEpoch 1, Loss: 4.583890438079834\nEpoch 1, Loss: 4.594191551208496\nEpoch 1, Loss: 4.5739006996154785\nEpoch 1, Loss: 4.593745231628418\nEpoch 1, Loss: 4.5715532302856445\nEpoch 1, Loss: 4.574126243591309\nEpoch 1, Loss: 4.574405670166016\nEpoch 1, Loss: 4.5884881019592285\nEpoch 1, Loss: 4.57478666305542\nEpoch 1, Loss: 4.574486255645752\nEpoch 1, Loss: 4.568758487701416\nEpoch 1, Loss: 4.562605857849121\nEpoch 1, Loss: 4.5653228759765625\nEpoch 1, Loss: 4.562115669250488\nEpoch 1, Loss: 4.560039520263672\nEpoch 1, Loss: 4.557546615600586\nEpoch 1, Loss: 4.56102180480957\nEpoch 1, Loss: 4.534060001373291\nEpoch 1, Loss: 4.542917251586914\nEpoch 1, Loss: 4.548670768737793\nEpoch 1, Loss: 4.526884078979492\nEpoch 1, Loss: 4.5511345863342285\nEpoch 1, Loss: 4.531102180480957\nEpoch 1, Loss: 4.608777046203613\nEpoch 2, Loss: 4.519712448120117\nEpoch 2, Loss: 4.5319013595581055\nEpoch 2, Loss: 4.491556644439697\nEpoch 2, Loss: 4.504249572753906\nEpoch 2, Loss: 4.488431930541992\nEpoch 2, Loss: 4.517702579498291\nEpoch 2, Loss: 4.484431266784668\nEpoch 2, Loss: 4.512794494628906\nEpoch 2, Loss: 4.496256351470947\nEpoch 2, Loss: 4.483736991882324\nEpoch 2, Loss: 4.488465309143066\nEpoch 2, Loss: 4.468440532684326\nEpoch 2, Loss: 4.472959518432617\nEpoch 2, Loss: 4.474058628082275\nEpoch 2, Loss: 4.484529495239258\nEpoch 2, Loss: 4.4905829429626465\nEpoch 2, Loss: 4.45571231842041\nEpoch 2, Loss: 4.481475353240967\nEpoch 2, Loss: 4.478452682495117\nEpoch 2, Loss: 4.478561878204346\nEpoch 2, Loss",
                "lineage": "2001"
            }
        ],
        "21": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXX.py",
                "accuracy": 0.2779,
                "model_info": "",
                "lineage": "2101"
            }
        ],
        "22": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    criterion = nn.CrossEntropyLoss()\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXX.py",
                "accuracy": 0.2803,
                "model_info": "Top-k feature importances: [[ 820  648 1283 1317 1087]\n [ 816  768  370  163 1337]\n [ 162  147 1971 1224 1557]\n [ 594  514  196  501 1094]\n [1875 1444 1776  992 1161]\n [1620 1028 1841  461  774]\n [ 295 1267  376  193 1341]\n [1509  409 1674 1009 2025]\n [1641  154 1593 1525 1772]\n [ 392 1555 1479  277 1066]\n [1807  243 1063  550  539]\n [1705  497  747 1256  528]\n [1559 1293 1032  468 1511]\n [1753  806  838  875  269]\n [ 486 1766 2046  504 1623]\n [ 959 1147   12 1120 1570]\n [ 124 1844 2015 1531 1374]\n [1784 1468  431  166   68]\n [ 386  284 1749   78 1012]\n [1754 1808 1797 1375   56]\n [1137  908  541   28 1713]\n [1657 1053 1454  520 1142]\n [1032 1202 1477 1838  182]\n [ 948 1974  196  538 1442]\n [ 213 1759 1445  890 1164]\n [1785  133 1210  761 1591]\n [1683  651 1819  533 1274]\n [ 584   23  346 1585 1642]\n [ 649  201  544  770  834]\n [1371 1872  169   47  225]\n [ 840 1843 1027  377 1666]\n [ 167 1926  794 1786  804]\n [1149  674 1176  321  697]\n [ 473  164 2031 1885 1469]\n [ 383 1157 1601  116  197]\n [ 503  156  896   26  462]\n [ 224  358  128  652 1956]\n [1754 1624  977  875 1520]\n [1708  594 2017 1067 1380]\n [ 962  717 1636 1777  671]\n [ 799 1151  935  239  264]\n [1500  101 1612  642 1339]\n [ 899  323 1881 2028 1106]\n [ 307 1687 1729 1394  125]\n [1315 1813   14   59  241]\n [ 869  331 1686 1714 1274]\n [ 402  142 1679 1058 1282]\n [1261  653 1299  751  252]\n [1930  685  922  143 1318]\n [1516 1980  939 1461  405]\n [1051  454  879  618  401]\n [1088  970 1298  386   48]\n [ 257  948 1373  565  688]\n [1861 1427  674  997 1292]\n [ 173  558  315 1633  666]\n [ 981  944 1508  486  660]\n [1503 1287 1221  688  565]\n [ 753  277 1147 1119 1055]\n [ 968  956 1353 1311 1741]\n [ 668  473 1845  788   72]\n [1961  939 1397  956 1806]\n [1816  835 1455 1790 1844]\n [1702 1225 1807 1673  755]\n [1117  610  520  353   42]\n [1567   34 1859  296  549]\n [ 192 2009  941  417 1496]\n [1078  177  759 1087  844]\n [1508  981  840  218  677]\n [1016  121  149 1133  713]\n [ 726 1703 1284 1975  425]\n [ 890 1898 1",
                "lineage": "2201"
            }
        ],
        "23": [],
        "24": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXX.py",
                "accuracy": 0.2964,
                "model_info": "Top-k feature importances: [[ 400   22 1811  820 1899]\n [ 816  768  463  370 1326]\n [1557  859  462  162 1971]\n [1094  594  581    5 1239]\n [1161 1875 1444  626 1678]\n [1542  461 1841   51  901]\n [ 295  193 1782  849  376]\n [1509  409 1342  364 1707]\n [1641 2021 1044  154  433]\n [ 161  392 1371  578 1656]\n [ 338  243 1807  312  472]\n [   3  115 1054 1170  528]\n [1293 1919  303 1559  373]\n [ 116  875  977  621  806]\n [ 888   20  546 1766  972]\n [1784 1068  594 2025 1669]\n [2015  776  654  124  206]\n [1784 1991  897  299 1468]\n [ 833 1281   13 1749  284]\n [  56 1797 1754 1094  611]\n [1841  908 1172 1359   28]\n [1454  633   24  520  522]\n [1202  356 1477 1970  789]\n [1974  948  538 1442  131]\n [ 213  890 1635 1759  782]\n [1785 1314  926 1360 1023]\n [ 533 1683  165 1819 1445]\n [1751  626  346 1802 1585]\n [ 649  834  762  303  530]\n [ 740 1629  576 1371 1872]\n [ 377  840 1027  559 1875]\n [ 167 1656    8 1907 1588]\n [1149  204  791 1167  866]\n [ 473  164 2031 1469 1839]\n [1157  465 1127 1438  398]\n [  26  575  503  156  896]\n [ 224 1076 1325  652  142]\n [ 875  977  701 1624 1973]\n [ 594  403  353 1713 1821]\n [1636 1823  971 1420  464]\n [1287  949 1777  322   32]\n [1500  101 1612  642 2021]\n [ 899  323    6 1752 1881]\n [1729  307   74 2031 1017]\n [1003  508 1813  478  471]\n [1714  869 1274 1260 1240]\n [1825  601  859 2043  261]\n [1601 1882 1822  679 1478]\n [1930  922 1318  450  143]\n [1516 1865  732  606 1858]\n [1232  879 1872 1713  454]\n [1088 1298 1059  398  970]\n [1373 1135  518 1590  565]\n [1365 1427 1861  637  387]\n [ 315  558 1043 1995  705]\n [1508  304 1056   43  660]\n [1503  920 1287  565   40]\n [ 753 1119  637 1055  281]\n [ 968  577 1766  497 1311]\n [ 668  505 1373  177   97]\n [ 939 1961 1397 1316 1442]\n [1844  189 1455 1040  567]\n [1673 1225 1702 1152  168]\n [1906  353  520 1117  610]\n [1567  410  547 1909   34]\n [2009 1859  994  381  192]\n [ 759  177  874 1300 1078]\n [ 840 1508 1436  263  981]\n [1869 1028 1133  354   91]\n [ 726 1703 1675 1975  405]\n [ 890 1898 1",
                "lineage": "2401"
            }
        ],
        "25": [],
        "26": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXX.py",
                "accuracy": 0.3239,
                "model_info": "Top-k feature importances: [[1318  348  400  648   10]\n [ 372  163  816  971 1850]\n [ 147 1971 1557  162  179]\n [1094 1120  514 1389  581]\n [1444 1875 1390 1887 1161]\n [1352  461 1643 1955 1580]\n [ 295  823  849 1931 1983]\n [1509  409 1707 1916  364]\n [1695  154 1213  495  433]\n [ 161  925  277   70 1951]\n [1057  338  521 1063 2001]\n [1170  347 1689 1901 2004]\n [1559 1293  940  736   92]\n [ 875  676 1937 1517  269]\n [1940  486 1147  118 1650]\n [1570 1603 1068 1784  895]\n [ 606 1028  389 1559  184]\n [1784 1468  897  299 1991]\n [  42 1519  903  833  284]\n [1094   56 1797 1244 1307]\n [ 983 1841 1137  438  541]\n [ 402  633 1142 1422 1161]\n [1202   39 1032 1596   25]\n [1974  196  852  948 1617]\n [1635 1759 1938 1768  884]\n [ 926   74 1451 1023 1785]\n [1954  654   42   51   94]\n [ 288  582 1667 1751  106]\n [ 447  303  649  124  834]\n [ 979  897 1849 1629 1872]\n [1632 1875  479 1763  506]\n [ 167 1656   76 1095 1926]\n [1149   51 1167  204 1203]\n [1469  473 1990 1579 2031]\n [1438  465 1072 1797  383]\n [ 420  462  256  156  503]\n [ 224  652 1076  882 1017]\n [ 875  599  411  977 1153]\n [ 353  594 1219 1489 1821]\n [  23  671 1792 1380  326]\n [ 687 1609  799 1431 1746]\n [ 454  642  122  101 1398]\n [ 975  899 1388 1199  359]\n [  74 1687  125  307 1789]\n [  61  654  967 1111 1813]\n [1260 1274  846 1480 1714]\n [ 601  261  255 1097 1710]\n [ 803 1822  630  751  674]\n [ 685 1574 1930 1420  922]\n [1525 1222 1028  732 1516]\n [ 454 1513 1872 1910  309]\n [1954  723  110 1088 1572]\n [1952 1135 1630  565 1399]\n [1427  731 1861  412 1365]\n [1579 1981  393 1633 1568]\n [1031 1408  304  660 2039]\n [ 920 1503  534 1221   16]\n [ 900 1147  753 1055  277]\n [1698  968  577 1398   93]\n [ 668 1273  788  473  196]\n [1397  939  787 1042  388]\n [ 835  711 1455  548  749]\n [ 217  695  986 1557 1170]\n [ 952 1117 1787 1390 1047]\n [ 547 1567 1909   34 1665]\n [1692 1579 1214 1315  381]\n [1078  482 1777  353 1110]\n [ 981  218 1508  840  700]\n [1028 1133  746 1213 1907]\n [ 726 1703  643 1675 1975]\n [ 539  890 1",
                "lineage": "2601"
            }
        ],
        "27": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXX.py",
                "accuracy": 0.2648,
                "model_info": "Top-k feature importances: [[ 580  400  348  648 1318]\n [ 163 1850  616  372  362]\n [ 462 1557 1971 1154  622]\n [1094  581  501 1120 1191]\n [1444 1875 1887 1390 1574]\n [1841 1352 1955 1620  461]\n [ 295 1931 1944 1629  823]\n [1509  409  364 1342 1674]\n [ 154 1044    8  495  433]\n [ 161  277 1739 1555  925]\n [1063 1057  338 1807  521]\n [1170  347   21    3  158]\n [1293  940 1559  303 1128]\n [ 269 1517 1937  244  875]\n [1147  438 1759  352 1322]\n [1068 1784 1570 1120  297]\n [ 606  145 1844 1597  124]\n [1784 1468  897  299 1991]\n [  42 1749  784  833  286]\n [  56 1094 1244 1797 1754]\n [ 541 1841  457 1137   31]\n [ 633  207 1454 1142 1422]\n [1202   39 1032  356  567]\n [1974  196 1442 1617  131]\n [1635 1795 1759 1768  213]\n [ 926 1785 1314  784 1192]\n [ 533  654   51  165   94]\n [1751 1553 1181  582 1667]\n [ 649  447  303 1660 1088]\n [1872  979 1371  576  897]\n [1875 1632 1763   59 1843]\n [ 167  804  418 1656 1120]\n [  51  204 1167 1149  272]\n [1469  473  238 1579 2031]\n [1438  465  804  383 1892]\n [ 256  503  156  420  508]\n [ 224 1076  652  882 1998]\n [ 875  977  701 1350 1973]\n [ 403  353 1219  594 2017]\n [  23 1792 1514  717  439]\n [1287  222  936  799  365]\n [ 642  101 1414 1277 1093]\n [ 899  323  975 1388 1752]\n [ 307   74  134  966 1729]\n [ 654 1813  967  957  471]\n [1274 1260  869 1714 1891]\n [ 601  255  261 1679  859]\n [1822  630  803  674 1478]\n [ 685 1657 1501  915  530]\n [ 606  732 1028 1525  669]\n [1872  454 1417  879  561]\n [1088 1636  723 1298   56]\n [1135 1399  565  868  630]\n [1861 1427 1365 1623  387]\n [1633 1568  393 1113 1981]\n [ 304 1408  927 1056 1508]\n [1503  920  815  534 1287]\n [ 753  900 1055 1880  637]\n [ 968 1698  577 1297 1898]\n [ 473  505  668  788 1135]\n [ 939  388 1397 1280 1316]\n [ 711 1790  835 1040 1455]\n [1673  217 1170  695 1702]\n [ 933 1117 1787  952  296]\n [1567  547 1909 1435   34]\n [ 192 2009 1315 1074  381]\n [1078  177  759 1777  844]\n [ 981  218  840 1508  700]\n [1133 1028 1869   91  746]\n [ 726 1703 1975 1675  405]\n [ 539  890 1",
                "lineage": "2701"
            }
        ],
        "28": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXX.py",
                "accuracy": 0.3035,
                "model_info": "Top-k feature importances: [[ 865  400  348 1671   81]\n [ 971  185  362  463  616]\n [ 147  162  585 1557  179]\n [ 514  858 1094 1389 1398]\n [1574  963 1444 1390 1875]\n [1580  511  461 1643 1352]\n [ 295  603  193 1439  823]\n [ 634  829  409 1916 1808]\n [1213 1570 1695 1173  154]\n [1615  925   82  161   70]\n [1057  338 2001 1063  355]\n [1806  160 1689 1367  270]\n [1293   63  303  940  185]\n [ 157  676  710  875 1517]\n [ 486 1363  118 1940 1147]\n [1570  249 1603  892 1123]\n [1028  606 1559 1597 1712]\n [1784 1468 1611 1123 1991]\n [  42  284 1048  833  714]\n [1754 1797 1244 1307 1094]\n [ 983 1841  541  438 1137]\n [ 402 1142  633  557 1341]\n [  39 1202 1032  310 1596]\n [1974  852  760  196  948]\n [1938 1038  716 1795 1759]\n [1451  926 1262   74 1500]\n [1954   94 1245 1994  490]\n [ 993  106 1642 1667  584]\n [ 649 1209  447 2005  834]\n [ 897 1629 1872  979 1633]\n [ 479 1632  633  583 1875]\n [ 847 1656  167 1434 1095]\n [  51 1149  204 1328 1167]\n [1469 1897 1990  361  473]\n [1438 1072  465 1065 1157]\n [1901  420 1039 1224  508]\n [1076  652   12 1626  224]\n [ 411  599 1915  877  875]\n [ 353  594 1219  953   51]\n [1792 1514   23 1777  671]\n [ 932  687  366  220  139]\n [ 642  454  488 1414 1500]\n [ 323  899  975 1581 1388]\n [1687   74  125 1789  500]\n [  61 1368 1111  967  654]\n [1260 1274   19  846  108]\n [ 601  261 1710  123 1426]\n [ 910  803 1258 1601 2021]\n [1574  685  608 1930 1544]\n [1525 1222 1480 1028 1516]\n [ 561  454 1513 1808  587]\n [1572 1954   10  110 1622]\n [1952 1220 1646  948 1135]\n [ 715  731 1623 1427  527]\n [1981 1568  393 1579 1113]\n [1031 1640 1939 2039    2]\n [1221 1503  815 1605 1289]\n [ 900 1055 1147 1459  911]\n [1698 1534  968   93  577]\n [ 923 1276 1217 1273  573]\n [1806 1042  324 1611 1397]\n [ 711  835  548 1816 1455]\n [ 914  848  264   75 1991]\n [1117  296 1562 1390 1047]\n [ 547 1567  814   34 1909]\n [1541  192 1579 2019 1692]\n [ 482 1078 1830 1777 1110]\n [ 981 1738  700  840 1099]\n [ 117 1133 1213   91 1028]\n [ 726 1703  963 1975  643]\n [1604  539  ",
                "lineage": "2801"
            }
        ],
        "29": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = False\n        \n    for param in model.fc.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXX.py",
                "accuracy": 0.2927,
                "model_info": "Top-k feature importances: [[1318  400  348  859  580]\n [ 372  971  163 1390 1326]\n [1557  147  622 1971  162]\n [ 514 1094 1120    5 1389]\n [1390 1444 1875 1161 1574]\n [1352 1643 1620 1955 1841]\n [ 295 1931  823 1439 1944]\n [1509  634 1916  409  364]\n [ 154  135 1695  620 1173]\n [ 161  277  566  839 1656]\n [1057 1063  338 1807 2001]\n [2004 1170 1689  347 1890]\n [1128 1293  940 1559  736]\n [ 269 1517  676  875 1937]\n [1147 1940 1714 1322 1952]\n [1570  895 1669 1120 1068]\n [ 606 1844 1057 1597  792]\n [1784  897 1468  299   68]\n [1345  833 1519  284  286]\n [1094 1797 1754   56 1244]\n [ 541 1137  438 1841  983]\n [1142  402  633 1454   24]\n [1202   39 1032 1596   25]\n [1974  196 1806  538 1442]\n [1635 1759 1795 1038  884]\n [ 926 1023 1785  793 1314]\n [ 654 1954   51 1994 1446]\n [1751 1667  582 1118  440]\n [ 649 1660  303  834  373]\n [ 897  191 1872  979  602]\n [1632 1875 2037 1184 1412]\n [1656 1095  804  167  418]\n [1149   51  204 1203 1167]\n [1469  473 2031 1569 1579]\n [1438  465 1072  398  383]\n [1039  256  503  156  462]\n [ 652 1076  882  224 1413]\n [ 875  977  877  411  748]\n [ 353  594  403  953  471]\n [1792  671  436  962 1514]\n [ 687 1287 1746 1130 1112]\n [ 454 1414  101 1500  642]\n [ 899 1388  323 1199  975]\n [  74  307  586  125  134]\n [  61  654 1111  967 1813]\n [1260 1274  101  846  869]\n [ 261  601  255  859  947]\n [ 803 1822 1601  751  674]\n [ 685 1544 1657  922  915]\n [1525 1222 1563  606 1028]\n [ 454 1631 1872  587  879]\n [1572  723 1059 1137 1954]\n [1135 1646  565  594 1952]\n [1427 1589 1365  731 1861]\n [1981 1633 1579 1568 1113]\n [1031  304 1408 2039  660]\n [ 920 1503   16 2003 1221]\n [ 900 2029 1055  753  692]\n [1698  968 1398   93  577]\n [ 788  668 1142 1845 1261]\n [ 787 1397  939 1042  388]\n [ 548 1844  835 1455  711]\n [ 695 1673 1170 1991 1557]\n [ 952 1117 1827  125 1787]\n [1567   34  547 1909 1665]\n [1579 1725  918 1214 1074]\n [1078 1777 1110  874  844]\n [ 981  218  700  840 1666]\n [1133  117 1213 1028  746]\n [ 726  643 1543 1140 1675]\n [ 539 1924 1",
                "lineage": "2901"
            }
        ],
        "30": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXX.py",
                "accuracy": 0.3303,
                "model_info": "Top-k feature importances: [[ 400  865 1318  648  348]\n [ 372  163 1326  616  816]\n [1557 1971  462  147  162]\n [1120  514 1094  581    5]\n [1444 1875 1390 1161  626]\n [1352  461 1643 1620 1955]\n [ 295 1931  603  193 1629]\n [1509 1916  409  364 1311]\n [1695  433  154 2021 1249]\n [ 161  277 1615  392 1739]\n [1063 1057  338 1807 2001]\n [1170    3  160 1901   77]\n [1293 1559  940 1609   92]\n [ 676  269 1937 1517  875]\n [1714 1147 1940 1322 1363]\n [1570 1120 1598  895 1068]\n [ 145 1844  606 1597 1028]\n [1468 1784  897  497 1222]\n [1345  793  903  833  284]\n [  56 1094 1797 1244 1754]\n [ 983  541 1137 1841   28]\n [ 633  402  207 1142 1161]\n [1202   39 1032  567 1596]\n [1974  196 1442 1806  948]\n [1635 1759 1795 1768  884]\n [ 926 1023 1785   74  784]\n [1954  654 1994  533 1446]\n [ 582 1751 1827 1118  584]\n [ 447  649  303  834 1660]\n [ 897  979 1872 1629  229]\n [1875 1632  840 1763   59]\n [ 167 1095  228 1734 1656]\n [  51 1149  204 1328 1167]\n [1469  473 1579 1990 1569]\n [1438  465 1072  892  383]\n [1901  256 1039  156  503]\n [ 652  224 1076 2009  882]\n [ 599  875 1350 1624 1153]\n [ 353  403 1219  594 1426]\n [1792 1514   23  326 1777]\n [ 687  361 1186  139 1112]\n [ 642  101  454 1414 1500]\n [ 899  323  975 1199 1388]\n [  74  125 1687  307  788]\n [  61  654 1111  967 1368]\n [1260 1274  869  101  210]\n [ 601  255  604 1710  261]\n [ 803 1822  674 1258  630]\n [ 685 1930 1657 1544  922]\n [1525 1222  606 1028  732]\n [ 561 1872  454 1808 1223]\n [1954  723  386 1088 1776]\n [1135 1952  948 1399  565]\n [1623  731 1427 1861 1589]\n [1981 1633  666 1568  393]\n [1031  304 1408 1640 1709]\n [1503  920 1221  534 2003]\n [ 900  753 1055 1147 1771]\n [1698  968  577   93 1398]\n [ 788   97  923  196  443]\n [1397  939 1042 1806  787]\n [ 548   81  711 1455  835]\n [1170  695  986  217 1673]\n [1117 1787  952  296  520]\n [1567  547 1909 1301   34]\n [1579 1214   81 1315  192]\n [1078  874 1110 1777  844]\n [ 981  700  218 1508 1678]\n [1213 1028 1133  746   91]\n [ 726 1703  643 1675  963]\n [ 539 1604  ",
                "lineage": "3001"
            }
        ],
        "31": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    unique_labels, counts = torch.unique(label_tensor, return_counts=True)\n    class_weights = torch.tensor([1.0 / (counts[i].item() + 1e-5) for i in range(len(unique_labels))], device=device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.2713,
                "model_info": "Top-k feature importances: [[ 580  648  400 1318 1283]\n [ 163  372  616  816  768]\n [ 462  162 1971  179 1557]\n [1120 1094  581 1657  514]\n [1444 1875 1161 1887 2036]\n [1841 1352 1620 1955  461]\n [1931  295  823 1629 1339]\n [1509  409  364 1916 1342]\n [ 154 1044    8  135  495]\n [ 161  277 1739  925 1555]\n [1063  338 1057 1807  521]\n [  21 1170  347 1901 1689]\n [1293 1559 1128  303  940]\n [ 269 1937 1517  676  223]\n [ 438 1147 1322 1759 1714]\n [1784 1068 1570 1440  297]\n [ 606  646  145  124 1844]\n [1784 1468  897  299 1222]\n [  42  793  833  500 1749]\n [1797   56 1094 1244 1754]\n [ 541 1841   31  457  983]\n [ 633 1142  207 1454 1341]\n [1202   39  567 1032  909]\n [1974  196 1617 1442  538]\n [1795 1759 1635  838  213]\n [ 926 1314 1785 1360   74]\n [ 533  165  654 2031   51]\n [1751 1181 1553  582  288]\n [ 649 1088 1660  447  303]\n [1872  897 1371 1629 1212]\n [1875 1632  377   59  840]\n [ 167  804 1656 1926 1120]\n [  51 1167 1149  204 1621]\n [1469  473 1579 1562 2031]\n [1438  383 1892  804  465]\n [ 256  420  503  156  508]\n [ 224 1076  652  882 1998]\n [ 875  977  701  327 1303]\n [ 403  353  594 2017 1588]\n [1792   23 1514 1636  211]\n [1287  222  799 1097 1431]\n [ 101  642 1093 1414  428]\n [ 323  899  975 1388 1881]\n [  74  307 1687 2031 1729]\n [ 654  967 1813  957  471]\n [1274  869 1260 1714 1891]\n [ 601  261  255 1679 1825]\n [1822  803  630  674 1478]\n [1657  685  922 1501  915]\n [ 606  732 1525 1028  669]\n [ 454 1872  879  561 1417]\n [1088   56 1954 1572 1298]\n [1135  565 1399  868  630]\n [1861 1365 1427 1623  387]\n [1633 1113  393 1568 1981]\n [1408  304 1508 1518  897]\n [1503  815  920  534 1124]\n [ 753  900 1055  637  107]\n [ 968 1698 1297  577 1898]\n [ 473  788  505  668 1747]\n [ 939 1397  388  787 1280]\n [ 752  711 1491 1010 1455]\n [1673 1991  217  848 1170]\n [ 952 1787  933 1117  296]\n [1567  547 1435 1909   34]\n [ 192  381 1315 2009 2017]\n [1078  177  759  844  874]\n [ 981  218  700 1508  840]\n [1028 1133 1213 1751 1869]\n [ 726 1703 1810 1675  643]\n [ 539  890 1",
                "lineage": "3101"
            }
        ],
        "32": [],
        "33": [],
        "34": [],
        "35": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport torch.nn.functional as F\n\nclass SphericalConvLayer(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(SphericalConvLayer, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n    \n    def forward(self, x):\n        return F.relu(self.conv(x))\n\nclass SphericalResNet(nn.Module):\n    def __init__(self, num_classes):\n        super(SphericalResNet, self).__init__()\n        self.resnet = resnet50(weights='DEFAULT')\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n\n    def forward(self, x):\n        return self.resnet(x)\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = SphericalResNet(len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.resnet.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.2625,
                "model_info": "Top-k feature importances: [[ 400 1318  580  348  648]\n [ 163  362 1850  372  616]\n [ 462 1971  179  859  162]\n [1094  581 1120  501  514]\n [1444 1875 1161 1887   86]\n [1643 1841  461 1955 1352]\n [ 295 1931 1629 1944  603]\n [1509 1916 1674 1342  409]\n [   8  154  135 1044 1695]\n [ 277  161 1424  858 1656]\n [1063 1807  338 1057  312]\n [ 347 1170 1689    3 1901]\n [1293 1559  303  940 1919]\n [ 269  223 1937  244 1517]\n [1147  438 1714  118  546]\n [1784 1068 1570 1120  297]\n [ 606  124  145  646 1597]\n [1784 1468  299  897 1222]\n [  42  833  793  500  903]\n [  56 1094 1797 1244 1754]\n [ 541   31 1841  983  457]\n [ 633 1142 1161 1454  207]\n [1202   39 1032  567 1596]\n [ 196 1617 1974 1442  538]\n [1795 1635  838 1759  213]\n [ 926 1314 1360 1785 1192]\n [ 533  654   51 1446  165]\n [1751 1181  582 1553 1667]\n [ 649 1660 1088  303  447]\n [ 897  979 1629 1872  576]\n [1875 1632  840 1843 1431]\n [ 167  804 1656 1926  418]\n [1149   51 1167  204 1621]\n [1469  473 1579  238 2031]\n [1438  804  383  465 1892]\n [ 256  503  420  508  896]\n [ 224 1076  652 1998  882]\n [ 875  977  701  599  411]\n [ 403 1219  353 2017  594]\n [1792 1514   23  671  211]\n [1287  365  222  406 1329]\n [ 642  101 1414 1277  428]\n [ 899  975  323 1388 1881]\n [ 307 1687   74 1567 1729]\n [ 654 1813  471  967   61]\n [1274 1260  869 1714  210]\n [ 601  255  261 1679  859]\n [1822  803  630  674 1697]\n [1657  685  922 1501  915]\n [ 606  732 1525 1028  669]\n [ 454 1417  879  231 1786]\n [1088 1954 1636  891  723]\n [1135  565  630  868 1399]\n [1427 1861 1365  731 1623]\n [1633 1113 1568 1981  666]\n [1408 1056  304 1508 1031]\n [1503  920  534   16  815]\n [ 753  900  637 1055  666]\n [ 968 1698 2018 1297  577]\n [ 668  473  505  788 1135]\n [ 388  939 1397 1280 1316]\n [ 867  567  835  711 1790]\n [1673 1521 1170 1557  695]\n [ 952 1787 1117  933  520]\n [1567  547 1909 1435   34]\n [ 192 1074 1315 2009  381]\n [1078  177  759  874  844]\n [ 981  218  840  700 1508]\n [1133 1028 1869 1213   91]\n [ 726 1703 1675  643 1140]\n [ 539  890 1",
                "lineage": "3501"
            }
        ],
        "36": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    print(\"Gradient clipping applied with max norm of 1.0\")\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXX.py",
                "accuracy": 0.3166,
                "model_info": "Gradient clipping applied with max norm of 1.0",
                "lineage": "3601"
            }
        ],
        "37": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\nclass SphericalResNet(nn.Module):\n    def __init__(self, num_classes):\n        super(SphericalResNet, self).__init__()\n        self.resnet = resnet50(weights='DEFAULT')\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n\n    def forward(self, x):\n        return self.resnet(x)\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = SphericalResNet(num_classes=len(set(train_label))).to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.resnet.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.2708,
                "model_info": "Top-k feature importances: [[ 400 1318  580  648 1671]\n [ 163  372 1850  616 1326]\n [ 462  147  162  179 1971]\n [1094  581  514  545 1657]\n [1444 1875 1161 1574 1776]\n [1352 1841 1643  461 1955]\n [ 295  823 1931 1944 1629]\n [1509  409 1916  364  495]\n [1044  154  495  433    8]\n [ 277  161 1739  858 1555]\n [1057 1807 1063  338  521]\n [1170  347 2004   21 1901]\n [1293 1559  940  303 1128]\n [ 269  223 1517  875 1937]\n [1147  438 1322  546 1714]\n [1784 1068 1570 1120  297]\n [ 606  145 1844  124 1559]\n [1784 1468  897  299  721]\n [  42  500 1749  284  286]\n [  56 1244 1094 1797 1754]\n [ 541   31 1841  457   28]\n [ 633 1454  207 1161 1142]\n [1202   39  567 1596 1032]\n [1974  196 1617 1442  131]\n [1795 1759  213 1635 1768]\n [ 926 1314 1785 1192 1130]\n [ 654  533   51  165 1446]\n [1751 1553  169  582 1181]\n [ 649 1660  447  834  303]\n [ 897  979 1872  576 1629]\n [1875 1632  377  840 1763]\n [ 167  804 1656  418 1926]\n [  51  204 1149 1167  946]\n [1469  473 2031  238 1579]\n [1438  383 1892  804 1017]\n [ 256  503  420  156  508]\n [ 224 1076  652 1017 1998]\n [ 875  701  977 1135  411]\n [ 403  594 1219  353 1588]\n [ 671 1792 1514  962   23]\n [1287  687  365  799 1184]\n [ 101  642 1414 1500 1093]\n [ 323  975  899 1881 1752]\n [ 307   74 1687  134 1567]\n [ 654  967 1813  957  471]\n [1274 1260  869 1714 1891]\n [ 601  261  255 1679 1825]\n [1822  803  630  674 1478]\n [1657  685  915  530 1501]\n [ 606 1028 1525  732  669]\n [ 454 1417 1872  231  879]\n [1088  723 1954 1298  294]\n [1135  565 1399  630 1630]\n [1861 1365 1427  731 1623]\n [1633 1981 1568  666  393]\n [ 304 1408  927 1518 1056]\n [1503  920  534  815 1287]\n [ 753  900 1880 1055  637]\n [ 968 1698 1898  577  815]\n [ 668  505  473 1135  979]\n [ 939 1397  388  787 1280]\n [ 835  711  867  567  749]\n [1673 1521  695 1557 1702]\n [ 933  952 1787 1117  520]\n [1567  547 1909 1435   34]\n [1315 2017  192  381 1074]\n [1078  177  874  844  759]\n [ 218  981  840 1508  700]\n [1133 1028   91 1869  746]\n [ 726 1703 1140 1975  643]\n [ 890  539 1",
                "lineage": "3701"
            }
        ],
        "38": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\nclass AttentionLayer(nn.Module):\n    def __init__(self, in_channels):\n        super(AttentionLayer, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, in_channels // 2, kernel_size=1)\n        self.conv2 = nn.Conv2d(in_channels // 2, in_channels, kernel_size=1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        attention = self.sigmoid(self.conv2(self.sigmoid(self.conv1(x))))\n        return x * attention\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    attention_layer = AttentionLayer(in_channels=3).to(device)\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            inputs = attention_layer(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            inputs = attention_layer(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.016,
                "model_info": "Top-k feature importances: [[ 914 1283  859  865   81]\n [ 971 1850 1390  441  463]\n [ 162 1557  462 1224  859]\n [ 276  581  944  501 1943]\n [1875 1161 1887  602  684]\n [ 461 1352 1841 1955 1643]\n [ 295 1629 1506  193 1050]\n [1509 1916  593  984  634]\n [1097  778 1173  228  777]\n [1479  637 1656   70  161]\n [ 521  338 1063   83 1507]\n [1689 1256  746 1170  347]\n [1559 1388 1919 1293  185]\n [ 964  431 1753  676 1517]\n [ 486 1650  438 1147   11]\n [ 895   31 1120 1705 1784]\n [ 145  654 2015  776  965]\n [1784  166 1468 1611  497]\n [ 793   42  543 1519 1048]\n [1808  893 1094 1797  844]\n [ 541 1841  448  798  457]\n [1523 1454  207  633 1053]\n [1202   39 1954 1596 1033]\n [1514  708 1712  641  196]\n [1938 1795 1164 1770  654]\n [ 926 1684 1145 1314 1262]\n [ 654  586 1819 1954 1406]\n [1372 1751  584 1181  346]\n [ 834  770 1582  373  762]\n [1872  897  740 1629  602]\n [ 909 1184 1419 1875 1746]\n [  76  804  167  987 1926]\n [1149  946   51 1328  790]\n [ 473   16 1469 1207 1579]\n [1785  892  383  288  804]\n [ 420  156  503 1224   26]\n [ 224 1076  882  652 1017]\n [ 599 1586  977  411  337]\n [ 594  241  471 1821 1669]\n [1514 1792  962  321  971]\n [ 880 1159 1287  795  687]\n [ 642 1093 1414  389 1612]\n [1388  899  975  323   98]\n [  74 1789 1053 1364 1687]\n [1925 1368 1111  386  609]\n [1260  606 1274   19  148]\n [ 255 1901  604 1937 2043]\n [1071 1405  435  582  803]\n [ 922  685 1501  608 1448]\n [1525 1563   63 1222 1522]\n [ 454  609 1417 1031 1504]\n [ 537 1298 1954 1661 1322]\n [1243  739 1630   41  317]\n [1427 1861  412 1623 1210]\n [1568  558   80  393  315]\n [1031  779 1508  897 1518]\n [1503  534  284  470   40]\n [1055  900  753  107 1021]\n [ 968   93 1812  815 1398]\n [ 328 1261  923  788 1823]\n [ 388 1306 1849 1397 1000]\n [ 298  567 1528  752  749]\n [1702 1264  217  891 1673]\n [1117  933 1827   42  520]\n [1909 1567 1279  547 1435]\n [1692 1074  192   81 1315]\n [1078  353 1830 1622  844]\n [ 700  981 1508 1678 1268]\n [1133   91  746 1751 1213]\n [ 726 1467 1975 1675 1006]\n [ 443 1886  ",
                "lineage": "3801"
            }
        ],
        "39": [],
        "40": [],
        "41": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    class_counts = torch.bincount(label_tensor)\n    class_weights = 1.0 / class_counts.float()\n    sample_weights = class_weights[label_tensor]\n    sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights))\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.3039,
                "model_info": "Top-k feature importances: [[ 580 1283  400 1671 1811]\n [ 163  768  616  372  816]\n [ 462 1154  162 1971 1557]\n [ 581 1094  514 1120 1191]\n [1875 1444 1161 1574 1788]\n [1643  461 1955 1841 1352]\n [ 295 1931 1944  193  556]\n [1509  752 1342 1916  409]\n [ 495  510  154 1173  116]\n [ 277  392  161 1728 1951]\n [1807  338 1057  521 1063]\n [ 347 1170  866  160 1689]\n [ 940 1293 1597  303 1388]\n [1937  223   51  244  710]\n [1147  438 1650   11 1714]\n [1068 1784 1120 1440  895]\n [ 606  395 1597  145  654]\n [1784 1468  897 1991  299]\n [ 793  631  284   13 1519]\n [  56 1797 1375 1754  295]\n [ 798  983 1841  899  541]\n [ 633 1226 1341 1454  207]\n [1202   39 1596 1954 1010]\n [1974  538 1442  196  641]\n [1759 1635  213 1370 1795]\n [  74 1192  926 1314 1785]\n [1274  533 1313 1994  946]\n [1751 1802  626 1667 1917]\n [ 649  834  447  762  303]\n [ 897  979 1629 1872 1656]\n [1875  840 1763  506  377]\n [ 167  804 1734 1656 1120]\n [  51 1167 1149  204  906]\n [1469 1579 2031  164  473]\n [1438  804 1157 1601  696]\n [ 503  575 1901  420  896]\n [1076  652  882  943  224]\n [ 337  977  701 1624  327]\n [ 403 1219  471 1713  594]\n [ 971  464 1514 1597  962]\n [1287  687  636   46  222]\n [1565 1500  642 1612  101]\n [1752  899  975 1388    6]\n [1729   74  307 1687  966]\n [1813  654  957  241  471]\n [1274  869 1714 1891 1260]\n [ 261  601 2043  255 1679]\n [1822  803 1261  630  751]\n [ 685 1657 1501 1930 1364]\n [1525  732  606 1222  669]\n [ 454 1872  879  231  561]\n [1088 1298 1954  891 1776]\n [1135 1630  257  630 1373]\n [1623 1427 1861 1292 1210]\n [1633 1113 1568 1981  315]\n [1056  660  304  927 1508]\n [1503  534 1287 1091  565]\n [ 753  900 1055  637 1147]\n [ 968  815 1698   93  577]\n [ 668  505  788  328  473]\n [ 388 1397 1611  939 1280]\n [1040 1844  711  752 1010]\n [1673  217  168 1991 1702]\n [1117 1787   42  952  933]\n [1567  547  304 1435 1301]\n [1074  192  918  941 2009]\n [ 844 1078  874  177 1087]\n [ 700 1508  218  840  981]\n [1028 1133   91 1238 1751]\n [ 726 1703 1975 1675 1810]\n [ 539  890  ",
                "lineage": "4101"
            }
        ],
        "42": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024, confidence_threshold=0.5):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(15):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(15):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        val_preds = torch.argmax(val_outputs, dim=1).cpu().numpy()\n        val_probs = torch.softmax(val_outputs, dim=1).cpu().numpy()\n    \n    low_confidence_count = (val_probs.max(axis=1) < confidence_threshold).sum()\n    low_confidence_percentage = low_confidence_count / len(val_preds) * 100\n    print(f\"Percentage of low-confidence predictions: {low_confidence_percentage:.2f}%\")\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXX.py",
                "accuracy": 0.3252,
                "model_info": "Percentage of low-confidence predictions: 43.68%",
                "lineage": "4201"
            }
        ],
        "43": [],
        "44": [],
        "45": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n\n    augmented_transforms = transforms.Compose([\n        color_jitter\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.3119,
                "model_info": "Top-k feature importances: [[1494  580  648 1743 1671]\n [ 372  163  768  204 1330]\n [1971  462  162  147  859]\n [ 581  514  945 1094  628]\n [1875 1161  862 1444   86]\n [1841  461 1352  511  541]\n [ 295 1944 1629  193 1395]\n [1509  118  409 1916 1191]\n [ 495    8  154 1044  510]\n [  80  161 1555 1728 1951]\n [ 837  243 1063  338  572]\n [1689  746 1148   77 1170]\n [1293 1559 1128 1853 1196]\n [ 710  157 1753  269  964]\n [1147  486 2046 1714  438]\n [1570 1120 1784 1068 1821]\n [1028 1057 1531  646  200]\n [1468 1784  362 1037  166]\n [ 793  631   42 1749  499]\n [1754  844  295 1094 1375]\n [1172   31  908  160 1923]\n [ 633 1454 1657 1142 1079]\n [1202   39  567 1032 1346]\n [ 764 1974 1617  948 1564]\n [ 213 1164 1759 1795 1493]\n [ 926  993 1785 1314 1360]\n [1274  863 1617  533  654]\n [1751 1802  584  288  626]\n [ 447 2005  834  649 1579]\n [ 897 1629 1371  740 1872]\n [1875  377 1763 1419  840]\n [ 804  167 1734 1926 1656]\n [ 946 1167 1149  204   41]\n [1469 2031  473 1562  164]\n [ 383 1072  371 1438  804]\n [ 462  503  256  420  575]\n [ 224 1257 1076 1998 1230]\n [ 977 1624 1303 1520 1572]\n [1380 1821 2017  403 1629]\n [ 464  671 1597  717  962]\n [ 936  795  636  617  222]\n [ 642 1414 1500 1565  101]\n [ 975    6  323  359 1106]\n [1789 1687 1364  125  788]\n [1813  241 1986 1012  178]\n [1274  101   71  108 1260]\n [ 261  601 1097 1717 2004]\n [1822 1261 1601  565 1478]\n [ 685  988  922  851 1856]\n [ 606 1222 1461  522 1480]\n [1872  454  618 1808 1417]\n [1088  891  970 1573  169]\n [1135  565 1045 1630  317]\n [1861 1427 1210 1292 1365]\n [1981  393 1568  315  666]\n [ 988  304  551 2037 1056]\n [1503  688  920 2047 1287]\n [ 753 1119  190 1055  281]\n [1898  577  815  956  696]\n [ 668 1845  505  473  923]\n [1397  388 1961  939 1280]\n [ 835 1790 1455 1378  711]\n [1673 1183 1557  562 1702]\n [1117  933  296  520  610]\n [1567  296 1279  547   72]\n [1315  192 1496 2009  785]\n [ 177 1078 1087 1830  759]\n [ 700 1268  981 1322 1508]\n [ 746   91 1213  244 1028]\n [ 726 1703 1810  625 1675]\n [ 890 1458 1",
                "lineage": "4501"
            }
        ],
        "46": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.3228,
                "model_info": "",
                "lineage": "4601"
            }
        ],
        "47": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(15):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    frozen_params = sum(not param.requires_grad for param in model.parameters())\n    trainable_params = sum(param.requires_grad for param in model.parameters())\n    print(f\"Trainable vs Frozen Parameters Ratio: {trainable_params / (frozen_params + 1e-6)}\")\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(15):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXX.py",
                "accuracy": 0.3218,
                "model_info": "Trainable vs Frozen Parameters Ratio: 161000000.0\nTop-k feature importances: [[1318  400 1494  348 1743]\n [ 372  135  185  971  816]\n [ 147 1557  162 1971 1505]\n [ 514 1120 1094 1171 1389]\n [1574 1390 1444 1875 1887]\n [1580 1352 1955  461 1841]\n [ 295  603 1983 1931  193]\n [1509 1916  364 1141 1385]\n [1835 1158  154 1213 1249]\n [1615  161  539   82  925]\n [1057 2001  338 1807  521]\n [ 160   77 1170 1806    3]\n [ 185  940 1559 1293  736]\n [ 676 1937 1767  964 1025]\n [1363  486  118 1714 1147]\n [1570  892  297 1120  895]\n [ 370  606 1028 1597 1844]\n [1784 1468 1991 1560 1611]\n [  42 1519  284  833  714]\n [1244 1754  860 1094 1030]\n [ 983 1841  541  438   28]\n [ 402 1142  633 1226   24]\n [1202   39 1611 1596 1032]\n [1564  196 1974  852 1442]\n [1759 1038  716 1635 1795]\n [ 926 1451  343 1262  784]\n [1954   94  946  654 1819]\n [ 582  288   23 1642  132]\n [ 447  649  834  303 2005]\n [ 979  897 1872 1212 1633]\n [1875 1632  633 1843 1167]\n [1734 1656 1095   76  847]\n [1149  204   51 1167  946]\n [1469 1990 1897  473 1839]\n [1438 1072  465  537  196]\n [1039  256  462  156  420]\n [1076  652  224 1856 1626]\n [ 599  875  411 1350  701]\n [ 353  594 1219 1821 1489]\n [1792  671   23  934 1946]\n [ 687  925  361 1746 1609]\n [ 454 1414 1500  642  488]\n [ 899  396  978  323  359]\n [1687  125  307  788   74]\n [  61  654 1111 1813  967]\n [1260 1274 1327  101  846]\n [ 601  261  255 1710  604]\n [ 803 1601 1822  751  910]\n [ 685 1574  915 1544 1930]\n [1525 1446  456 1222  212]\n [1513  454  587  410 1808]\n [1954   10  386  723 1573]\n [1952 1646 1135 1009 1220]\n [ 715  731 1427 1861 1623]\n [1579 1568 1633  393 1981]\n [1031 1408  385  790  603]\n [1503  920 1221 2003  815]\n [ 900 1147  277   77 1055]\n [1698  968  577 2018  815]\n [ 788  196  573 1273  328]\n [1042 1778  939 1806 1306]\n [ 835  711  548 1305 1455]\n [ 217  264 1557  891  848]\n [  42 1117 1390  296 1661]\n [ 547 1567 1909   34  814]\n [ 788  192   81 2033 1315]\n [1078 1110  482  353  759]\n [ 981  700 1971 1871  840]\n [ 746 1028 1133 12",
                "lineage": "4701"
            }
        ],
        "48": [],
        "49": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.2745,
                "model_info": "",
                "lineage": "4901"
            }
        ],
        "50": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n\n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(15):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(15):\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n\n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.3158,
                "model_info": "Top-k feature importances: [[ 400 1233  914  859  348]\n [ 372  971 1801  816  616]\n [ 162  147 1971  622  585]\n [1120  514 1094  557  581]\n [1444 1161 1887 1390   86]\n [1580 1352  461 1841  133]\n [ 295  823  849 1931   57]\n [1916  409 1509  823  364]\n [1835  154 1213 1173 1249]\n [ 161 1615  843 1479   82]\n [1057  521 1063  338  837]\n [  77 1954  160 1689  158]\n [1293   92  303  736  940]\n [ 964  875 1753  710 1025]\n [ 118 1952  486  703 1714]\n [1570 1123  892 1271 1120]\n [1028  606 1597  145 1844]\n [1784 1468 1560 1219  497]\n [  42  926  284 1345  833]\n [1754 1808 1244 1797 1094]\n [ 541  983 1841 1137  438]\n [1142  402  633 1236  207]\n [1202   39 1032 1596   25]\n [1974  760  196 1712  948]\n [1635 1825 1795 1759 1768]\n [ 926 1451 1023 1500  784]\n [  94 1954 1680 1179  490]\n [ 584  288  106 1642  582]\n [2005  649  834  212  713]\n [ 897  979 1872  430  602]\n [ 479 1875 1632 1763 1412]\n [1656  167 1095 1574  804]\n [  51 1167  204  946 1328]\n [1469  473 1897 1579  151]\n [ 465 1438 1157 1072  892]\n [ 420  256 2034 1039 1596]\n [ 652 1076 1730  224 1980]\n [ 875  599  701  343  411]\n [ 353  594 1219 1588 1821]\n [1792 1514  671 1631   23]\n [ 932 1746  687 1159 1186]\n [ 642  454 1500 1398 1093]\n [ 975  899 1581 1199  359]\n [1687  125   74 1223  500]\n [  61  654  967 1693 1111]\n [1260 1274  101 1714   19]\n [ 601  261 1710  255 1426]\n [ 803  910 1822 1601 1258]\n [1574  685 1965  495 1657]\n [1525 1222 1865 1784  456]\n [ 454  587 1513  309 1910]\n [1954 1572  386 1088 1217]\n [1952 1135  893 1646  948]\n [ 731  715  735 1623 1861]\n [1981  393 1568  666 1633]\n [1031 1640 1408 1518 2039]\n [1503  920  815  534 1221]\n [ 900  277 1055   77 1147]\n [1698  968  577   93 1040]\n [ 788  923 1823 1348  502]\n [1042 1397  787 1611  388]\n [ 548  711   81  835 1455]\n [ 217 1521 1991   75 1928]\n [1117 1562  952 1171  296]\n [ 547 1567   34 1301 1909]\n [1579 1214  192 1116  227]\n [1078 1777  874  844  482]\n [ 981  742 1971 1871  218]\n [ 746   91 1213 1028 1133]\n [ 726 1703 1975 1675  643]\n [ 539 1604 1",
                "lineage": "5001"
            }
        ],
        "51": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    random_rotation = transforms.RandomRotation(degrees=30)\n    \n    augmented_transforms = transforms.Compose([\n        color_jitter,\n        random_rotation\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = augmented_transforms(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXX.py",
                "accuracy": 0.3317,
                "model_info": "Epoch 1 data loading time: 8.9980 seconds\nEpoch 2 data loading time: 8.1296 seconds\nEpoch 3 data loading time: 8.0683 seconds\nEpoch 4 data loading time: 8.0828 seconds\nEpoch 5 data loading time: 8.0855 seconds\nEpoch 6 data loading time: 8.0893 seconds\nEpoch 7 data loading time: 8.0904 seconds\nEpoch 8 data loading time: 8.0861 seconds\nEpoch 9 data loading time: 8.0623 seconds\nEpoch 10 data loading time: 8.0623 seconds\nEpoch 1 data loading time: 8.0626 seconds\nEpoch 2 data loading time: 8.0644 seconds\nEpoch 3 data loading time: 8.0647 seconds\nEpoch 4 data loading time: 8.0681 seconds\nEpoch 5 data loading time: 8.0667 seconds\nEpoch 6 data loading time: 8.0668 seconds\nEpoch 7 data loading time: 8.0692 seconds\nEpoch 8 data loading time: 8.0682 seconds\nEpoch 9 data loading time: 8.0837 seconds\nEpoch 10 data loading time: 8.0875 seconds\nTop-k feature importances: [[ 400 1318  348  580 1494]\n [ 372  185  163  616  971]\n [1971 1557  462  147  162]\n [1094 1120  514  581  383]\n [1875 1444 1390 1161 1574]\n [1352 1841 1620  461 1955]\n [ 295  849  823 1931  193]\n [1509 1916  829  364  409]\n [1173  154  433 1249 1695]\n [ 925  161 1615  277 1656]\n [1057 1063  338 1807 1608]\n [  21  347 1901 1170    3]\n [1559 1293 1388  303  185]\n [ 676  964  875  269  157]\n [1147 1940  118 1650 1952]\n [1570 1120 1669 1784  895]\n [ 606 1057  145 1559 1028]\n [1784 1468  897  299  497]\n [ 833  284   42 1519  793]\n [1094 1244 1797  141   56]\n [ 541 1137  983 1841  438]\n [1142  402  633 1161   24]\n [1202   39 1032 1611 1346]\n [ 196 1974  948  709  519]\n [1768 1635 1795 1038  884]\n [ 926 1262   74 1785 1023]\n [1954   42 1819   51  654]\n [ 582  288 1667 1751   23]\n [ 447  649  303 2005 1660]\n [ 897  979 1872 1371 1629]\n [1875 1632 2037  479   59]\n [1095 1656 1926  228 1734]\n [1149   51  204 1167 1328]\n [1469  473  238 1207 1990]\n [ 465 1438 1072  383 1157]\n [ 462  256  156  420 1039]\n [1076  652  224  882 1017]\n [ 875  977  701 1973  411]\n [1219  353  403  594 2017]\n [ 671 1792   23 1380 1777]\n [ 406 1287",
                "lineage": "5101"
            }
        ],
        "52": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXX.py",
                "accuracy": 0.3477,
                "model_info": "Epoch 1 data loading time: 8.1595 seconds\nEpoch 2 data loading time: 7.5432 seconds\nEpoch 3 data loading time: 7.5353 seconds\nEpoch 4 data loading time: 7.5518 seconds\nEpoch 5 data loading time: 7.5527 seconds\nEpoch 6 data loading time: 7.5430 seconds\nEpoch 7 data loading time: 7.5437 seconds\nEpoch 8 data loading time: 7.5510 seconds\nEpoch 9 data loading time: 7.6058 seconds\nEpoch 10 data loading time: 7.6166 seconds\nTop-k feature importances: [[1283  648 1161 1494 1811]\n [ 768  163  372  971  816]\n [ 462 1971 1557  179  859]\n [ 581 1094 1128  104 1191]\n [1875 1444  602  817 1887]\n [1643 1352 1028 1841  461]\n [ 295 1931 1944  403 1339]\n [1509  409 1311  118  752]\n [1173  116  778  154  510]\n [ 161  277  392  266 1555]\n [1542 1063  338  521 1057]\n [1170  347   77    3 1256]\n [1559 1128  904 1597  303]\n [ 686  244  875 1762 1753]\n [ 118  438 1322  486  114]\n [1570 1120 1784 1068  297]\n [ 606 1559 1057  277  646]\n [1784  897 1037  299 1468]\n [ 793  631  955 1749  903]\n [1048   56 1754 1030 1797]\n [1841  983 1923   28 1359]\n [1226  633 1454 1523 1657]\n [  39 1202  182 1346 1596]\n [1974  641  196  948 1712]\n [1759  782  596  213  594]\n [1785 1192  926 1262 1314]\n [ 863 1819 1274  154   42]\n [1181 1751 1802 2017  758]\n [ 649  834 1660 1895 1438]\n [1371 1629  979  897 1872]\n [1875 1419 1431  840  377]\n [ 167 1120  611 1926 1095]\n [  51  946 1149 1167 1621]\n [2031 1579  164  473 1280]\n [1438  752  804  383 1892]\n [ 503  896  156 1224  420]\n [1076  224 1250 1626  652]\n [ 977 1754  701 1624  875]\n [1821  471 1788 1689  594]\n [ 971 1514  671 1777  717]\n [1287  936  799  222  151]\n [1093  642  122 1500 1414]\n [ 975    6 1752  323  381]\n [1364  134 1687 1567 1789]\n [1813  654  386  508  471]\n [ 869  210 1273 1714 1274]\n [ 261  255 1901  601 2004]\n [1822  630 1478 1263  674]\n [ 988  685  530 1930  143]\n [1525  732  669  606 1784]\n [ 390 1910  879  618 1913]\n [1088  723 1661  455 1954]\n [1630  565  893  630  868]\n [1427 1861  674 1365 1210]\n [ 666 1633  315  558 1568]\n [ 988 1056 ",
                "lineage": "5201"
            }
        ],
        "53": [],
        "54": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\nclass SphericalResNet(nn.Module):\n    def __init__(self, num_classes):\n        super(SphericalResNet, self).__init__()\n        self.resnet = resnet50(weights='DEFAULT')\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n\n    def forward(self, x):\n        return self.resnet(x)\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = SphericalResNet(len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXX.py",
                "accuracy": 0.3449,
                "model_info": "Epoch 1 data loading time: 8.1796 seconds\nEpoch 2 data loading time: 7.5413 seconds\nEpoch 3 data loading time: 7.5319 seconds\nEpoch 4 data loading time: 7.5385 seconds\nEpoch 5 data loading time: 7.5423 seconds\nEpoch 6 data loading time: 7.5504 seconds\nEpoch 7 data loading time: 7.5541 seconds\nEpoch 8 data loading time: 7.5590 seconds\nEpoch 9 data loading time: 7.5711 seconds\nEpoch 10 data loading time: 7.5703 seconds",
                "lineage": "5401"
            }
        ],
        "55": [],
        "56": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXX.py",
                "accuracy": 0.4075,
                "model_info": "Epoch 1 data loading time: 28.6137 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.84 batches/sec\nEpoch 2 data loading time: 14.6778 seconds\nBatch size: 64, Queue length: 625, Throughput: 42.58 batches/sec\nEpoch 3 data loading time: 31.0394 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.14 batches/sec\nEpoch 4 data loading time: 31.1292 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.08 batches/sec\nEpoch 5 data loading time: 21.6319 seconds\nBatch size: 64, Queue length: 625, Throughput: 28.89 batches/sec\nEpoch 6 data loading time: 13.5920 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.98 batches/sec\nEpoch 7 data loading time: 13.6121 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.91 batches/sec\nEpoch 8 data loading time: 13.6200 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.89 batches/sec\nEpoch 9 data loading time: 16.9401 seconds\nBatch size: 64, Queue length: 625, Throughput: 36.89 batches/sec\nEpoch 10 data loading time: 31.5537 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.81 batches/sec\nTop-k feature importances: [[ 580 1283   22 1161 1109]\n [ 816 1460  463  329 1330]\n [1557  462  273  622  691]\n [ 150  514  944  594  545]\n [1887 1875   43  270 1198]\n [1230  461 1733 1352 1643]\n [ 295  658  193  403 1633]\n [1335  814 1509  409 1141]\n [1835 1173 1992  116  154]\n [2022  277  578  164  266]\n [1943 1807 1323  338 1063]\n [  77  160  347 1839 1419]\n [ 856 1128  774 1597 1249]\n [1762 1937  234  157  806]\n [1322  118 1243 1759  265]\n [ 892 1570  895  511  943]\n [ 232   62  606 1559 1597]\n [ 897 1784 1991 1037  610]\n [ 793 1178  329 1813  833]\n [1754 1048  738 1092 1307]\n [ 983  798 1034  820 1137]\n [1142 1226 1523 1454  421]\n [1202   39   25  182  567]\n [1974 1450  948  538 1827]\n [ 596  437 2003 1009  438]\n [1684 1192  115  761 1785]\n [1683  863  262 1819  390]\n [ 660 1181 1727 1751 2017]\n [1438 1968 1660  834  447]\n [1986 1629 1844  897 1647]\n [1875 2047   59  559  479]\n [ 167  735  305 1656 10",
                "lineage": "5601"
            }
        ],
        "57": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\nfrom sklearn.manifold import TSNE\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    train_features = model.fc.weight.detach().cpu().numpy()\n    tsne = TSNE(n_components=2)\n    reduced_features = tsne.fit_transform(train_features)\n    \n    feature_importance = torch.softmax(model.fc.weight.detach(), dim=1).cpu().numpy()\n    top_k_indices = feature_importance.argsort(axis=1)[:, -5:][:, ::-1]\n    print(\"Top-k feature importances:\", top_k_indices)\n\n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXX.py",
                "accuracy": 0.4019,
                "model_info": "Epoch 1 data loading time: 27.2083 seconds\nBatch size: 64, Queue length: 625, Throughput: 22.97 batches/sec\nEpoch 2 data loading time: 13.8386 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.16 batches/sec\nEpoch 3 data loading time: 14.1828 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.07 batches/sec\nEpoch 4 data loading time: 18.9219 seconds\nBatch size: 64, Queue length: 625, Throughput: 33.03 batches/sec\nEpoch 5 data loading time: 31.4785 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.85 batches/sec\nEpoch 6 data loading time: 31.3738 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.92 batches/sec\nEpoch 7 data loading time: 27.8270 seconds\nBatch size: 64, Queue length: 625, Throughput: 22.46 batches/sec\nEpoch 8 data loading time: 31.0279 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.14 batches/sec\nEpoch 9 data loading time: 27.0888 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.07 batches/sec\nEpoch 10 data loading time: 30.3724 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.58 batches/sec\nTop-k feature importances: [[ 580  400 1283  865 1811]\n [ 696  816 1390  669    0]\n [1557 1273  622  859  199]\n [  14  936    5  500 1040]\n [1887   43 1875  602  135]\n [1352 1230  461  825 1471]\n [ 295  193 1506 1931  260]\n [1509 1141 1342 1311 1335]\n [1641 1593  154  116 2021]\n [ 392 1700  637  578 1656]\n [1807  521 1021 1326  617]\n [  21 1248  528    3  347]\n [ 856 1559 1919  424 1937]\n [ 527  570  234  989  244]\n [ 118 1322 1147  265  486]\n [1570 1670  895  165 1120]\n [ 606  232  325 2015   62]\n [1037  897 1784  497  431]\n [ 793 1469  833  329   21]\n [ 296 1048 1754 1191  844]\n [ 983   28 1137  798  541]\n [1226 1454 1523  633 1389]\n [1202 1596   39 1010 1333]\n [ 948 1974 1450  538 1514]\n [ 437 2003  596 1770 1759]\n [1192 1684  761  596 1262]\n [1683 1819 1954 1929  356]\n [ 146  660 1727   44 2017]\n [1660  672  834 1507 1151]\n [1844    5 1116 1849  132]\n [1767 1843 1793  559 2037]\n [ 167 1891  611 1694 19",
                "lineage": "5701"
            }
        ],
        "58": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXX.py",
                "accuracy": 0.4108,
                "model_info": "Epoch 1 data loading time: 23.8207 seconds\nBatch size: 64, Queue length: 625, Throughput: 26.24 batches/sec\nEpoch 2 data loading time: 28.2924 seconds\nBatch size: 64, Queue length: 625, Throughput: 22.09 batches/sec\nEpoch 3 data loading time: 19.6194 seconds\nBatch size: 64, Queue length: 625, Throughput: 31.86 batches/sec\nEpoch 4 data loading time: 31.3574 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.93 batches/sec\nEpoch 5 data loading time: 22.7345 seconds\nBatch size: 64, Queue length: 625, Throughput: 27.49 batches/sec\nEpoch 6 data loading time: 14.4042 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.39 batches/sec\nEpoch 7 data loading time: 13.5740 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.04 batches/sec\nEpoch 8 data loading time: 20.3451 seconds\nBatch size: 64, Queue length: 625, Throughput: 30.72 batches/sec\nEpoch 9 data loading time: 13.7533 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.44 batches/sec\nEpoch 10 data loading time: 13.5859 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.00 batches/sec",
                "lineage": "5801"
            }
        ],
        "59": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nimport time\n\nclass SphericalConvLayer(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(SphericalConvLayer, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass SphericalResNet(nn.Module):\n    def __init__(self, num_classes):\n        super(SphericalResNet, self).__init__()\n        self.spherical_conv1 = SphericalConvLayer(3, 64)\n        self.fc = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        x = self.spherical_conv1(x)\n        x = nn.functional.relu(x)\n        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = SphericalResNet(num_classes=len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXX.py",
                "accuracy": 0.0061,
                "model_info": "Epoch 1 data loading time: 3.0713 seconds\nBatch size: 64, Queue length: 625, Throughput: 203.49 batches/sec\nEpoch 2 data loading time: 1.2376 seconds\nBatch size: 64, Queue length: 625, Throughput: 504.99 batches/sec\nEpoch 3 data loading time: 1.2230 seconds\nBatch size: 64, Queue length: 625, Throughput: 511.01 batches/sec\nEpoch 4 data loading time: 1.2218 seconds\nBatch size: 64, Queue length: 625, Throughput: 511.52 batches/sec\nEpoch 5 data loading time: 1.2249 seconds\nBatch size: 64, Queue length: 625, Throughput: 510.22 batches/sec\nEpoch 6 data loading time: 1.2217 seconds\nBatch size: 64, Queue length: 625, Throughput: 511.56 batches/sec\nEpoch 7 data loading time: 1.2217 seconds\nBatch size: 64, Queue length: 625, Throughput: 511.56 batches/sec\nEpoch 8 data loading time: 1.2234 seconds\nBatch size: 64, Queue length: 625, Throughput: 510.86 batches/sec\nEpoch 9 data loading time: 1.2215 seconds\nBatch size: 64, Queue length: 625, Throughput: 511.66 batches/sec\nEpoch 10 data loading time: 1.2212 seconds\nBatch size: 64, Queue length: 625, Throughput: 511.80 batches/sec",
                "lineage": "5901"
            }
        ],
        "60": [],
        "61": [],
        "62": [],
        "63": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15),\n        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=None, shear=None)\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXX.py",
                "accuracy": 0.4059,
                "model_info": "Epoch 1 data loading time: 30.1586 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.72 batches/sec\nEpoch 2 data loading time: 30.9527 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.19 batches/sec\nEpoch 3 data loading time: 19.9563 seconds\nBatch size: 64, Queue length: 625, Throughput: 31.32 batches/sec\nEpoch 4 data loading time: 15.9477 seconds\nBatch size: 64, Queue length: 625, Throughput: 39.19 batches/sec\nEpoch 5 data loading time: 23.2018 seconds\nBatch size: 64, Queue length: 625, Throughput: 26.94 batches/sec\nEpoch 6 data loading time: 13.8355 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.17 batches/sec\nEpoch 7 data loading time: 13.8542 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.11 batches/sec\nEpoch 8 data loading time: 13.8719 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.06 batches/sec\nEpoch 9 data loading time: 13.8728 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.05 batches/sec\nEpoch 10 data loading time: 13.8751 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.04 batches/sec",
                "lineage": "6301"
            }
        ],
        "64": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n        return F_loss.mean()\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = FocalLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXX.py",
                "accuracy": 0.3809,
                "model_info": "Epoch 1 data loading time: 30.7627 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.32 batches/sec\nEpoch 2 data loading time: 30.7302 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.34 batches/sec\nEpoch 3 data loading time: 30.9703 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.18 batches/sec\nEpoch 4 data loading time: 22.5741 seconds\nBatch size: 64, Queue length: 625, Throughput: 27.69 batches/sec\nEpoch 5 data loading time: 26.1075 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.94 batches/sec\nEpoch 6 data loading time: 20.9074 seconds\nBatch size: 64, Queue length: 625, Throughput: 29.89 batches/sec\nEpoch 7 data loading time: 13.8198 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.22 batches/sec\nEpoch 8 data loading time: 13.8366 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.17 batches/sec\nEpoch 9 data loading time: 13.8364 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.17 batches/sec\nEpoch 10 data loading time: 13.8417 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.15 batches/sec",
                "lineage": "6401"
            }
        ],
        "65": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(15):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXX.py",
                "accuracy": 0.3977,
                "model_info": "Epoch 1 data loading time: 29.4486 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.22 batches/sec\nEpoch 2 data loading time: 28.9715 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.57 batches/sec\nEpoch 3 data loading time: 30.8698 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.25 batches/sec\nEpoch 4 data loading time: 26.9594 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.18 batches/sec\nEpoch 5 data loading time: 13.5344 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.18 batches/sec\nEpoch 6 data loading time: 13.5502 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.12 batches/sec\nEpoch 7 data loading time: 13.5613 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.09 batches/sec\nEpoch 8 data loading time: 13.5636 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.08 batches/sec\nEpoch 9 data loading time: 13.5673 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.07 batches/sec\nEpoch 10 data loading time: 13.5779 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.03 batches/sec\nEpoch 11 data loading time: 13.5840 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.01 batches/sec\nEpoch 12 data loading time: 18.5624 seconds\nBatch size: 64, Queue length: 625, Throughput: 33.67 batches/sec\nEpoch 13 data loading time: 32.1258 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.45 batches/sec\nEpoch 14 data loading time: 31.8920 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.60 batches/sec\nEpoch 15 data loading time: 32.0458 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.50 batches/sec",
                "lineage": "6501"
            }
        ],
        "66": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    for param in model.parameters():\n        param.requires_grad = True\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXX.py",
                "accuracy": 0.4021,
                "model_info": "Epoch 1 data loading time: 32.5240 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.22 batches/sec\nEpoch 2 data loading time: 31.8557 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.62 batches/sec\nEpoch 3 data loading time: 31.9757 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.55 batches/sec\nEpoch 4 data loading time: 32.1430 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.44 batches/sec\nEpoch 5 data loading time: 32.0565 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.50 batches/sec\nEpoch 6 data loading time: 19.3206 seconds\nBatch size: 64, Queue length: 625, Throughput: 32.35 batches/sec\nEpoch 7 data loading time: 13.5198 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.23 batches/sec\nEpoch 8 data loading time: 13.5331 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.18 batches/sec\nEpoch 9 data loading time: 13.5503 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.12 batches/sec\nEpoch 10 data loading time: 13.5612 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.09 batches/sec",
                "lineage": "6601"
            }
        ],
        "67": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    model = resnet50(weights='DEFAULT')\n    model.fc = nn.Linear(model.fc.in_features, len(set(train_label)))\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            print(f\"Epoch {epoch+1}, Gradient Norm: {grad_norm:.4f}\")\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXX.py",
                "accuracy": 0.4115,
                "model_info": "Epoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradient Norm: 1.0000\nEpoch 1, Gradien",
                "lineage": "6701"
            }
        ],
        "68": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXX.py",
                "accuracy": 0.4202,
                "model_info": "Epoch 1 data loading time: 32.4199 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.28 batches/sec\nEpoch 2 data loading time: 22.1055 seconds\nBatch size: 64, Queue length: 625, Throughput: 28.27 batches/sec\nEpoch 3 data loading time: 13.6382 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.83 batches/sec\nEpoch 4 data loading time: 13.6390 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.82 batches/sec\nEpoch 5 data loading time: 30.6376 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.40 batches/sec\nEpoch 6 data loading time: 31.3991 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.90 batches/sec\nEpoch 7 data loading time: 32.1591 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.43 batches/sec\nEpoch 8 data loading time: 32.1366 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.45 batches/sec\nEpoch 9 data loading time: 32.1249 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.46 batches/sec\nEpoch 10 data loading time: 32.1080 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.47 batches/sec",
                "lineage": "6801"
            }
        ],
        "69": [],
        "70": [],
        "71": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXX.py",
                "accuracy": 0.3505,
                "model_info": "Epoch 1 data loading time: 23.5537 seconds\nBatch size: 64, Queue length: 625, Throughput: 26.53 batches/sec\nEpoch 2 data loading time: 17.9567 seconds\nBatch size: 64, Queue length: 625, Throughput: 34.81 batches/sec\nEpoch 3 data loading time: 17.8730 seconds\nBatch size: 64, Queue length: 625, Throughput: 34.97 batches/sec\nEpoch 4 data loading time: 17.7556 seconds\nBatch size: 64, Queue length: 625, Throughput: 35.20 batches/sec\nEpoch 5 data loading time: 29.9851 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.84 batches/sec\nEpoch 6 data loading time: 31.6596 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.74 batches/sec\nEpoch 7 data loading time: 31.6524 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.75 batches/sec\nEpoch 8 data loading time: 31.6525 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.75 batches/sec\nEpoch 9 data loading time: 31.6543 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.74 batches/sec\nEpoch 10 data loading time: 31.6545 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.74 batches/sec",
                "lineage": "7101"
            }
        ],
        "72": [],
        "73": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXX.py",
                "accuracy": 0.4286,
                "model_info": "Epoch 1 data loading time: 31.4344 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.88 batches/sec\nEpoch 2 data loading time: 14.7216 seconds\nBatch size: 64, Queue length: 625, Throughput: 42.45 batches/sec\nEpoch 3 data loading time: 13.6372 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.83 batches/sec\nEpoch 4 data loading time: 13.6491 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.79 batches/sec\nEpoch 5 data loading time: 13.6756 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.70 batches/sec\nEpoch 6 data loading time: 13.6846 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.67 batches/sec\nEpoch 7 data loading time: 13.6950 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.64 batches/sec\nEpoch 8 data loading time: 13.6944 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.64 batches/sec\nEpoch 9 data loading time: 13.6930 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.64 batches/sec\nEpoch 10 data loading time: 13.6984 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.63 batches/sec",
                "lineage": "7301"
            }
        ],
        "74": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15),\n        transforms.RandomAffine(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4065,
                "model_info": "Epoch 1 data loading time: 27.9935 seconds\nBatch size: 64, Queue length: 625, Throughput: 22.33 batches/sec\nEpoch 2 data loading time: 14.9600 seconds\nBatch size: 64, Queue length: 625, Throughput: 41.78 batches/sec\nEpoch 3 data loading time: 13.9168 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.91 batches/sec\nEpoch 4 data loading time: 13.9242 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.89 batches/sec\nEpoch 5 data loading time: 27.0796 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.08 batches/sec\nEpoch 6 data loading time: 32.1063 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.47 batches/sec\nEpoch 7 data loading time: 25.9899 seconds\nBatch size: 64, Queue length: 625, Throughput: 24.05 batches/sec\nEpoch 8 data loading time: 14.0553 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.47 batches/sec\nEpoch 9 data loading time: 13.9358 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.85 batches/sec\nEpoch 10 data loading time: 13.9447 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.82 batches/sec",
                "lineage": "7401"
            }
        ],
        "75": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    early_stopping_counter = 0\n    best_val_loss = float('inf')\n\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            val_preds = model(val_tensor)\n            val_loss = criterion(val_preds, torch.tensor(train_label[:val_tensor.size(0)]).long().to(device)).item()\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            early_stopping_counter = 0\n        else:\n            early_stopping_counter += 1\n\n        if early_stopping_counter > 2:\n            break\n\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.3821,
                "model_info": "Epoch 1 data loading time: 32.9686 seconds\nBatch size: 64, Queue length: 625, Throughput: 18.96 batches/sec\nEpoch 2 data loading time: 21.6550 seconds\nBatch size: 64, Queue length: 625, Throughput: 28.86 batches/sec\nEpoch 3 data loading time: 14.4056 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.39 batches/sec",
                "lineage": "7501"
            }
        ],
        "76": [],
        "77": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = nn.Sequential(\n                nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n                nn.AdaptiveAvgPool2d((1, 1))\n            )\n            self.fc = nn.Linear(64, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.0122,
                "model_info": "Epoch 1 data loading time: 3.1228 seconds\nBatch size: 64, Queue length: 625, Throughput: 200.14 batches/sec\nEpoch 2 data loading time: 1.3605 seconds\nBatch size: 64, Queue length: 625, Throughput: 459.40 batches/sec\nEpoch 3 data loading time: 1.2185 seconds\nBatch size: 64, Queue length: 625, Throughput: 512.92 batches/sec\nEpoch 4 data loading time: 1.2178 seconds\nBatch size: 64, Queue length: 625, Throughput: 513.21 batches/sec\nEpoch 5 data loading time: 1.2181 seconds\nBatch size: 64, Queue length: 625, Throughput: 513.10 batches/sec\nEpoch 6 data loading time: 1.2165 seconds\nBatch size: 64, Queue length: 625, Throughput: 513.77 batches/sec\nEpoch 7 data loading time: 1.2194 seconds\nBatch size: 64, Queue length: 625, Throughput: 512.53 batches/sec\nEpoch 8 data loading time: 1.2181 seconds\nBatch size: 64, Queue length: 625, Throughput: 513.07 batches/sec\nEpoch 9 data loading time: 1.2163 seconds\nBatch size: 64, Queue length: 625, Throughput: 513.85 batches/sec\nEpoch 10 data loading time: 1.2186 seconds\nBatch size: 64, Queue length: 625, Throughput: 512.88 batches/sec",
                "lineage": "7701"
            }
        ],
        "78": [],
        "79": [],
        "80": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15),\n        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4156,
                "model_info": "Epoch 1 data loading time: 32.4358 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.27 batches/sec\nEpoch 2 data loading time: 31.9843 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.54 batches/sec\nEpoch 3 data loading time: 32.0685 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.49 batches/sec\nEpoch 4 data loading time: 32.0823 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.48 batches/sec\nEpoch 5 data loading time: 32.1317 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.45 batches/sec\nEpoch 6 data loading time: 32.1542 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.44 batches/sec\nEpoch 7 data loading time: 32.1584 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.43 batches/sec\nEpoch 8 data loading time: 32.1473 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.44 batches/sec\nEpoch 9 data loading time: 32.1324 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.45 batches/sec\nEpoch 10 data loading time: 32.1459 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.44 batches/sec",
                "lineage": "8001"
            }
        ],
        "81": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15),\n        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))  # Adding RandomAffine\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4023,
                "model_info": "Epoch 1 data loading time: 32.2609 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.37 batches/sec\nEpoch 2 data loading time: 31.6543 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.74 batches/sec\nEpoch 3 data loading time: 31.6395 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.75 batches/sec\nEpoch 4 data loading time: 31.6406 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.75 batches/sec\nEpoch 5 data loading time: 31.6265 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 6 data loading time: 31.6217 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 7 data loading time: 31.6137 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 8 data loading time: 31.6465 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.75 batches/sec\nEpoch 9 data loading time: 31.6386 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.75 batches/sec\nEpoch 10 data loading time: 31.6086 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec",
                "lineage": "8101"
            }
        ],
        "82": [],
        "83": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = []\n        for i in range(0, val_tensor.size(0), batch_size):\n            batch = val_tensor[i:i + batch_size]\n            preds = torch.argmax(model(batch), dim=1).cpu().numpy()\n            val_preds.extend(preds)\n    \n    return val_preds",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4227,
                "model_info": "Epoch 1 data loading time: 32.1710 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.43 batches/sec\nEpoch 2 data loading time: 31.6233 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 3 data loading time: 26.2244 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.83 batches/sec\nEpoch 4 data loading time: 13.8420 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.15 batches/sec\nEpoch 5 data loading time: 13.5497 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.13 batches/sec\nEpoch 6 data loading time: 13.5820 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.02 batches/sec\nEpoch 7 data loading time: 13.5829 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.01 batches/sec\nEpoch 8 data loading time: 13.5850 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.01 batches/sec\nEpoch 9 data loading time: 13.5937 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.98 batches/sec\nEpoch 10 data loading time: 13.5960 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.97 batches/sec",
                "lineage": "8301"
            }
        ],
        "84": [],
        "85": [],
        "86": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n        transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0))\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n            for param in self.base_model.parameters():\n                param.requires_grad = False\n            for param in self.fc.parameters():\n                param.requires_grad = True\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    print(\"Frozen layers:\", [name for name, param in model.named_parameters() if not param.requires_grad])\n    print(\"Trainable layers:\", [name for name, param in model.named_parameters() if param.requires_grad])\n\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXXX.py",
                "accuracy": 0.0037,
                "model_info": "Frozen layers: ['base_model.conv1.weight', 'base_model.bn1.weight', 'base_model.bn1.bias', 'base_model.layer1.0.conv1.weight', 'base_model.layer1.0.bn1.weight', 'base_model.layer1.0.bn1.bias', 'base_model.layer1.0.conv2.weight', 'base_model.layer1.0.bn2.weight', 'base_model.layer1.0.bn2.bias', 'base_model.layer1.0.conv3.weight', 'base_model.layer1.0.bn3.weight', 'base_model.layer1.0.bn3.bias', 'base_model.layer1.0.downsample.0.weight', 'base_model.layer1.0.downsample.1.weight', 'base_model.layer1.0.downsample.1.bias', 'base_model.layer1.1.conv1.weight', 'base_model.layer1.1.bn1.weight', 'base_model.layer1.1.bn1.bias', 'base_model.layer1.1.conv2.weight', 'base_model.layer1.1.bn2.weight', 'base_model.layer1.1.bn2.bias', 'base_model.layer1.1.conv3.weight', 'base_model.layer1.1.bn3.weight', 'base_model.layer1.1.bn3.bias', 'base_model.layer1.2.conv1.weight', 'base_model.layer1.2.bn1.weight', 'base_model.layer1.2.bn1.bias', 'base_model.layer1.2.conv2.weight', 'base_model.layer1.2.bn2.weight', 'base_model.layer1.2.bn2.bias', 'base_model.layer1.2.conv3.weight', 'base_model.layer1.2.bn3.weight', 'base_model.layer1.2.bn3.bias', 'base_model.layer2.0.conv1.weight', 'base_model.layer2.0.bn1.weight', 'base_model.layer2.0.bn1.bias', 'base_model.layer2.0.conv2.weight', 'base_model.layer2.0.bn2.weight', 'base_model.layer2.0.bn2.bias', 'base_model.layer2.0.conv3.weight', 'base_model.layer2.0.bn3.weight', 'base_model.layer2.0.bn3.bias', 'base_model.layer2.0.downsample.0.weight', 'base_model.layer2.0.downsample.1.weight', 'base_model.layer2.0.downsample.1.bias', 'base_model.layer2.1.conv1.weight', 'base_model.layer2.1.bn1.weight', 'base_model.layer2.1.bn1.bias', 'base_model.layer2.1.conv2.weight', 'base_model.layer2.1.bn2.weight', 'base_model.layer2.1.bn2.bias', 'base_model.layer2.1.conv3.weight', 'base_model.layer2.1.bn3.weight', 'base_model.layer2.1.bn3.bias', 'base_model.layer2.2.conv1.weight', 'base_model.layer2.2.bn1.weight', 'base_model.layer2.2.bn1.bias', 'base_model.layer2.2.co",
                "lineage": "8601"
            }
        ],
        "87": [],
        "88": [],
        "89": [],
        "90": [],
        "91": [],
        "92": [],
        "93": [],
        "94": [],
        "95": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    print(\"Assumed feature ranges: Input images should be in the range [0, 1] and of shape (C, H, W) where C=3, H=224, W=224.\")\n    print(\"Model-specific assumptions: Non-linearity assumed in the model architecture, homoscedasticity assumed in loss function.\")\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4192,
                "model_info": "Assumed feature ranges: Input images should be in the range [0, 1] and of shape (C, H, W) where C=3, H=224, W=224.\nModel-specific assumptions: Non-linearity assumed in the model architecture, homoscedasticity assumed in loss function.\nEpoch 1 data loading time: 26.1406 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.91 batches/sec\nEpoch 2 data loading time: 22.7970 seconds\nBatch size: 64, Queue length: 625, Throughput: 27.42 batches/sec\nEpoch 3 data loading time: 31.1467 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.07 batches/sec\nEpoch 4 data loading time: 31.4758 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.86 batches/sec\nEpoch 5 data loading time: 30.5373 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.47 batches/sec\nEpoch 6 data loading time: 30.5052 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.49 batches/sec\nEpoch 7 data loading time: 26.4546 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.63 batches/sec\nEpoch 8 data loading time: 14.5288 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.02 batches/sec\nEpoch 9 data loading time: 13.7342 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.51 batches/sec\nEpoch 10 data loading time: 13.7445 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.47 batches/sec",
                "lineage": "9501"
            }
        ],
        "96": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4011,
                "model_info": "Epoch 1 data loading time: 26.0780 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.97 batches/sec\nEpoch 2 data loading time: 14.8338 seconds\nBatch size: 64, Queue length: 625, Throughput: 42.13 batches/sec\nEpoch 3 data loading time: 13.5664 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.07 batches/sec\nEpoch 4 data loading time: 13.5711 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.05 batches/sec\nEpoch 5 data loading time: 13.5804 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.02 batches/sec\nEpoch 6 data loading time: 13.5904 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.99 batches/sec\nEpoch 7 data loading time: 13.5922 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.98 batches/sec\nEpoch 8 data loading time: 22.3381 seconds\nBatch size: 64, Queue length: 625, Throughput: 27.98 batches/sec\nEpoch 9 data loading time: 27.0301 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.12 batches/sec\nEpoch 10 data loading time: 22.2015 seconds\nBatch size: 64, Queue length: 625, Throughput: 28.15 batches/sec",
                "lineage": "9601"
            }
        ],
        "97": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            for param in self.base_model.parameters():\n                param.requires_grad = False\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    for param in model.base_model.parameters():\n        param.requires_grad = True\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.1017,
                "model_info": "Epoch 1 data loading time: 5.9504 seconds\nBatch size: 64, Queue length: 625, Throughput: 105.03 batches/sec\nEpoch 2 data loading time: 4.4255 seconds\nBatch size: 64, Queue length: 625, Throughput: 141.23 batches/sec\nEpoch 3 data loading time: 4.3919 seconds\nBatch size: 64, Queue length: 625, Throughput: 142.31 batches/sec\nEpoch 4 data loading time: 4.3937 seconds\nBatch size: 64, Queue length: 625, Throughput: 142.25 batches/sec\nEpoch 5 data loading time: 4.3913 seconds\nBatch size: 64, Queue length: 625, Throughput: 142.33 batches/sec\nEpoch 6 data loading time: 4.3858 seconds\nBatch size: 64, Queue length: 625, Throughput: 142.50 batches/sec\nEpoch 7 data loading time: 4.3921 seconds\nBatch size: 64, Queue length: 625, Throughput: 142.30 batches/sec\nEpoch 8 data loading time: 4.3792 seconds\nBatch size: 64, Queue length: 625, Throughput: 142.72 batches/sec\nEpoch 9 data loading time: 4.3923 seconds\nBatch size: 64, Queue length: 625, Throughput: 142.30 batches/sec\nEpoch 10 data loading time: 4.4601 seconds\nBatch size: 64, Queue length: 625, Throughput: 140.13 batches/sec",
                "lineage": "9701"
            }
        ],
        "98": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            return self.base_model(x)\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4001,
                "model_info": "Epoch 1 data loading time: 31.6786 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.73 batches/sec\nEpoch 2 data loading time: 14.5846 seconds\nBatch size: 64, Queue length: 625, Throughput: 42.85 batches/sec\nEpoch 3 data loading time: 13.5812 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.02 batches/sec\nEpoch 4 data loading time: 25.2154 seconds\nBatch size: 64, Queue length: 625, Throughput: 24.79 batches/sec\nEpoch 5 data loading time: 21.9787 seconds\nBatch size: 64, Queue length: 625, Throughput: 28.44 batches/sec\nEpoch 6 data loading time: 27.6717 seconds\nBatch size: 64, Queue length: 625, Throughput: 22.59 batches/sec\nEpoch 7 data loading time: 31.3621 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.93 batches/sec\nEpoch 8 data loading time: 29.9697 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.85 batches/sec\nEpoch 9 data loading time: 28.5257 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.91 batches/sec\nEpoch 10 data loading time: 30.4962 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.49 batches/sec",
                "lineage": "9801"
            }
        ],
        "99": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    val_loader = DataLoader(TensorDataset(val_tensor), batch_size=batch_size, shuffle=False)\n    val_preds = []\n    with torch.no_grad():\n        for inputs in val_loader:\n            outputs = model(inputs[0])\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            val_preds.extend(preds)\n    \n    return val_preds",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4238,
                "model_info": "Epoch 1 data loading time: 31.8437 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.63 batches/sec\nEpoch 2 data loading time: 29.8896 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.91 batches/sec\nEpoch 3 data loading time: 30.9080 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.22 batches/sec\nEpoch 4 data loading time: 29.5035 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.18 batches/sec\nEpoch 5 data loading time: 14.4435 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.27 batches/sec\nEpoch 6 data loading time: 13.7505 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.45 batches/sec\nEpoch 7 data loading time: 13.7609 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.42 batches/sec\nEpoch 8 data loading time: 29.3355 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.31 batches/sec\nEpoch 9 data loading time: 29.2174 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.39 batches/sec\nEpoch 10 data loading time: 14.0148 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.60 batches/sec",
                "lineage": "9901"
            }
        ],
        "100": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    for param in model.base_model.parameters():\n        param.requires_grad = True\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.403,
                "model_info": "Epoch 1 data loading time: 24.8593 seconds\nBatch size: 64, Queue length: 625, Throughput: 25.14 batches/sec\nEpoch 2 data loading time: 23.8849 seconds\nBatch size: 64, Queue length: 625, Throughput: 26.17 batches/sec\nEpoch 3 data loading time: 13.7664 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.40 batches/sec\nEpoch 4 data loading time: 13.5637 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.08 batches/sec\nEpoch 5 data loading time: 18.8298 seconds\nBatch size: 64, Queue length: 625, Throughput: 33.19 batches/sec\nEpoch 6 data loading time: 17.6556 seconds\nBatch size: 64, Queue length: 625, Throughput: 35.40 batches/sec\nEpoch 7 data loading time: 31.4022 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.90 batches/sec\nEpoch 8 data loading time: 31.4662 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.86 batches/sec\nEpoch 9 data loading time: 16.0497 seconds\nBatch size: 64, Queue length: 625, Throughput: 38.94 batches/sec\nEpoch 10 data loading time: 16.7668 seconds\nBatch size: 64, Queue length: 625, Throughput: 37.28 batches/sec",
                "lineage": "10001"
            }
        ],
        "101": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.3322,
                "model_info": "Epoch 1 data loading time: 32.4170 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.28 batches/sec\nEpoch 2 data loading time: 31.5189 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.83 batches/sec\nEpoch 3 data loading time: 17.3611 seconds\nBatch size: 64, Queue length: 625, Throughput: 36.00 batches/sec\nEpoch 4 data loading time: 14.1604 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.14 batches/sec\nEpoch 5 data loading time: 14.1782 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.08 batches/sec\nEpoch 6 data loading time: 14.1827 seconds\nBatch size: 64, Queue length: 625, Throughput: 44.07 batches/sec\nEpoch 7 data loading time: 21.6281 seconds\nBatch size: 64, Queue length: 625, Throughput: 28.90 batches/sec\nEpoch 8 data loading time: 31.5321 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.82 batches/sec\nEpoch 9 data loading time: 29.4713 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.21 batches/sec\nEpoch 10 data loading time: 28.6759 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.80 batches/sec",
                "lineage": "10101"
            }
        ],
        "102": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n        print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4176,
                "model_info": "Epoch 1 data loading time: 29.8899 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.91 batches/sec\nLearning rate: 0.0001\nEpoch 2 data loading time: 31.0333 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.14 batches/sec\nLearning rate: 0.0001\nEpoch 3 data loading time: 27.2880 seconds\nBatch size: 64, Queue length: 625, Throughput: 22.90 batches/sec\nLearning rate: 0.0001\nEpoch 4 data loading time: 14.5234 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.03 batches/sec\nLearning rate: 0.0001\nEpoch 5 data loading time: 15.7055 seconds\nBatch size: 64, Queue length: 625, Throughput: 39.79 batches/sec\nLearning rate: 0.0001\nEpoch 6 data loading time: 31.2174 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.02 batches/sec\nLearning rate: 0.0001\nEpoch 7 data loading time: 31.1577 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.06 batches/sec\nLearning rate: 0.0001\nEpoch 8 data loading time: 15.1667 seconds\nBatch size: 64, Queue length: 625, Throughput: 41.21 batches/sec\nLearning rate: 0.0001\nEpoch 9 data loading time: 13.5796 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.02 batches/sec\nLearning rate: 0.0001\nEpoch 10 data loading time: 13.6074 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.93 batches/sec\nLearning rate: 0.0001",
                "lineage": "10201"
            }
        ],
        "103": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4142,
                "model_info": "Epoch 1 data loading time: 30.4512 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.52 batches/sec\nEpoch 2 data loading time: 30.5655 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.45 batches/sec\nEpoch 3 data loading time: 31.0855 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.11 batches/sec\nEpoch 4 data loading time: 31.1399 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.07 batches/sec\nEpoch 5 data loading time: 29.5491 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.15 batches/sec\nEpoch 6 data loading time: 29.3359 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.30 batches/sec\nEpoch 7 data loading time: 31.7551 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.68 batches/sec\nEpoch 8 data loading time: 28.2155 seconds\nBatch size: 64, Queue length: 625, Throughput: 22.15 batches/sec\nEpoch 9 data loading time: 21.2114 seconds\nBatch size: 64, Queue length: 625, Throughput: 29.47 batches/sec\nEpoch 10 data loading time: 31.4667 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.86 batches/sec",
                "lineage": "10301"
            }
        ],
        "104": [],
        "105": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.3578,
                "model_info": "Epoch 1 data loading time: 32.8848 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.01 batches/sec\nEpoch 2 data loading time: 20.8719 seconds\nBatch size: 64, Queue length: 625, Throughput: 29.94 batches/sec\nEpoch 3 data loading time: 31.3165 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.96 batches/sec\nEpoch 4 data loading time: 31.7538 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.68 batches/sec\nEpoch 5 data loading time: 19.6560 seconds\nBatch size: 64, Queue length: 625, Throughput: 31.80 batches/sec\nEpoch 6 data loading time: 19.0123 seconds\nBatch size: 64, Queue length: 625, Throughput: 32.87 batches/sec\nEpoch 7 data loading time: 18.9956 seconds\nBatch size: 64, Queue length: 625, Throughput: 32.90 batches/sec\nEpoch 8 data loading time: 22.5763 seconds\nBatch size: 64, Queue length: 625, Throughput: 27.68 batches/sec\nEpoch 9 data loading time: 19.0081 seconds\nBatch size: 64, Queue length: 625, Throughput: 32.88 batches/sec\nEpoch 10 data loading time: 19.0009 seconds\nBatch size: 64, Queue length: 625, Throughput: 32.89 batches/sec",
                "lineage": "10501"
            }
        ],
        "106": [],
        "107": [],
        "108": [],
        "109": [],
        "110": [],
        "111": [],
        "112": [],
        "113": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_counts = torch.bincount(label_tensor)\n    class_weights = 1.0 / class_counts.float()\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4063,
                "model_info": "Epoch 1 data loading time: 20.2929 seconds\nBatch size: 64, Queue length: 625, Throughput: 30.80 batches/sec\nEpoch 2 data loading time: 15.0847 seconds\nBatch size: 64, Queue length: 625, Throughput: 41.43 batches/sec\nEpoch 3 data loading time: 15.3431 seconds\nBatch size: 64, Queue length: 625, Throughput: 40.73 batches/sec\nEpoch 4 data loading time: 13.6011 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.95 batches/sec\nEpoch 5 data loading time: 13.6125 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.91 batches/sec\nEpoch 6 data loading time: 13.6316 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.85 batches/sec\nEpoch 7 data loading time: 14.3455 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.57 batches/sec\nEpoch 8 data loading time: 19.9263 seconds\nBatch size: 64, Queue length: 625, Throughput: 31.37 batches/sec\nEpoch 9 data loading time: 30.9585 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.19 batches/sec\nEpoch 10 data loading time: 27.6737 seconds\nBatch size: 64, Queue length: 625, Throughput: 22.58 batches/sec",
                "lineage": "11301"
            }
        ],
        "114": [],
        "115": [],
        "116": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    val_loader = DataLoader(TensorDataset(val_tensor), batch_size=batch_size, shuffle=False)\n    val_preds = []\n    with torch.no_grad():\n        for inputs in val_loader:\n            outputs = model(inputs[0])\n            val_preds.append(torch.argmax(outputs, dim=1).cpu().numpy())\n    val_preds = np.concatenate(val_preds)\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4215,
                "model_info": "Epoch 1 data loading time: 31.0140 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.15 batches/sec\nEpoch 2 data loading time: 27.0170 seconds\nBatch size: 64, Queue length: 625, Throughput: 23.13 batches/sec\nEpoch 3 data loading time: 13.6720 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.71 batches/sec\nEpoch 4 data loading time: 13.5818 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.02 batches/sec\nEpoch 5 data loading time: 13.8615 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.09 batches/sec\nEpoch 6 data loading time: 30.9799 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.17 batches/sec\nEpoch 7 data loading time: 31.3649 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.93 batches/sec\nEpoch 8 data loading time: 31.3506 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.94 batches/sec\nEpoch 9 data loading time: 31.5737 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.79 batches/sec\nEpoch 10 data loading time: 24.2437 seconds\nBatch size: 64, Queue length: 625, Throughput: 25.78 batches/sec",
                "lineage": "11601"
            }
        ],
        "117": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\nfrom sklearn.utils import class_weight\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_label), y=train_label)\n    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4194,
                "model_info": "Epoch 1 data loading time: 31.1250 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.08 batches/sec\nEpoch 2 data loading time: 24.5551 seconds\nBatch size: 64, Queue length: 625, Throughput: 25.45 batches/sec\nEpoch 3 data loading time: 20.1337 seconds\nBatch size: 64, Queue length: 625, Throughput: 31.04 batches/sec\nEpoch 4 data loading time: 30.9933 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.17 batches/sec\nEpoch 5 data loading time: 17.4052 seconds\nBatch size: 64, Queue length: 625, Throughput: 35.91 batches/sec\nEpoch 6 data loading time: 31.3043 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.97 batches/sec\nEpoch 7 data loading time: 31.5318 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.82 batches/sec\nEpoch 8 data loading time: 31.4907 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.85 batches/sec\nEpoch 9 data loading time: 30.8879 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.23 batches/sec\nEpoch 10 data loading time: 31.3097 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.96 batches/sec",
                "lineage": "11701"
            }
        ],
        "118": [],
        "119": [],
        "120": [],
        "121": [],
        "122": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15),\n        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.2141,
                "model_info": "Epoch 1 data loading time: 32.2193 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.40 batches/sec\nEpoch 2 data loading time: 15.0727 seconds\nBatch size: 64, Queue length: 625, Throughput: 41.47 batches/sec\nEpoch 3 data loading time: 13.8484 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.13 batches/sec\nEpoch 4 data loading time: 13.8297 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.19 batches/sec\nEpoch 5 data loading time: 15.2888 seconds\nBatch size: 64, Queue length: 625, Throughput: 40.88 batches/sec\nEpoch 6 data loading time: 19.1228 seconds\nBatch size: 64, Queue length: 625, Throughput: 32.68 batches/sec\nEpoch 7 data loading time: 13.8657 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.07 batches/sec\nEpoch 8 data loading time: 13.8752 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.04 batches/sec\nEpoch 9 data loading time: 13.8715 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.06 batches/sec\nEpoch 10 data loading time: 13.8790 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.03 batches/sec",
                "lineage": "12201"
            }
        ],
        "123": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.3918,
                "model_info": "Epoch 1 data loading time: 31.7729 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.67 batches/sec\nEpoch 2 data loading time: 31.9250 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.58 batches/sec\nEpoch 3 data loading time: 31.6581 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.74 batches/sec\nEpoch 4 data loading time: 31.6914 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.72 batches/sec\nEpoch 5 data loading time: 31.1370 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.07 batches/sec\nEpoch 6 data loading time: 31.6570 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.74 batches/sec\nEpoch 7 data loading time: 18.9610 seconds\nBatch size: 64, Queue length: 625, Throughput: 32.96 batches/sec\nEpoch 8 data loading time: 21.0944 seconds\nBatch size: 64, Queue length: 625, Throughput: 29.63 batches/sec\nEpoch 9 data loading time: 31.5493 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.81 batches/sec\nEpoch 10 data loading time: 19.9502 seconds\nBatch size: 64, Queue length: 625, Throughput: 31.33 batches/sec",
                "lineage": "12301"
            }
        ],
        "124": [],
        "125": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_counts = torch.bincount(label_tensor)\n    class_weights = 1.0 / class_counts.float()\n    class_weights = class_weights / class_weights.sum() * len(class_counts)\n    criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4262,
                "model_info": "Epoch 1 data loading time: 31.7945 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.66 batches/sec\nEpoch 2 data loading time: 31.4970 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.84 batches/sec\nEpoch 3 data loading time: 30.7706 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.31 batches/sec\nEpoch 4 data loading time: 25.2012 seconds\nBatch size: 64, Queue length: 625, Throughput: 24.80 batches/sec\nEpoch 5 data loading time: 29.4902 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.19 batches/sec\nEpoch 6 data loading time: 30.7839 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.30 batches/sec\nEpoch 7 data loading time: 31.6545 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.74 batches/sec\nEpoch 8 data loading time: 30.9367 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.20 batches/sec\nEpoch 9 data loading time: 31.1458 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.07 batches/sec\nEpoch 10 data loading time: 31.7513 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.68 batches/sec",
                "lineage": "12501"
            }
        ],
        "126": [],
        "127": [],
        "128": [],
        "129": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).float().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, 1)\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels.view(-1, 1))\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        val_preds = torch.sigmoid(val_outputs).cpu().numpy()\n    \n    return (val_preds > 0.5).astype(int).tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.0002,
                "model_info": "Epoch 1 data loading time: 31.4924 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.85 batches/sec\nEpoch 2 data loading time: 17.7311 seconds\nBatch size: 64, Queue length: 625, Throughput: 35.25 batches/sec\nEpoch 3 data loading time: 13.5830 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.01 batches/sec\nEpoch 4 data loading time: 17.1400 seconds\nBatch size: 64, Queue length: 625, Throughput: 36.46 batches/sec\nEpoch 5 data loading time: 14.3552 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.54 batches/sec\nEpoch 6 data loading time: 13.5796 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.02 batches/sec\nEpoch 7 data loading time: 13.5922 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.98 batches/sec\nEpoch 8 data loading time: 13.6105 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.92 batches/sec\nEpoch 9 data loading time: 22.8891 seconds\nBatch size: 64, Queue length: 625, Throughput: 27.31 batches/sec\nEpoch 10 data loading time: 29.6268 seconds\nBatch size: 64, Queue length: 625, Throughput: 21.10 batches/sec",
                "lineage": "12901"
            }
        ],
        "130": [],
        "131": [],
        "132": [],
        "133": [],
        "134": [],
        "135": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    for param in model.base_model.parameters():\n        param.requires_grad = False\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4031,
                "model_info": "Epoch 1 data loading time: 32.6219 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.16 batches/sec\nEpoch 2 data loading time: 31.8349 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.63 batches/sec\nEpoch 3 data loading time: 14.8706 seconds\nBatch size: 64, Queue length: 625, Throughput: 42.03 batches/sec\nEpoch 4 data loading time: 13.6655 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.74 batches/sec\nEpoch 5 data loading time: 13.6500 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.79 batches/sec\nEpoch 6 data loading time: 25.6885 seconds\nBatch size: 64, Queue length: 625, Throughput: 24.33 batches/sec\nEpoch 7 data loading time: 32.1112 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.46 batches/sec\nEpoch 8 data loading time: 32.0940 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.47 batches/sec\nEpoch 9 data loading time: 32.1658 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.43 batches/sec\nEpoch 10 data loading time: 32.0931 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.47 batches/sec",
                "lineage": "13501"
            }
        ],
        "136": [],
        "137": [],
        "138": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n        transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0))\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.3184,
                "model_info": "Epoch 1 data loading time: 32.4274 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.27 batches/sec\nEpoch 2 data loading time: 31.5891 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.79 batches/sec\nEpoch 3 data loading time: 31.6138 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 4 data loading time: 17.3400 seconds\nBatch size: 64, Queue length: 625, Throughput: 36.04 batches/sec\nEpoch 5 data loading time: 14.4630 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.21 batches/sec\nEpoch 6 data loading time: 14.4697 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.19 batches/sec\nEpoch 7 data loading time: 14.4772 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.17 batches/sec\nEpoch 8 data loading time: 14.4857 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.15 batches/sec\nEpoch 9 data loading time: 14.4877 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.14 batches/sec\nEpoch 10 data loading time: 14.4909 seconds\nBatch size: 64, Queue length: 625, Throughput: 43.13 batches/sec",
                "lineage": "13801"
            }
        ],
        "139": [],
        "140": [],
        "141": [],
        "142": [],
        "143": [],
        "144": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.349,
                "model_info": "Epoch 1 data loading time: 31.9738 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.55 batches/sec\nEpoch 2 data loading time: 31.4071 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.90 batches/sec\nEpoch 3 data loading time: 31.0839 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.11 batches/sec\nEpoch 4 data loading time: 17.9793 seconds\nBatch size: 64, Queue length: 625, Throughput: 34.76 batches/sec\nEpoch 5 data loading time: 15.4279 seconds\nBatch size: 64, Queue length: 625, Throughput: 40.51 batches/sec\nEpoch 6 data loading time: 15.4342 seconds\nBatch size: 64, Queue length: 625, Throughput: 40.49 batches/sec\nEpoch 7 data loading time: 15.4256 seconds\nBatch size: 64, Queue length: 625, Throughput: 40.52 batches/sec\nEpoch 8 data loading time: 15.4263 seconds\nBatch size: 64, Queue length: 625, Throughput: 40.52 batches/sec\nEpoch 9 data loading time: 15.4301 seconds\nBatch size: 64, Queue length: 625, Throughput: 40.51 batches/sec\nEpoch 10 data loading time: 15.4444 seconds\nBatch size: 64, Queue length: 625, Throughput: 40.47 batches/sec",
                "lineage": "14401"
            }
        ],
        "145": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\nfrom collections import Counter\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    label_distribution = Counter(train_label)\n    print(f\"Label distribution: {dict(label_distribution)}\")\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4213,
                "model_info": "Label distribution: {66: 403, 87: 397, 56: 394, 33: 390, 73: 407, 76: 393, 58: 402, 12: 411, 34: 394, 84: 391, 69: 415, 18: 382, 35: 397, 22: 400, 67: 410, 47: 396, 39: 405, 5: 405, 7: 390, 19: 415, 6: 401, 61: 411, 36: 396, 93: 409, 94: 392, 50: 394, 23: 409, 13: 393, 97: 409, 45: 400, 80: 399, 92: 382, 38: 391, 29: 416, 64: 419, 88: 390, 90: 382, 68: 410, 27: 390, 86: 390, 11: 393, 57: 419, 71: 399, 99: 405, 79: 386, 70: 399, 25: 403, 59: 400, 95: 395, 4: 408, 1: 397, 9: 408, 20: 389, 8: 401, 40: 396, 49: 407, 28: 399, 26: 404, 3: 407, 83: 399, 17: 404, 10: 408, 82: 403, 0: 410, 37: 399, 21: 382, 53: 403, 32: 418, 16: 399, 42: 399, 48: 396, 44: 414, 65: 390, 41: 423, 78: 403, 60: 426, 74: 411, 62: 388, 43: 408, 75: 390, 2: 414, 96: 384, 55: 395, 63: 411, 14: 410, 15: 381, 51: 396, 98: 406, 24: 397, 77: 403, 85: 392, 46: 389, 89: 400, 52: 388, 30: 387, 72: 405, 54: 391, 81: 393, 31: 401, 91: 389}\nEpoch 1 data loading time: 32.2549 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.38 batches/sec\nEpoch 2 data loading time: 31.6326 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 3 data loading time: 31.6141 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 4 data loading time: 31.6271 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 5 data loading time: 31.5945 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.78 batches/sec\nEpoch 6 data loading time: 31.6359 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 7 data loading time: 31.6122 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 8 data loading time: 31.6224 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 9 data loading time: 31.6386 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.75 batches/sec\nEpoch 10 data loading time: 31.6138 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec",
                "lineage": "14501"
            }
        ],
        "146": [],
        "147": [],
        "148": [],
        "149": [],
        "150": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = []\n        val_loader = DataLoader(val_tensor, batch_size=batch_size, shuffle=False)\n        for val_inputs in val_loader:\n            val_outputs = model(val_inputs.to(device))\n            val_preds.append(torch.argmax(val_outputs, dim=1).cpu().numpy())\n    \n    return np.concatenate(val_preds).tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4168,
                "model_info": "Epoch 1 data loading time: 32.2242 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.40 batches/sec\nEpoch 2 data loading time: 31.6208 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 3 data loading time: 31.5433 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.81 batches/sec\nEpoch 4 data loading time: 30.8154 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.28 batches/sec\nEpoch 5 data loading time: 30.3826 seconds\nBatch size: 64, Queue length: 625, Throughput: 20.57 batches/sec\nEpoch 6 data loading time: 31.6110 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 7 data loading time: 31.6188 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 8 data loading time: 31.6445 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.75 batches/sec\nEpoch 9 data loading time: 31.6279 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 10 data loading time: 31.6544 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.74 batches/sec",
                "lineage": "15001"
            }
        ],
        "151": [],
        "152": [],
        "153": [],
        "154": [],
        "155": [],
        "156": [],
        "157": [],
        "158": [],
        "159": [],
        "160": [],
        "161": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n            self.fc = nn.Linear(self.base_model.fc.out_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            x = x.view(x.size(0), -1)\n            x = self.fc(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    class_weights = torch.tensor([1.0] * len(set(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss() \n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4168,
                "model_info": "Epoch 1 data loading time: 32.2180 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.40 batches/sec\nEpoch 2 data loading time: 31.5582 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.80 batches/sec\nEpoch 3 data loading time: 31.6364 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 4 data loading time: 31.6227 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 5 data loading time: 31.5309 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.82 batches/sec\nEpoch 6 data loading time: 31.6092 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 7 data loading time: 31.6134 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 8 data loading time: 31.6435 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.75 batches/sec\nEpoch 9 data loading time: 31.6298 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec\nEpoch 10 data loading time: 31.6332 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.76 batches/sec",
                "lineage": "16101"
            }
        ],
        "162": [],
        "163": [],
        "164": [],
        "165": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport time\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=64, input_size=224):\n    train_tensor = torch.tensor(train_data).float().to(device)\n    label_tensor = torch.tensor(train_label).long().to(device)\n    val_tensor = torch.tensor(val_data).float().to(device)\n\n    train_dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    domain_specific_augmentations = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(degrees=15)\n    ])\n\n    class SphericalResNet(nn.Module):\n        def __init__(self):\n            super(SphericalResNet, self).__init__()\n            self.base_model = resnet50(weights='DEFAULT')\n            self.base_model.fc = nn.Linear(self.base_model.fc.in_features, len(set(train_label)))\n\n        def forward(self, x):\n            x = self.base_model(x)\n            return x\n\n    model = SphericalResNet().to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(10):\n        start_time = time.time()\n        for inputs, labels in train_loader:\n            inputs = domain_specific_augmentations(inputs)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch+1} data loading time: {time.time() - start_time:.4f} seconds\")\n        print(f\"Batch size: {len(inputs)}, Queue length: {len(train_loader)}, Throughput: {len(train_loader)/ (time.time() - start_time):.2f} batches/sec\")\n\n    model.eval()\n    with torch.no_grad():\n        val_preds = torch.argmax(model(val_tensor), dim=1).cpu().numpy()\n    \n    return val_preds.tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8294_transformer_based_moXXXXXXXXXXXXX.py",
                "accuracy": 0.4003,
                "model_info": "Epoch 1 data loading time: 32.2538 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.38 batches/sec\nEpoch 2 data loading time: 31.6178 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.77 batches/sec\nEpoch 3 data loading time: 31.5883 seconds\nBatch size: 64, Queue length: 625, Throughput: 19.79 batches/sec\nEpoch 4 data loading time: 14.8924 seconds\nBatch size: 64, Queue length: 625, Throughput: 41.97 batches/sec\nEpoch 5 data loading time: 13.5631 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.08 batches/sec\nEpoch 6 data loading time: 13.5545 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.11 batches/sec\nEpoch 7 data loading time: 13.5622 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.08 batches/sec\nEpoch 8 data loading time: 13.5799 seconds\nBatch size: 64, Queue length: 625, Throughput: 46.02 batches/sec\nEpoch 9 data loading time: 13.5889 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.99 batches/sec\nEpoch 10 data loading time: 13.5940 seconds\nBatch size: 64, Queue length: 625, Throughput: 45.98 batches/sec",
                "lineage": "16501"
            }
        ],
        "166": [],
        "167": []
    },
    "1": {
        "2": [
            {
                "code": "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F\n\nclass SphericalCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(SphericalCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(64 * 30 * 30 // 4, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.int64).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = SphericalCNN(num_classes=len(np.unique(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, val_preds = torch.max(val_outputs, 1)\n\n    return val_preds.cpu().numpy().tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8292_recurrent_neural_netXXX.py",
                "accuracy": 0.1032,
                "model_info": "",
                "lineage": "211"
            }
        ],
        "3": [],
        "4": [
            {
                "code": "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F\n\nclass SphericalCNNWithAttention(nn.Module):\n    def __init__(self, num_classes):\n        super(SphericalCNNWithAttention, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(64 * 30 * 30 // 4, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n        self.attention = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        attention_weights = self.attention(x)\n        x = x * attention_weights\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1024):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.int64).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = SphericalCNNWithAttention(num_classes=len(np.unique(train_label))).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, val_preds = torch.max(val_outputs, 1)\n\n    return val_preds.cpu().numpy().tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/spherical_initial_8292_recurrent_neural_netXXXX.py",
                "accuracy": 0.1012,
                "model_info": "",
                "lineage": "411"
            }
        ]
    }
}