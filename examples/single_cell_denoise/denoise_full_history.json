{
    "0": {
        "0": [
            {
                "code": "import numpy as np\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    X = a.X.toarray() if hasattr(a.X, 'toarray') else a.X\n    mask = np.isnan(X) if isinstance(X, np.ndarray) and np.issubdtype(X.dtype, np.floating) else np.zeros(X.shape, dtype=bool)\n    X_filled = X.copy()\n    \n    for i in range(X.shape[1]):\n        if np.any(mask[:, i]):\n            knn = KNeighborsRegressor(n_neighbors=5)\n            knn.fit(np.arange(X.shape[0])[~mask[:, i]].reshape(-1, 1), X[~mask[:, i], i])\n            X_filled[mask[:, i], i] = knn.predict(np.arange(X.shape[0])[mask[:, i]].reshape(-1, 1))\n    \n    adata.obsm[\"denoised\"] = X_filled\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round10_k_nearest_neighbors_.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "denoise_tusoml_round10_k_nearest_neighbors_"
            }
        ],
        "1": [
            {
                "code": "import numpy as np\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    X = a.X.toarray() if hasattr(a.X, 'toarray') else a.X\n    mask = np.isnan(X) if isinstance(X, np.ndarray) and np.issubdtype(X.dtype, np.floating) else np.zeros(X.shape, dtype=bool)\n    X_filled = X.copy()\n    \n    dropout_rate = np.mean(mask, axis=0)\n    for i in range(X.shape[1]):\n        if np.any(mask[:, i]):\n            knn = KNeighborsRegressor(n_neighbors=5)\n            knn.fit(np.arange(X.shape[0])[~mask[:, i]].reshape(-1, 1), X[~mask[:, i], i])\n            X_filled[mask[:, i], i] = knn.predict(np.arange(X.shape[0])[mask[:, i]].reshape(-1, 1)) * (1 - dropout_rate[i])\n    \n    adata.obsm[\"denoised\"] = X_filled\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round10_k_nearest_neighbors_X.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "101"
            }
        ],
        "2": [
            {
                "code": "import numpy as np\nfrom anndata import AnnData\nfrom sklearn.decomposition import NMF\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(a.X.toarray())\n    H = model.components_\n    denoised_data = np.dot(W, H)\n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round16_scImputeX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "201"
            }
        ],
        "3": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n    denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "301"
            }
        ],
        "4": [
            {
                "code": "import numpy as np\nfrom anndata import AnnData\nfrom sklearn.preprocessing import normalize\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    if 'batch' in adata.obs.columns:\n        batch = adata.obs['batch'].values\n    else:\n        batch = None\n    \n    denoised_data = normalize(a.X.toarray(), axis=0)  \n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round16_scImputeX.py",
                "accuracy": 0.5117256022478074,
                "model_info": "",
                "lineage": "401"
            }
        ],
        "5": [],
        "6": [
            {
                "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.cluster import AgglomerativeClustering\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    distance_matrix = pairwise_distances(data)\n    clustering = AgglomerativeClustering(distance_threshold=0.5, n_clusters=None)\n    clusters = clustering.fit_predict(distance_matrix)\n    \n    denoised_data = np.zeros_like(data)\n    for cluster in np.unique(clusters):\n        cluster_data = data[clusters == cluster]\n        denoised_data[clusters == cluster] = np.mean(cluster_data, axis=0)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteX.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "601"
            }
        ],
        "7": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(data)\n    \n    if np.any(scaled_data < 0):\n        scaled_data = np.abs(scaled_data)\n    \n    model = NMF(n_components=30, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(scaled_data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    missing_counts = np.sum(adjusted_denoised_data == 0, axis=0)\n    print(\"Missing values per feature post-imputation:\", missing_counts)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.6084723497335325,
                "model_info": "Missing values per feature post-imputation: [0 1 1 ... 0 0 0]",
                "lineage": "701"
            }
        ],
        "8": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    X = a.X.toarray() if hasattr(a.X, 'toarray') else a.X\n    mask = np.isnan(X) if isinstance(X, np.ndarray) and np.issubdtype(X.dtype, np.floating) else np.zeros(X.shape, dtype=bool)\n    X_filled = np.maximum(X.copy(), 0)\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(X_filled)\n    H = model.components_\n    X_denoised = np.dot(W, H)\n    \n    for i in range(X.shape[1]):\n        if np.any(mask[:, i]):\n            X_filled[mask[:, i], i] = X_denoised[mask[:, i], i]\n    \n    noise = np.random.normal(0, 0.1, X_filled.shape)\n    X_filled_noisy = X_filled + noise\n    X_filled_noisy = np.maximum(X_filled_noisy, 0)\n\n    model_noisy = NMF(n_components=20, init='nndsvd', random_state=0)\n    W_noisy = model_noisy.fit_transform(X_filled_noisy)\n    H_noisy = model_noisy.components_\n    X_denoised_noisy = np.dot(W_noisy, H_noisy)\n    \n    for i in range(X.shape[1]):\n        if np.any(mask[:, i]):\n            X_filled[mask[:, i], i] = X_denoised_noisy[mask[:, i], i]\n    \n    adata.obsm[\"denoised\"] = X_filled\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round10_k_nearest_neighbors_XX.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "801"
            }
        ],
        "9": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n    \n    kmeans = KMeans(n_clusters=10, random_state=0)\n    kmeans.fit(adjusted_denoised_data)\n    \n    silhouette_avg = silhouette_score(adjusted_denoised_data, kmeans.labels_)\n    \n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data *= (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "901"
            }
        ],
        "10": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    if np.any(np.isnan(data)) or np.any(np.isinf(data)):\n        nan_count = np.sum(np.isnan(data))\n        inf_count = np.sum(np.isinf(data))\n        print(f\"NaN count: {nan_count}, Inf count: {inf_count}\")\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "1001"
            }
        ],
        "11": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    logging.info(\"Starting model optimization with hyper-parameter settings: n_components=20, init='nndsvd', random_state=0\")\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "1101"
            }
        ],
        "12": [],
        "13": [],
        "14": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    input_dim = data.shape[1]\n    encoded = np.maximum(0, np.dot(data, np.random.rand(input_dim, 64)))\n    residual = data + np.dot(encoded, np.random.rand(64, input_dim))\n    encoded = np.maximum(0, np.dot(residual, np.random.rand(input_dim, 32)))\n    decoded = np.maximum(0, np.dot(encoded, np.random.rand(32, 64)))\n    output_layer = np.dot(decoded, np.random.rand(64, input_dim))\n\n    adata.obsm[\"denoised\"] = output_layer\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.5785854350159192,
                "model_info": "",
                "lineage": "1401"
            }
        ],
        "15": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    print(f\"Data shape: {data.shape}, Data type: {data.dtype}\")\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Data shape: (1087, 15099), Data type: float64",
                "lineage": "1501"
            }
        ],
        "16": [],
        "17": [],
        "18": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "1801"
            }
        ],
        "19": [],
        "20": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import pairwise_distances\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    if 'batch' in a.obs.columns:\n        batch_labels = a.obs['batch'].values\n    else:\n        batch_labels = None\n    \n    combat_data = data\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(combat_data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(combat_data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "2001"
            }
        ],
        "21": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n\n    original_data = data[data != 0]\n    imputed_data = adjusted_denoised_data[data != 0]\n    mse = mean_squared_error(original_data, imputed_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "2101"
            }
        ],
        "22": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    data = imputer.fit_transform(data)\n    \n    data = np.maximum(data, 0)\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.5817670447253104,
                "model_info": "",
                "lineage": "2201"
            }
        ],
        "23": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n    \n    if 'cell_type' in adata.obs.columns:\n        n_clusters = len(adata.obs['cell_type'].unique())\n    else:\n        n_clusters = 1\n    \n    if n_clusters < 2:\n        n_clusters = 2\n    \n    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n    cluster_labels = kmeans.fit_predict(adjusted_denoised_data)\n    \n    if len(set(cluster_labels)) > 1:\n        silhouette_avg = silhouette_score(adjusted_denoised_data, cluster_labels)\n    else:\n        silhouette_avg = None\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "2301"
            }
        ],
        "24": [],
        "25": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Trainable parameters: {W.size + H.size}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Trainable parameters: 323720",
                "lineage": "2501"
            }
        ],
        "26": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.model_selection import ParameterGrid\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    param_grid = {'n_components': [5, 10, 15, 20, 25, 30]}\n    best_score = -np.inf\n    best_denoised = None\n    \n    for params in ParameterGrid(param_grid):\n        model = NMF(n_components=params['n_components'], init='nndsvd', random_state=0)\n        W = model.fit_transform(data)\n        H = model.components_\n\n        dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n        adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n        \n        score = np.mean((data - adjusted_denoised_data) ** 2)  # Example scoring method\n        if score < best_score or best_score == -np.inf:\n            best_score = score\n            best_denoised = adjusted_denoised_data\n    \n    adata.obsm[\"denoised\"] = best_denoised\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.810878701977205,
                "model_info": "",
                "lineage": "2601"
            }
        ],
        "27": [],
        "28": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = RobustScaler()\n    data = scaler.fit_transform(data)\n    \n    data[data < 0] = 0\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.5875333317633833,
                "model_info": "",
                "lineage": "2801"
            }
        ],
        "29": [],
        "30": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import SimpleImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = SimpleImputer(strategy='mean')\n    filled_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = filled_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "3001"
            }
        ],
        "31": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport networkx as nx\nfrom sklearn.metrics import pairwise_distances\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adjacency_matrix = pairwise_distances(adjusted_denoised_data)\n    graph = nx.from_numpy_array(adjacency_matrix)\n    clusters = KMeans(n_clusters=5, random_state=0).fit_predict(adjusted_denoised_data)\n\n    for cluster in np.unique(clusters):\n        cluster_indices = np.where(clusters == cluster)[0]\n        cluster_data = adjusted_denoised_data[cluster_indices]\n        knn_imputer = KNeighborsRegressor(n_neighbors=5)\n        knn_imputer.fit(cluster_data, cluster_data)\n        adjusted_denoised_data[cluster_indices] = knn_imputer.predict(cluster_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8104375066348564,
                "model_info": "",
                "lineage": "3101"
            }
        ],
        "32": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import SimpleImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    imputer = SimpleImputer(strategy='mean')\n    adjusted_denoised_data_imputed = imputer.fit_transform(adjusted_denoised_data)\n\n    knn = KNeighborsRegressor(n_neighbors=5)\n    knn.fit(adjusted_denoised_data_imputed, adjusted_denoised_data_imputed)\n    imputed_data = knn.predict(adjusted_denoised_data_imputed)\n\n    adata.obsm[\"denoised\"] = imputed_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8104695198101014,
                "model_info": "",
                "lineage": "3201"
            }
        ],
        "33": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import NearestNeighbors\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    knn = NearestNeighbors(n_neighbors=5)\n    knn.fit(adjusted_denoised_data)\n    imputed_data = adjusted_denoised_data.copy()\n    for i in range(imputed_data.shape[0]):\n        if np.any(imputed_data[i] == 0):\n            neighbors = knn.kneighbors(imputed_data[i].reshape(1, -1), return_distance=False)\n            imputed_data[i] = np.where(imputed_data[i] == 0, np.mean(imputed_data[neighbors], axis=1), imputed_data[i])\n\n    adata.obsm[\"denoised\"] = imputed_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106146467997457,
                "model_info": "",
                "lineage": "3301"
            }
        ],
        "34": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n\n    imputer = KNNImputer(n_neighbors=5)\n    data = imputer.fit_transform(data)\n    \n    data = np.maximum(data, 0)\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.5817670447253104,
                "model_info": "",
                "lineage": "3401"
            }
        ],
        "35": [],
        "36": [],
        "37": [],
        "38": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.ensemble import RandomForestRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    def impute_missing_values(X):\n        mask = np.isnan(X)\n        if np.any(mask):\n            imputer = RandomForestRegressor(random_state=0)\n            X_non_missing = X[~mask]\n            X_non_missing = X_non_missing.reshape(-1, 1)\n            imputer.fit(X_non_missing, X_non_missing)\n            X[mask] = imputer.predict(X[mask].reshape(-1, 1)).flatten()\n        return X\n\n    adjusted_denoised_data = impute_missing_values(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "3801"
            }
        ],
        "39": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.model_selection import KFold\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    if np.any(np.isnan(adjusted_denoised_data)):\n        print(\"Warning: Denoised data contains NaN values.\")\n    if np.any(adjusted_denoised_data < 0):\n        print(\"Warning: Denoised data contains negative values.\")\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    kf = KFold(n_splits=5)\n    cv_scores = []\n    for train_index, test_index in kf.split(data):\n        model.fit(data[train_index])\n        score = model.reconstruction_err_\n        cv_scores.append(score)\n    \n    print(f\"Cross-validation scores - Mean: {np.mean(cv_scores):.3f}, Std: {np.std(cv_scores):.3f}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Cross-validation scores - Mean: 2796.051, Std: 43.306",
                "lineage": "3901"
            }
        ],
        "40": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = StandardScaler()\n    data_scaled = scaler.fit_transform(data)\n    data_scaled[data_scaled < 0] = 0\n    \n    model = NMF(n_components=30, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data_scaled)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(\"Parameter Change Magnitude:\")\n    for i in range(1, model.n_iter_):\n        if i < W.shape[0] and i < H.shape[0]:\n            print(f\"Iteration {i}: W change magnitude = {np.linalg.norm(W - W[i-1])}, H change magnitude = {np.linalg.norm(H - H[i-1])}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.6162195928692237,
                "model_info": "Parameter Change Magnitude:\nIteration 1: W change magnitude = 97.88250813662606, H change magnitude = 192.90698361373583\nIteration 2: W change magnitude = 101.6179263856486, H change magnitude = 133.69220554559007\nIteration 3: W change magnitude = 95.52652214260966, H change magnitude = 145.86528633394238\nIteration 4: W change magnitude = 95.22340259965505, H change magnitude = 117.47717745401987\nIteration 5: W change magnitude = 95.78720359970667, H change magnitude = 133.24394407342206\nIteration 6: W change magnitude = 104.92081036678309, H change magnitude = 145.26954080653363\nIteration 7: W change magnitude = 98.71498701269846, H change magnitude = 119.64728430069283\nIteration 8: W change magnitude = 101.50679183765202, H change magnitude = 125.89261291264486\nIteration 9: W change magnitude = 107.5738329359044, H change magnitude = 124.60335774532294\nIteration 10: W change magnitude = 95.88092178930538, H change magnitude = 110.36673052572647\nIteration 11: W change magnitude = 95.47142448759452, H change magnitude = 109.0550779378017\nIteration 12: W change magnitude = 99.96585889918516, H change magnitude = 111.87532264751661\nIteration 13: W change magnitude = 95.46908335864204, H change magnitude = 104.54052995771963\nIteration 14: W change magnitude = 168.93577973141785, H change magnitude = 104.84795924486751\nIteration 15: W change magnitude = 122.2292742445167, H change magnitude = 109.09969700779676\nIteration 16: W change magnitude = 100.0536243159167, H change magnitude = 111.73532966560863\nIteration 17: W change magnitude = 99.94508909197167, H change magnitude = 106.41966883912521\nIteration 18: W change magnitude = 471.9478843139727, H change magnitude = 105.00824702032048\nIteration 19: W change magnitude = 97.76125044171656, H change magnitude = 106.61967834577605\nIteration 20: W change magnitude = 96.36542050918169, H change magnitude = 107.07464196816991\nIteration 21: W change magnitude = 94.6817887331871, H change magnitude = 104.21310080920614\nIterat",
                "lineage": "4001"
            }
        ],
        "41": [],
        "42": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.metrics import mutual_info_score\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    imputed_data = np.dot(W, H)\n    \n    def normalized_mutual_information(original, imputed):\n        return mutual_info_score(original.flatten(), imputed.flatten())\n\n    nmi_score = normalized_mutual_information(data, imputed_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "4201"
            }
        ],
        "43": [],
        "44": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, solver='cd', max_iter=200)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "4401"
            }
        ],
        "45": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, solver='mu', beta_loss='frobenius', max_iter=500, tol=1e-4)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8087560416800808,
                "model_info": "",
                "lineage": "4501"
            }
        ],
        "46": [],
        "47": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\nimport psutil\n\ndef tuso_model(adata):\n    start_time = time.time()\n    process = psutil.Process()\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = MinMaxScaler()\n    data = scaler.fit_transform(data)\n    \n    model = NMF(n_components=15, init='nndsvd', random_state=0, max_iter=300)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    end_time = time.time()\n    memory_usage = process.memory_info().rss / (1024 * 1024)\n    num_parameters = W.size + H.size\n    \n    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n    print(f\"Memory usage: {memory_usage:.2f} MB\")\n    print(f\"Number of trainable parameters: {num_parameters}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.6429475492317149,
                "model_info": "Time taken: 6.94 seconds\nMemory usage: 976.67 MB\nNumber of trainable parameters: 242790",
                "lineage": "4701"
            }
        ],
        "48": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom anndata import AnnData\nfrom sklearn.impute import SimpleImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = SimpleImputer(strategy='median')\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "4801"
            }
        ],
        "49": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.impute import SimpleImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = SimpleImputer(strategy='mean')\n    imputed_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    rf_imputer = RandomForestRegressor(random_state=0)\n    rf_imputer.fit(np.arange(imputed_data.shape[0]).reshape(-1, 1), imputed_data)\n    final_data = rf_imputer.predict(np.arange(imputed_data.shape[0]).reshape(-1, 1))\n    \n    adata.obsm[\"denoised\"] = final_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8045777043544204,
                "model_info": "",
                "lineage": "4901"
            }
        ],
        "50": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.ensemble import RandomForestRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    missing_mask = np.isnan(adjusted_denoised_data)\n    imputed_data = adjusted_denoised_data.copy()\n    if np.any(missing_mask):\n        rf_imputer = RandomForestRegressor(random_state=0)\n        for i in range(imputed_data.shape[1]):\n            if np.any(missing_mask[:, i]):\n                rf_imputer.fit(np.arange(imputed_data.shape[0]).reshape(-1, 1)[~missing_mask[:, i]], imputed_data[~missing_mask[:, i], i])\n                imputed_data[missing_mask[:, i], i] = rf_imputer.predict(np.arange(imputed_data.shape[0]).reshape(-1, 1)[missing_mask[:, i]])\n\n    adata.obsm[\"denoised\"] = imputed_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "5001"
            }
        ],
        "51": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    trainable_params = W.size + H.size\n    print(f\"Trainable parameters: {trainable_params}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "Trainable parameters: 323720",
                "lineage": "5101"
            }
        ],
        "52": [],
        "53": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom scipy.stats import zscore\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    z_scores = zscore(adjusted_denoised_data, axis=0)\n    outliers = np.sum(np.abs(z_scores) > 3, axis=0)\n    print(f'Outlier counts per feature: {outliers}')\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Outlier counts per feature: [16 13  4 ...  7 10 18]",
                "lineage": "5301"
            }
        ],
        "54": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.ensemble import RandomForestRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    rf_imputer = RandomForestRegressor(n_estimators=100, random_state=0)\n    for i in range(adjusted_denoised_data.shape[1]):\n        missing_mask = np.isnan(adjusted_denoised_data[:, i])\n        if np.any(missing_mask):\n            rf_imputer.fit(np.arange(adjusted_denoised_data.shape[0])[~missing_mask].reshape(-1, 1), \n                                      adjusted_denoised_data[~missing_mask, i])\n            adjusted_denoised_data[missing_mask, i] = rf_imputer.predict(np.arange(adjusted_denoised_data.shape[0])[missing_mask].reshape(-1, 1))\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "5401"
            }
        ],
        "55": [],
        "56": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    dropout_info_content = np.mean(data == 0, axis=0)\n    ranked_genes = np.argsort(dropout_info_content)\n    selected_genes = ranked_genes[:int(len(ranked_genes) * 0.5)]\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data[:, selected_genes])\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n    full_denoised_data = np.zeros(data.shape)\n    full_denoised_data[:, selected_genes] = adjusted_denoised_data\n    \n    adata.obsm[\"denoised\"] = full_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.7809703335055312,
                "model_info": "",
                "lineage": "5601"
            }
        ],
        "57": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "5701"
            }
        ],
        "58": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    highly_correlated_features = np.corrcoef(data.T)\n    threshold = 0.9\n    correlated_pairs = np.argwhere(np.abs(highly_correlated_features) > threshold)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    print(\"Highly correlated feature pairs:\", correlated_pairs)\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Highly correlated feature pairs: [[    0     0]\n [    1     1]\n [    2     2]\n ...\n [15096 15096]\n [15097 15097]\n [15098 15098]]",
                "lineage": "5801"
            }
        ],
        "59": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    if 'marker' in adata.var.columns:\n        known_markers = adata.var['marker'].values\n        relevant_genes = np.where(known_markers)[0]\n        data = data[:, relevant_genes]\n    else:\n        relevant_genes = np.arange(data.shape[1])\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "5901"
            }
        ],
        "60": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise = np.random.normal(0, 0.1, data.shape)\n    data_noisy = data + noise\n    data_noisy = np.clip(data_noisy, 0, None)\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data_noisy)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data_noisy == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.7982191375190002,
                "model_info": "",
                "lineage": "6001"
            }
        ],
        "61": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "6101"
            }
        ],
        "62": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "6201"
            }
        ],
        "63": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\n\nclass AttentionLayer(nn.Module):\n    def __init__(self, input_dim):\n        super(AttentionLayer, self).__init__()\n        self.W = nn.Parameter(torch.randn(input_dim, input_dim))\n        self.b = nn.Parameter(torch.zeros(input_dim))\n\n    def forward(self, x):\n        attention_scores = torch.matmul(x, self.W) + self.b\n        attention_weights = torch.softmax(attention_scores, dim=-1)\n        return x * attention_weights\n\nclass ImputationModel(nn.Module):\n    def __init__(self, input_dim):\n        super(ImputationModel, self).__init__()\n        self.attention = AttentionLayer(input_dim)\n        self.nmf = NMF(n_components=20, init='nndsvd', random_state=0)\n\n    def forward(self, x):\n        x = self.attention(x)\n        W = self.nmf.fit_transform(x.detach().numpy())\n        H = self.nmf.components_\n        return torch.tensor(np.dot(W, H), dtype=torch.float32)\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = ImputationModel(data.shape[1])\n    denoised_data = model(torch.tensor(data, dtype=torch.float32)).detach().numpy()\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.7551403344303784,
                "model_info": "",
                "lineage": "6301"
            }
        ],
        "64": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    imputer = KNNImputer(n_neighbors=5)\n    data = imputer.fit_transform(data)\n    \n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n    \n    data = np.maximum(data, 0)\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.5817670447253103,
                "model_info": "",
                "lineage": "6401"
            }
        ],
        "65": [],
        "66": [],
        "67": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNNImputer(n_neighbors=5)\n    imputed_data = knn_imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "6701"
            }
        ],
        "68": [],
        "69": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import PowerTransformer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom scipy.stats import skew, kurtosis\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    transformer = PowerTransformer(method='yeo-johnson', standardize=False)\n    data = transformer.fit_transform(data)\n    \n    data[data < 0] = 0\n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    skewness = skew(data, axis=0)\n    kurt = kurtosis(data, axis=0)\n    for i in range(data.shape[1]):\n        print(f\"Feature {i}: Skewness = {skewness[i]}, Kurtosis = {kurt[i]}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.775354785321472,
                "model_info": "Feature 0: Skewness = 1.6232619523621068, Kurtosis = 0.6350630120471079\nFeature 1: Skewness = 5.665145381156285, Kurtosis = 30.093872189637203\nFeature 2: Skewness = 11.527463479554942, Kurtosis = 130.88241427246476\nFeature 3: Skewness = 2.5952814504853334, Kurtosis = 4.735485956054929\nFeature 4: Skewness = 18.956162609057166, Kurtosis = 357.33610086101146\nFeature 5: Skewness = 2.579195838573533, Kurtosis = 4.65225119155568\nFeature 6: Skewness = 4.787603133981682, Kurtosis = 20.921143768510845\nFeature 7: Skewness = 2.8619795120976472, Kurtosis = 6.190926728921108\nFeature 8: Skewness = 0.2455414103244987, Kurtosis = -1.6214527903766354\nFeature 9: Skewness = 3.118565210120207, Kurtosis = 7.725448969826505\nFeature 10: Skewness = 1.061969441607888, Kurtosis = -0.8689809384369611\nFeature 11: Skewness = 2.9016871839359393, Kurtosis = 6.419788513471163\nFeature 12: Skewness = 2.861979512300388, Kurtosis = 6.190926730553281\nFeature 13: Skewness = 5.987308962229953, Kurtosis = 33.84786860919835\nFeature 14: Skewness = 3.895521692499687, Kurtosis = 13.17508925673527\nFeature 15: Skewness = 2.9219636194362564, Kurtosis = 6.5378713937608435\nFeature 16: Skewness = 1.6794023919819903, Kurtosis = 0.8204207513831423\nFeature 17: Skewness = 11.527463479554784, Kurtosis = 130.88241427246908\nFeature 18: Skewness = 4.385302684546765, Kurtosis = 17.230879635092016\nFeature 19: Skewness = 0.9388412473261308, Kurtosis = -1.1150994843633546\nFeature 20: Skewness = 8.335505935693202, Kurtosis = 67.48065920397723\nFeature 21: Skewness = 2.9219636193628302, Kurtosis = 6.537871393157509\nFeature 22: Skewness = 4.546935568391935, Kurtosis = 18.67462306310825\nFeature 23: Skewness = 23.24869551862966, Kurtosis = 538.5018433179797\nFeature 24: Skewness = 4.057712469308343, Kurtosis = 14.465030483579962\nFeature 25: Skewness = 7.807500516878327, Kurtosis = 58.95706432105368\nFeature 26: Skewness = 4.01565875597313, Kurtosis = 14.125515244422704\nFeature 27: Skewness = 16.393708959358186, Kurtosis = 266.75369344",
                "lineage": "6901"
            }
        ],
        "70": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_std = 0.1 * np.std(data, axis=0)\n    noisy_data = data + np.random.normal(0, noise_std, data.shape)\n    noisy_data = np.maximum(noisy_data, 0)\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noisy_data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8090625136872992,
                "model_info": "",
                "lineage": "7001"
            }
        ],
        "71": [],
        "72": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "7201"
            }
        ],
        "73": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n\n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n\n    imputer = KNNImputer(n_neighbors=5)\n    data = imputer.fit_transform(data)\n\n    data = np.maximum(data, 0)\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.5817670447253104,
                "model_info": "",
                "lineage": "7301"
            }
        ],
        "74": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer()\n    imputed_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "7401"
            }
        ],
        "75": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import PowerTransformer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    transformer = PowerTransformer()\n    data = transformer.fit_transform(data)\n    data[data < 0] = 0\n\n    model = NMF(n_components=15, init='nndsvd', random_state=0, max_iter=300)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    frozen_layers = []\n    trainable_layers = []\n    \n    print(f\"Frozen layers: {len(frozen_layers)}, Trainable layers: {len(trainable_layers)}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.5850675833969436,
                "model_info": "Frozen layers: 0, Trainable layers: 0",
                "lineage": "7501"
            }
        ],
        "76": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise = np.random.normal(loc=0, scale=0.1, size=data.shape)\n    data_noisy = data + noise\n    data_noisy[data_noisy < 0] = 0\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data_noisy)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data_noisy == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.7982191375190002,
                "model_info": "",
                "lineage": "7601"
            }
        ],
        "77": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, solver='mu', max_iter=1000, tol=1e-4)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8087560416800808,
                "model_info": "",
                "lineage": "7701"
            }
        ],
        "78": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    nan_count = np.isnan(adjusted_denoised_data).sum()\n    inf_count = np.isinf(adjusted_denoised_data).sum()\n    print(f\"NaN count: {nan_count}, Inf count: {inf_count}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "NaN count: 0, Inf count: 0",
                "lineage": "7801"
            }
        ],
        "79": [],
        "80": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n\n    feature_correlations = np.corrcoef(data.T)\n    correlated_features = np.where(np.abs(feature_correlations) > 0.8)\n    for i, j in zip(*correlated_features):\n        if i < j:\n            print(f\"Highly correlated features: {i}, {j} with correlation {feature_correlations[i, j]}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Highly correlated features: 4, 4018 with correlation 0.8524095363837105\nHighly correlated features: 104, 4262 with correlation 0.8161202284850892\nHighly correlated features: 183, 2060 with correlation 0.8739643329793841\nHighly correlated features: 183, 6889 with correlation 0.8389921124223971\nHighly correlated features: 375, 10752 with correlation 0.9428091415991361\nHighly correlated features: 407, 1869 with correlation 0.8048853465572312\nHighly correlated features: 466, 7761 with correlation 0.8196718228981078\nHighly correlated features: 694, 3670 with correlation 0.8432462382199217\nHighly correlated features: 694, 7340 with correlation 0.8193735439015752\nHighly correlated features: 694, 8307 with correlation 0.80988477403161\nHighly correlated features: 694, 13204 with correlation 0.8709536927783221\nHighly correlated features: 876, 1869 with correlation 0.8048853465572288\nHighly correlated features: 1058, 2973 with correlation 0.9141289319219904\nHighly correlated features: 1058, 3239 with correlation 0.8611958783896598\nHighly correlated features: 1058, 3591 with correlation 0.8750923853053308\nHighly correlated features: 1058, 3602 with correlation 0.9040049160383333\nHighly correlated features: 1058, 3670 with correlation 0.8316025955474072\nHighly correlated features: 1058, 4839 with correlation 0.8476839051361643\nHighly correlated features: 1058, 5766 with correlation 0.8220099731896948\nHighly correlated features: 1058, 5823 with correlation 0.8782352357147425\nHighly correlated features: 1058, 6032 with correlation 0.8811867952588404\nHighly correlated features: 1058, 6345 with correlation 0.8895636620256511\nHighly correlated features: 1058, 7251 with correlation 0.8672698345953239\nHighly correlated features: 1058, 9417 with correlation 0.9121787630813327\nHighly correlated features: 1058, 9631 with correlation 0.8059459744966593\nHighly correlated features: 1058, 10413 with correlation 0.8965790003178906\nHighly correlated features: 1058, 10914 with correlation 0.8737",
                "lineage": "8001"
            }
        ],
        "81": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    imputer = SimpleImputer(strategy='mean')\n    data = imputer.fit_transform(data)\n    \n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n    \n    data[data < 0] = 0\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.5817670447253104,
                "model_info": "",
                "lineage": "8101"
            }
        ],
        "82": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import RobustScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = RobustScaler()\n    data_scaled = scaler.fit_transform(data)\n    \n    if np.any(data_scaled < 0):\n        data_scaled = np.abs(data_scaled)\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=300)\n    W = model.fit_transform(data_scaled)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Best hyper-parameter configuration: n_components=20, init='nndsvd', random_state=0\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.6222962427556755,
                "model_info": "Best hyper-parameter configuration: n_components=20, init='nndsvd', random_state=0",
                "lineage": "8201"
            }
        ],
        "83": [],
        "84": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    trainable_params = W.size + H.size\n    print(f\"Trainable parameters: {trainable_params}\")\n\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "Trainable parameters: 323720",
                "lineage": "8401"
            }
        ],
        "85": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\n\ndef tuso_model(adata):\n    start_time = time.time()\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = MinMaxScaler()\n    data = scaler.fit_transform(data)\n    \n    model = NMF(n_components=20, init='nndsvd', max_iter=400, random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    elapsed_time = time.time() - start_time\n    print(f\"Performance Snapshot - Time taken: {elapsed_time:.2f}s, Components: {W.shape[1]}, Dropout Rate: {dropout_rate.mean():.2f}\")\n\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.6429272148867332,
                "model_info": "Performance Snapshot - Time taken: 16.04s, Components: 20, Dropout Rate: 0.86",
                "lineage": "8501"
            }
        ],
        "86": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import StandardScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    data = np.maximum(data, 0)\n    \n    scaler = StandardScaler(with_mean=False)\n    data = scaler.fit_transform(data)\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.6570478114406799,
                "model_info": "",
                "lineage": "8601"
            }
        ],
        "87": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    adjusted_denoised_data = np.maximum(adjusted_denoised_data, 0)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "8701"
            }
        ],
        "88": [],
        "89": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "8901"
            }
        ],
        "90": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "9001"
            }
        ],
        "91": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    knn_imputer.fit(adjusted_denoised_data, adjusted_denoised_data)\n    imputed_data = knn_imputer.predict(adjusted_denoised_data)\n    \n    adata.obsm[\"imputed\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "9101"
            }
        ],
        "92": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    feature_importances = np.mean(H, axis=0)\n    top_k_indices = np.argsort(feature_importances)[-5:][::-1]\n    top_k_importances = feature_importances[top_k_indices]\n    \n    print(\"Top-k feature importances:\", list(zip(top_k_indices, top_k_importances)))\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Top-k feature importances: [(np.int64(7809), np.float64(13.731832239509838)), (np.int64(6528), np.float64(8.42443756336041)), (np.int64(2352), np.float64(6.855522041424628)), (np.int64(4653), np.float64(6.246918961768779)), (np.int64(13258), np.float64(5.818659380181732))]",
                "lineage": "9201"
            }
        ],
        "93": [],
        "94": [],
        "95": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n\n    if np.any(np.isnan(adjusted_denoised_data)):\n        print(\"Warning: NaN values detected in denoised data.\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "9501"
            }
        ],
        "96": [],
        "97": [],
        "98": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, solver='mu', max_iter=500, tol=1e-4)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8087560416800808,
                "model_info": "",
                "lineage": "9801"
            }
        ],
        "99": [],
        "100": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    kmeans = KMeans(n_clusters=10, random_state=0)\n    kmeans.fit(adjusted_denoised_data)\n    silhouette_avg = silhouette_score(adjusted_denoised_data, kmeans.labels_)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "10001"
            }
        ],
        "101": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    kmeans = KMeans(n_clusters=5, random_state=0)\n    kmeans.fit(adjusted_denoised_data)\n    silhouette_avg = silhouette_score(adjusted_denoised_data, kmeans.labels_)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "10101"
            }
        ],
        "102": [],
        "103": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler, PowerTransformer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    transformer = PowerTransformer()\n    data = transformer.fit_transform(data)\n    \n    scaler = RobustScaler()\n    data = scaler.fit_transform(data)\n    \n    data = np.maximum(data, 0)\n    \n    model = NMF(n_components=20, init='nndsvd', max_iter=400, random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"NMF assumptions: independence of components, non-negativity of factors\")\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.5673895558666324,
                "model_info": "NMF assumptions: independence of components, non-negativity of factors",
                "lineage": "10301"
            }
        ],
        "104": [],
        "105": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    trainable_params = W.size + H.size\n    print(f\"Trainable Parameters: {trainable_params}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "Trainable Parameters: 323720",
                "lineage": "10501"
            }
        ],
        "106": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.metrics import mean_squared_error\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    mse = mean_squared_error(data, denoised_data)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "10601"
            }
        ],
        "107": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    mean_before = np.mean(data, axis=0)\n    std_before = np.std(data, axis=0)\n    min_before = np.min(data, axis=0)\n    max_before = np.max(data, axis=0)\n\n    mean_after = np.mean(adjusted_denoised_data, axis=0)\n    std_after = np.std(adjusted_denoised_data, axis=0)\n    min_after = np.min(adjusted_denoised_data, axis=0)\n    max_after = np.max(adjusted_denoised_data, axis=0)\n\n    print(f\"Before scaling: mean={mean_before}, std={std_before}, min={min_before}, max={max_before}\")\n    print(f\"After scaling: mean={mean_after}, std={std_after}, min={min_after}, max={max_after}\")\n\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Before scaling: mean=[0.22539098 0.02943882 0.00735971 ... 0.73413063 0.23735051 0.13707452], std=[0.55413409 0.17439067 0.08547245 ... 1.21178047 0.51541426 0.37465212], min=[0. 0. 0. ... 0. 0. 0.], max=[7. 2. 1. ... 8. 3. 2.]\nAfter scaling: mean=[4.26835223e-02 8.87616681e-04 8.05136280e-05 ... 2.89331838e-01\n 4.65398306e-02 1.75437581e-02], std=[2.96726895e-02 4.07467344e-04 2.43013442e-04 ... 3.28888685e-01\n 3.24358663e-02 1.14148984e-02], min=[0.0065217  0.         0.         ... 0.00832504 0.00502927 0.        ], max=[0.28849712 0.00320154 0.00627194 ... 2.75505811 0.28320191 0.16070289]",
                "lineage": "10701"
            }
        ],
        "108": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    library_size = np.sum(data, axis=1, keepdims=True)\n    normalized_data = data / library_size * np.mean(library_size)\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(normalized_data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8110875523461814,
                "model_info": "",
                "lineage": "10801"
            }
        ],
        "109": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import StandardScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    if data.shape[0] < 100:\n        print(\"Warning: Insufficient training data volume. Consider increasing the dataset size.\")\n    \n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n    \n    data[data < 0] = 0\n    \n    model = NMF(n_components=20, init='nndsvd', max_iter=400, random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(\"Denoising completed. Data shape:\", adjusted_denoised_data.shape)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.5817670447253104,
                "model_info": "Denoising completed. Data shape: (1087, 15099)",
                "lineage": "10901"
            }
        ],
        "110": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\n\nclass ImputationModel(nn.Module):\n    def __init__(self, input_dim):\n        super(ImputationModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, input_dim)\n        self.activation = nn.ReLU()\n        \n    def forward(self, x):\n        x = self.activation(self.fc1(x))\n        x = self.activation(self.fc2(x))\n        return self.fc3(x)\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    input_tensor = torch.tensor(adjusted_denoised_data, dtype=torch.float32)\n    imputation_model = ImputationModel(input_dim=adjusted_denoised_data.shape[1])\n    optimizer = torch.optim.Adam(imputation_model.parameters(), lr=0.001)\n    criterion = nn.MSELoss()\n\n    imputation_model.train()\n    for epoch in range(100): \n        optimizer.zero_grad()\n        output = imputation_model(input_tensor)\n        loss = criterion(output, input_tensor)\n        loss.backward()\n        optimizer.step()\n\n    adjusted_denoised_data = output.detach().numpy()\n    adata.obsm[\"denoised\"] = np.maximum(adjusted_denoised_data, 0)\n\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.7676626112807776,
                "model_info": "",
                "lineage": "11001"
            }
        ],
        "111": [],
        "112": [],
        "113": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\nfrom sklearn.preprocessing import StandardScaler\n\ndef tuso_model(adata):\n    start_time = time.time()\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n    data[data < 0] = 0\n\n    model = NMF(n_components=18, init='nndsvd', max_iter=400, random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    end_time = time.time()\n    print(f\"Data loading and processing time: {end_time - start_time:.4f} seconds\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.5817428717938944,
                "model_info": "Data loading and processing time: 4.1680 seconds",
                "lineage": "11301"
            }
        ],
        "114": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNNImputer(n_neighbors=5)\n    imputed_data = knn_imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.810703997486097,
                "model_info": "",
                "lineage": "11401"
            }
        ],
        "115": [
            {
                "code": "import numpy as np\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neural_network import MLPRegressor\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = MLPRegressor(hidden_layer_sizes=(128, 64, 32), activation='relu', solver='adam', max_iter=100)\n    model.fit(data, data)\n\n    adjusted_denoised_data = model.predict(data)\n    adjusted_denoised_data = np.maximum(adjusted_denoised_data, 0)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.6573050202066872,
                "model_info": "",
                "lineage": "11501"
            }
        ],
        "116": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    feature_selection_weights = np.exp(-dropout_rate)  # Integrating dropout with attention-like weighting\n    adjusted_denoised_data = np.dot(W, H) * feature_selection_weights\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8061250168869557,
                "model_info": "",
                "lineage": "11601"
            }
        ],
        "117": [],
        "118": [],
        "119": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    \n    start_time = time.time()\n    W = model.fit_transform(data)\n    H = model.components_\n    elapsed_time = time.time() - start_time\n    \n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Epoch completed in {elapsed_time:.2f} seconds, dropout rate: {dropout_rate.mean():.2f}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Epoch completed in 8.17 seconds, dropout rate: 0.86",
                "lineage": "11901"
            }
        ],
        "120": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    knn_imputer.fit(data, adjusted_denoised_data)\n    imputed_data = knn_imputer.predict(data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8110627742624926,
                "model_info": "",
                "lineage": "12001"
            }
        ],
        "121": [],
        "122": [],
        "123": [],
        "124": [],
        "125": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import normalize\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n\n    size_factors = data.sum(axis=1) / np.mean(data.sum(axis=1))\n    normalized_data = data / size_factors[:, np.newaxis]\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(normalized_data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(normalized_data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8110875523461814,
                "model_info": "",
                "lineage": "12501"
            }
        ],
        "126": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import QuantileTransformer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    transformer = QuantileTransformer(output_distribution='normal')\n    data = transformer.fit_transform(data)\n    \n    data[data < 0] = 0\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.595028050897029,
                "model_info": "",
                "lineage": "12601"
            }
        ],
        "127": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import QuantileTransformer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    transformer = QuantileTransformer()\n    data = transformer.fit_transform(data)\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.6332898913157763,
                "model_info": "",
                "lineage": "12701"
            }
        ],
        "128": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    feature_importance = np.mean(W, axis=0)\n    top_features = np.argsort(feature_importance)[-5:]  # Get indices of top 5 features\n    logging.info(f\"Top features for imputation: {top_features}, Importance: {feature_importance[top_features]}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "12801"
            }
        ],
        "129": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\n\ndef tuso_model(adata):\n    start_time = time.time()\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    fit_start_time = time.time()\n    W = model.fit_transform(data)\n    fit_end_time = time.time()\n    \n    H = model.components_\n    \n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Data loading time: {fit_start_time - start_time:.4f} seconds\")\n    print(f\"Model fitting time: {fit_end_time - fit_start_time:.4f} seconds\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Data loading time: 0.0309 seconds\nModel fitting time: 16.0392 seconds",
                "lineage": "12901"
            }
        ],
        "130": [],
        "131": [],
        "132": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    knn = KNeighborsRegressor(n_neighbors=5)\n    knn.fit(adjusted_denoised_data, adjusted_denoised_data)\n    imputed_data = knn.predict(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8105107748602138,
                "model_info": "",
                "lineage": "13201"
            }
        ],
        "133": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn = KNeighborsRegressor(n_neighbors=5)\n    knn.fit(adjusted_denoised_data, adjusted_denoised_data)\n    imputed_data = knn.predict(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8105107748602138,
                "model_info": "",
                "lineage": "13301"
            }
        ],
        "134": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    validation_metrics = {\n        \"n_components\": model.n_components,\n        \"reconstruction_error\": model.reconstruction_err_,\n        \"dropout_rate\": dropout_rate.tolist()\n    }\n    print(validation_metrics)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "{'n_components': 20, 'reconstruction_error': np.float64(3171.337726126415), 'dropout_rate': [0.8150873965041399, 0.9714811407543699, 0.99, 0.8960441582336707, 0.99, 0.8951241950321988, 0.9613615455381784, 0.9098436062557498, 0.5013799448022079, 0.920883164673413, 0.734130634774609, 0.9116835326586936, 0.9098436062557498, 0.9742410303587856, 0.9448022079116836, 0.9126034958601656, 0.8215271389144434, 0.99, 0.9549218031278749, 0.7120515179392825, 0.9862005519779209, 0.9126034958601656, 0.9576816927322908, 0.99, 0.9484820607175714, 0.984360625574977, 0.9475620975160993, 0.99, 0.8537258509659613, 0.9641214351425943, 0.922723091076357, 0.968721251149954, 0.8528058877644894, 0.9126034958601656, 0.9862005519779209, 0.8840846366145354, 0.9494020239190433, 0.99, 0.9632014719411224, 0.9797608095676172, 0.9236430542778289, 0.9751609935602575, 0.9420423183072677, 0.9714811407543699, 0.9034038638454461, 0.8509659613615456, 0.7470101195952162, 0.7433302667893285, 0.8620055197792088, 0.9880404783808647, 0.8978840846366145, 0.9512419503219871, 0.99, 0.99, 0.9282428702851886, 0.9466421343146274, 0.8923643054277829, 0.8638454461821528, 0.8482060717571297, 0.99, 0.6356945722171113, 0.9070837166513339, 0.983440662373505, 0.44342226310947563, 0.9319227230910764, 0.9825206991720331, 0.8831646734130635, 0.8215271389144434, 0.8242870285188593, 0.9751609935602575, 0.8114075436982521, 0.9622815087396505, 0.9383624655013799, 0.6669733210671573, 0.8859245630174793, 0.7792088316467342, 0.9586016559337627, 0.9282428702851886, 0.9024839006439742, 0.84360625574977, 0.99, 0.985280588776449, 0.795768169273229, 0.39466421343146274, 0.8518859245630175, 0.9089236430542779, 0.7856485740570377, 0.7056117755289788, 0.99, 0.99, 0.99, 0.99, 0.9659613615455381, 0.99, 0.99, 0.99, 0.9760809567617296, 0.9871205151793928, 0.9862005519779209, 0.99, 0.9172033118675254, 0.9448022079116836, 0.99, 0.9871205151793928, 0.99, 0.9742410303587856, 0.99, 0.9678012879484821, 0.99, 0.99, 0.9871205151793928, 0.99, 0.969641214",
                "lineage": "13401"
            }
        ],
        "135": [],
        "136": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=200)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    correlation_matrix = np.corrcoef(adjusted_denoised_data.T)\n    threshold = 0.8\n    correlated_features = np.where(np.abs(correlation_matrix) > threshold)\n    correlated_pairs = set()\n    for i, j in zip(*correlated_features):\n        if i < j:\n            correlated_pairs.add((i, j))\n    \n    print(f\"Correlated feature pairs above threshold {threshold}: {correlated_pairs}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "Correlated feature pairs above threshold 0.8: {(np.int64(1271), np.int64(4513)), (np.int64(9532), np.int64(14024)), (np.int64(938), np.int64(8245)), (np.int64(2734), np.int64(10545)), (np.int64(1065), np.int64(3856)), (np.int64(10557), np.int64(10785)), (np.int64(9490), np.int64(14552)), (np.int64(7783), np.int64(10789)), (np.int64(3175), np.int64(11419)), (np.int64(1052), np.int64(2116)), (np.int64(1580), np.int64(8651)), (np.int64(5098), np.int64(9330)), (np.int64(8425), np.int64(11195)), (np.int64(9323), np.int64(12345)), (np.int64(7616), np.int64(8582)), (np.int64(6778), np.int64(8237)), (np.int64(3128), np.int64(10822)), (np.int64(1051), np.int64(12444)), (np.int64(2001), np.int64(13784)), (np.int64(3195), np.int64(5628)), (np.int64(3247), np.int64(5818)), (np.int64(4569), np.int64(13123)), (np.int64(7241), np.int64(12842)), (np.int64(9913), np.int64(12561)), (np.int64(4586), np.int64(7842)), (np.int64(1936), np.int64(11854)), (np.int64(2591), np.int64(14000)), (np.int64(2130), np.int64(2271)), (np.int64(2658), np.int64(8806)), (np.int64(8164), np.int64(9326)), (np.int64(12491), np.int64(12618)), (np.int64(2718), np.int64(9611)), (np.int64(13389), np.int64(13768)), (np.int64(3313), np.int64(10952)), (np.int64(10615), np.int64(13772)), (np.int64(3462), np.int64(10294)), (np.int64(10401), np.int64(12500)), (np.int64(6134), np.int64(10013)), (np.int64(10461), np.int64(13305)), (np.int64(8384), np.int64(14927)), (np.int64(2730), np.int64(3205)), (np.int64(2427), np.int64(3396)), (np.int64(9217), np.int64(14147)), (np.int64(8128), np.int64(14183)), (np.int64(8217), np.int64(12720)), (np.int64(1397), np.int64(5510)), (np.int64(9115), np.int64(13870)), (np.int64(9294), np.int64(9671)), (np.int64(1124), np.int64(10047)), (np.int64(3796), np.int64(9766)), (np.int64(2141), np.int64(6193)), (np.int64(6187), np.int64(13407)), (np.int64(6557), np.int64(8022)), (np.int64(7033), np.int64(14367)), (np.int64(8807), np.int64(12936)), (np.int64(4311), np.int64(14561)), (np.int64(",
                "lineage": "13601"
            }
        ],
        "137": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import QuantileTransformer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    transformer = QuantileTransformer(output_distribution='uniform')\n    data = transformer.fit_transform(data)\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.6332898913157763,
                "model_info": "",
                "lineage": "13701"
            }
        ],
        "138": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  # Noise modeling to capture zero-preserving imputation\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "13801"
            }
        ],
        "139": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata, threshold_cell=0.1, threshold_gene=0.1):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    high_quality_cells = np.mean(data, axis=1) > threshold_cell\n    high_quality_genes = np.mean(data, axis=0) > threshold_gene\n    filtered_data = data[high_quality_cells, :][:, high_quality_genes]\n\n    noise_model = np.random.poisson(filtered_data)\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    denoised_data_full = np.zeros(data.shape)\n    denoised_data_full[high_quality_cells, :][:, high_quality_genes] = adjusted_denoised_data\n    adata.obsm[\"denoised\"] = denoised_data_full\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.7560048437472111,
                "model_info": "",
                "lineage": "13901"
            }
        ],
        "140": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    logging.info(f\"NMF components: {model.n_components}\")\n    logging.info(f\"Model fit time: {model.n_iter_} iterations\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "14001"
            }
        ],
        "141": [],
        "142": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    refined_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "14201"
            }
        ],
        "143": [],
        "144": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neural_network import MLPRegressor\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    mlp = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', max_iter=1000, random_state=0)\n    mlp.fit(data, adjusted_denoised_data)\n    adjusted_denoised_data = mlp.predict(data)\n    \n    adata.obsm[\"denoised\"] = np.maximum(adjusted_denoised_data, 0)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.7107713309616632,
                "model_info": "",
                "lineage": "14401"
            }
        ],
        "145": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Number of trainable parameters: {W.shape[1] * (W.shape[0] + H.shape[0])}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Number of trainable parameters: 22140",
                "lineage": "14501"
            }
        ],
        "146": [],
        "147": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    knn_imputer.fit(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1), adjusted_denoised_data)\n    refined_data = knn_imputer.predict(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1))\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.804790588387059,
                "model_info": "",
                "lineage": "14701"
            }
        ],
        "148": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    refined_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "14801"
            }
        ],
        "149": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=15, init='nndsvd', random_state=0, max_iter=300)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(\"Per-epoch loss:\", model.reconstruction_err_)\n    print(\"Validation score:\", model.reconstruction_err_)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8168388404101238,
                "model_info": "Per-epoch loss: 4267.847451283299\nValidation score: 4267.847451283299",
                "lineage": "14901"
            }
        ],
        "150": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    kmeans = KMeans(n_clusters=5, random_state=0)\n    kmeans.fit(adjusted_denoised_data)\n    silhouette_avg = silhouette_score(adjusted_denoised_data, kmeans.labels_)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "15001"
            }
        ],
        "151": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank_estimation = np.linalg.matrix_rank(data)\n    optimal_rank = min(rank_estimation, 20)\n    \n    model = NMF(n_components=optimal_rank, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "15101"
            }
        ],
        "152": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNNImputer(n_neighbors=5)\n    refined_data = knn_imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "15201"
            }
        ],
        "153": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\n\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.fc2 = nn.Linear(128, input_dim)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    input_tensor = torch.tensor(adjusted_denoised_data, dtype=torch.float32)\n    nn_model = SimpleNN(input_dim=adjusted_denoised_data.shape[1])\n    nn_model.eval()\n    with torch.no_grad():\n        refined_data = nn_model(input_tensor).numpy()\n\n    adata.obsm[\"denoised\"] = np.maximum(refined_data, 0)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.44350532424218814,
                "model_info": "",
                "lineage": "15301"
            }
        ],
        "154": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model = NMF(n_components=20, init='nndsvd', random_state=0, beta_loss='kullback-leibler', solver='mu', max_iter=200)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = np.maximum(adjusted_denoised_data, 0)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8174094363782127,
                "model_info": "",
                "lineage": "15401"
            }
        ],
        "155": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "15501"
            }
        ],
        "156": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    knn_imputer.fit(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1), adjusted_denoised_data)\n    refined_data = knn_imputer.predict(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1))\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.804790588387059,
                "model_info": "",
                "lineage": "15601"
            }
        ],
        "157": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    refined_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "15701"
            }
        ],
        "158": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import QuantileTransformer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    quantile_transformer = QuantileTransformer(output_distribution='normal')\n    data_normalized = quantile_transformer.fit_transform(data)\n    \n    data_normalized[data_normalized < 0] = 0\n    noise_model = np.random.poisson(data_normalized)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.5842621104073651,
                "model_info": "",
                "lineage": "15801"
            }
        ],
        "159": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    kmeans = KMeans(n_clusters=10, random_state=0)\n    cluster_labels = kmeans.fit_predict(adjusted_denoised_data)\n    sil_score = silhouette_score(adjusted_denoised_data, cluster_labels)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "15901"
            }
        ],
        "160": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    data = np.clip(data, a_min=1e-10, a_max=None)\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7836744359114295,
                "model_info": "",
                "lineage": "16001"
            }
        ],
        "161": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n\n    mu = np.mean(data, axis=0)\n    sigma = np.std(data, axis=0)\n    noise_model = mu + sigma * np.random.randn(*data.shape)\n    noise_model = np.maximum(noise_model, 0)\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7677848647713716,
                "model_info": "",
                "lineage": "16101"
            }
        ],
        "162": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    nans_count = np.isnan(data).sum()\n    infs_count = np.isinf(data).sum()\n    print(f\"NaN count: {nans_count}, Inf count: {infs_count}\")\n\n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "NaN count: 0, Inf count: 0",
                "lineage": "16201"
            }
        ],
        "163": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNNImputer(n_neighbors=5)\n    refined_data = knn_imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "16301"
            }
        ],
        "164": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    refined_data = imputer.fit_transform(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "16401"
            }
        ],
        "165": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    low_confidence_threshold = 0.5\n    low_confidence_predictions = np.mean(adjusted_denoised_data < low_confidence_threshold)\n    print(f\"Percentage of low-confidence predictions: {low_confidence_predictions * 100:.2f}%\")\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Percentage of low-confidence predictions: 96.16%",
                "lineage": "16501"
            }
        ],
        "166": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.cluster import AgglomerativeClustering\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0)\n    clustering.fit(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "16601"
            }
        ],
        "167": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    refined_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "16701"
            }
        ],
        "168": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Final evaluation metrics: \\n\"\n          f\"Components: {model.n_components}, \\n\"\n          f\"Converged: {model.n_iter_}, \\n\"\n          f\"Reconstruction error: {model.reconstruction_err_}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Final evaluation metrics: \nComponents: 20, \nConverged: 200, \nReconstruction error: 4025.3663611136917",
                "lineage": "16801"
            }
        ],
        "169": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, beta_loss='kullback-leibler', solver='mu', max_iter=200)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adjusted_denoised_data[adjusted_denoised_data < 0] = 0\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8174094363782127,
                "model_info": "",
                "lineage": "16901"
            }
        ],
        "170": [],
        "171": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=400)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    sparsity = np.mean(adjusted_denoised_data == 0)\n    low_rank_representation = np.linalg.matrix_rank(adjusted_denoised_data)\n    \n    print(f\"Sparsity: {sparsity:.4f}, Low-rank representation: {low_rank_representation}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.8171406760578661,
                "model_info": "Sparsity: 0.0167, Low-rank representation: 20",
                "lineage": "17101"
            }
        ],
        "172": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    \n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(noise_model)\n    \n    model = NMF(n_components=15, init='nndsvd', max_iter=400, random_state=0)\n    W = model.fit_transform(scaled_data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    mean_before = np.mean(data, axis=0)\n    std_before = np.std(data, axis=0)\n    min_before = np.min(data, axis=0)\n    max_before = np.max(data, axis=0)\n    \n    mean_after = np.mean(adjusted_denoised_data, axis=0)\n    std_after = np.std(adjusted_denoised_data, axis=0)\n    min_after = np.min(adjusted_denoised_data, axis=0)\n    max_after = np.max(adjusted_denoised_data, axis=0)\n    \n    print(f\"Before scaling: mean={mean_before}, std={std_before}, min={min_before}, max={max_before}\")\n    print(f\"After scaling: mean={mean_after}, std={std_after}, min={min_after}, max={max_after}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.6759811933409765,
                "model_info": "Before scaling: mean=[0.22539098 0.02943882 0.00735971 ... 0.73413063 0.23735051 0.13707452], std=[0.55413409 0.17439067 0.08547245 ... 1.21178047 0.51541426 0.37465212], min=[0. 0. 0. ... 0. 0. 0.], max=[7. 2. 1. ... 8. 3. 2.]\nAfter scaling: mean=[2.27281922e-03 9.73591791e-05 2.89588175e-05 ... 2.01690442e-02\n 6.28366219e-03 1.73186422e-03], std=[2.76393141e-03 1.46604616e-04 9.03318907e-05 ... 2.26874408e-02\n 3.77015843e-03 1.11121574e-03], min=[0.         0.         0.         ... 0.00043332 0.         0.        ], max=[0.03808894 0.00146078 0.00203224 ... 0.23412018 0.03004085 0.01270642]",
                "lineage": "17201"
            }
        ],
        "173": [],
        "174": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    imputed_data = np.dot(W, H)\n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827940516218752,
                "model_info": "",
                "lineage": "17401"
            }
        ],
        "175": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    param_grid = {'n_components': [10, 15, 20, 25, 30]}\n    model = NMF(init='nndsvd', random_state=0)\n    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error')\n    grid_search.fit(noise_model)\n    \n    best_model = grid_search.best_estimator_\n    W = best_model.fit_transform(noise_model)\n    H = best_model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8159826882817671,
                "model_info": "",
                "lineage": "17501"
            }
        ],
        "176": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(noise_model), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "17601"
            }
        ],
        "177": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(\"Assumptions: Using Poisson noise model for single-cell RNA-seq data.\")\n    print(\"Feature distribution: Assumed non-negative and sparse.\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Assumptions: Using Poisson noise model for single-cell RNA-seq data.\nFeature distribution: Assumed non-negative and sparse.",
                "lineage": "17701"
            }
        ],
        "178": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    print(f\"Data shape: {data.shape}, Data type: {data.dtype}\")\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Data shape: (1087, 15099), Data type: float64",
                "lineage": "17801"
            }
        ],
        "179": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    feature_distribution_assumptions = {\n        \"assumption_1\": \"Feature distributions are assumed to follow a Poisson distribution due to the nature of RNA-seq data.\",\n        \"assumption_2\": \"Data transformation is performed to handle sparsity by using NMF for denoising.\",\n    }\n    print(feature_distribution_assumptions)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "{'assumption_1': 'Feature distributions are assumed to follow a Poisson distribution due to the nature of RNA-seq data.', 'assumption_2': 'Data transformation is performed to handle sparsity by using NMF for denoising.'}",
                "lineage": "17901"
            }
        ],
        "180": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import StandardScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    data = StandardScaler().fit_transform(data)\n    \n    data = np.clip(data, 0, None)\n    noise_model = np.random.poisson(data)  \n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.5677230307433033,
                "model_info": "",
                "lineage": "18001"
            }
        ],
        "181": [],
        "182": [],
        "183": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, solver='mu', beta_loss='frobenius', max_iter=200)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7814114899787854,
                "model_info": "",
                "lineage": "18301"
            }
        ],
        "184": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    knn_imputer.fit(adjusted_denoised_data, adjusted_denoised_data)\n    refined_data = knn_imputer.predict(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8169398702464666,
                "model_info": "",
                "lineage": "18401"
            }
        ],
        "185": [],
        "186": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    refined_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "18601"
            }
        ],
        "187": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn = KNeighborsRegressor(n_neighbors=5)\n    knn.fit(data, adjusted_denoised_data)\n    refined_data = knn.predict(data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8175396750576287,
                "model_info": "",
                "lineage": "18701"
            }
        ],
        "188": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate) + np.dot(W, H) * dropout_rate\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827940516218752,
                "model_info": "",
                "lineage": "18801"
            }
        ],
        "189": [],
        "190": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    knn_imputer.fit(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1), adjusted_denoised_data)\n    refined_denoised_data = knn_imputer.predict(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1))\n    \n    adata.obsm[\"denoised\"] = refined_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.804790588387059,
                "model_info": "",
                "lineage": "19001"
            }
        ],
        "191": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827940516218752,
                "model_info": "",
                "lineage": "19101"
            }
        ],
        "192": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    denoised_data = adjusted_denoised_data + np.random.poisson(0.1, adjusted_denoised_data.shape)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7273395249425689,
                "model_info": "",
                "lineage": "19201"
            }
        ],
        "193": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    print(f\"Input data shape: {data.shape}, dtype: {data.dtype}\")\n    \n    noise_model = np.random.poisson(data)  \n    noise_model[noise_model < 0] = 0\n    scaler = RobustScaler()\n    scaled_data = scaler.fit_transform(noise_model)\n    \n    scaled_data = np.maximum(scaled_data, 0)\n    \n    model = NMF(n_components=18, init='nndsvd', max_iter=400, random_state=0)\n    W = model.fit_transform(scaled_data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Denoised data shape: {adjusted_denoised_data.shape}, dtype: {adjusted_denoised_data.dtype}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.6210223751463508,
                "model_info": "Input data shape: (1087, 15099), dtype: float64\nDenoised data shape: (1087, 15099), dtype: float64",
                "lineage": "19301"
            }
        ],
        "194": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    logging.info(\"Starting the tuso_model function.\")\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    logging.info(\"Data shape: {}\".format(data.shape))\n    \n    noise_model = np.random.poisson(data)  \n    logging.info(\"Noise model generated.\")\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n    \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    logging.info(\"Dropout rate calculated: {}\".format(dropout_rate))\n    \n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    logging.info(\"Denoised data stored in adata.obsm['denoised'].\")\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "19401"
            }
        ],
        "195": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNNImputer(n_neighbors=5)\n    refined_data = knn_imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "19501"
            }
        ],
        "196": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Performance Snapshot: Mean Dropout Rate: {np.mean(dropout_rate):.4f}, Reconstruction Error: {np.linalg.norm(data - adjusted_denoised_data):.4f}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Performance Snapshot: Mean Dropout Rate: 0.8979, Reconstruction Error: 19664.0596",
                "lineage": "19601"
            }
        ],
        "197": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\nimport time\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    logging.info(\"Hyper-parameter settings: n_components=20, init='nndsvd', random_state=0\")\n    \n    start_time = time.time()\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    logging.info(f\"Data loading time: {time.time() - start_time:.4f} seconds\")\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    start_time = time.time()\n    W = model.fit_transform(noise_model)\n    H = model.components_\n    logging.info(f\"NMF fitting time: {time.time() - start_time:.4f} seconds\")\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "19701"
            }
        ],
        "198": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = np.maximum(adjusted_denoised_data, 0)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "19801"
            }
        ],
        "199": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    missing_counts = np.sum(noise_model == 0, axis=0)\n    print(\"Missing values per feature post-imputation:\", missing_counts)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Missing values per feature post-imputation: [ 952 1072 1081 ...  765  942 1001]",
                "lineage": "19901"
            }
        ],
        "200": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\nimport resource\n\ndef tuso_model(adata):\n    start_time = time.time()\n    mem_usage_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    noise_model = StandardScaler().fit_transform(noise_model)\n    noise_model = np.maximum(noise_model, 0)  \n    model = NMF(n_components=18, init='nndsvd', max_iter=400, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    mem_usage_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n    elapsed_time = time.time() - start_time\n    \n    print(f\"Memory Usage: Start={mem_usage_start}KB End={mem_usage_end}KB, Time Elapsed={elapsed_time:.2f}s\")\n    print(f\"Trainable Parameters: {W.size + H.size}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.6022314636074249,
                "model_info": "Memory Usage: Start=642156KB End=1271480KB, Time Elapsed=5.34s\nTrainable Parameters: 291348",
                "lineage": "20001"
            }
        ],
        "201": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn = KNeighborsRegressor(n_neighbors=5)\n    knn.fit(data, adjusted_denoised_data)\n    refined_denoised_data = knn.predict(data)\n    \n    adata.obsm[\"denoised\"] = refined_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8175396750576287,
                "model_info": "",
                "lineage": "20101"
            }
        ],
        "202": [],
        "203": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    \n    print(f\"Dataset statistics: shape={data.shape}, non-zero elements={np.count_nonzero(data)}, mean={np.mean(data)}, std={np.std(data)}\")\n    \n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Dataset statistics: shape=(1087, 15099), non-zero elements=2249402, mean=0.4443931627462367, std=7.520005466085367",
                "lineage": "20301"
            }
        ],
        "204": [],
        "205": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import FunctionTransformer\n\ndef variance_stabilizing_transformation(data):\n    return np.sqrt(data + 1) - 1\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    data = variance_stabilizing_transformation(data)\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.794122385004393,
                "model_info": "",
                "lineage": "20501"
            }
        ],
        "206": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn = KNeighborsRegressor(n_neighbors=5)\n    knn.fit(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1), adjusted_denoised_data)\n    refined_data = knn.predict(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1))\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.804790588387059,
                "model_info": "",
                "lineage": "20601"
            }
        ],
        "207": [],
        "208": [],
        "209": [],
        "210": [],
        "211": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.model_selection import KFold\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    \n    kf = KFold(n_splits=5)\n    scores = []\n    for train_index, test_index in kf.split(noise_model):\n        model.fit(noise_model[train_index])\n        score = model.reconstruction_err_\n        scores.append(score)\n        \n    mean_score = np.mean(scores)\n    std_score = np.std(scores)\n    \n    print(f\"Cross-validation mean score: {mean_score:.4f}, std: {std_score:.4f}\")\n    \n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Cross-validation mean score: 3564.7383, std: 40.5133",
                "lineage": "21101"
            }
        ],
        "212": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=200)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "21201"
            }
        ],
        "213": [],
        "214": [],
        "215": [],
        "216": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    if np.any(np.isnan(data)) or np.any(np.isinf(data)):\n        print(\"NaN or Inf values encountered in input data.\")\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    missing_counts = np.sum(np.isnan(adjusted_denoised_data), axis=0)\n    print(f\"Missing values post-imputation per feature: {missing_counts}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Missing values post-imputation per feature: [0 0 0 ... 0 0 0]",
                "lineage": "21601"
            }
        ],
        "217": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    knn = KNeighborsRegressor(n_neighbors=5)\n    knn.fit(np.arange(adjusted_denoised_data.shape[1]).reshape(-1, 1), adjusted_denoised_data.T)\n    refined_data = knn.predict(np.arange(adjusted_denoised_data.shape[1]).reshape(-1, 1)).T\n\n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7342753857148194,
                "model_info": "",
                "lineage": "21701"
            }
        ],
        "218": [],
        "219": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    refined_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "21901"
            }
        ],
        "220": [],
        "221": [],
        "222": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827940516218752,
                "model_info": "",
                "lineage": "22201"
            }
        ],
        "223": [],
        "224": [],
        "225": [],
        "226": [],
        "227": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    if data.shape[0] < 100:\n        print(\"Warning: Insufficient training data volume.\")\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Trainable parameters: {W.size + H.size}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Trainable parameters: 323720",
                "lineage": "22701"
            }
        ],
        "228": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\n\nclass AttentionLayer(nn.Module):\n    def __init__(self, input_dim):\n        super(AttentionLayer, self).__init__()\n        self.W = nn.Linear(input_dim, input_dim)\n        self.V = nn.Linear(input_dim, 1)\n\n    def forward(self, x):\n        scores = self.V(torch.tanh(self.W(x)))\n        weights = torch.softmax(scores, dim=1)\n        return torch.sum(weights * x, dim=1)\n\nclass ImputationModel(nn.Module):\n    def __init__(self, input_dim):\n        super(ImputationModel, self).__init__()\n        self.attention = AttentionLayer(input_dim)\n        self.fc = nn.Linear(input_dim, input_dim)\n\n    def forward(self, x):\n        x = self.attention(x.unsqueeze(1))\n        return self.fc(x)\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    input_tensor = torch.tensor(adjusted_denoised_data, dtype=torch.float32)\n    imputation_model = ImputationModel(input_dim=adjusted_denoised_data.shape[1])\n    imputed_data = imputation_model(input_tensor).detach().numpy()\n\n    adata.obsm[\"denoised\"] = np.maximum(imputed_data, 0)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.4441839068502673,
                "model_info": "",
                "lineage": "22801"
            }
        ],
        "229": [],
        "230": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n\n    print(\"Parameter change magnitude:\", np.linalg.norm(W - model.fit_transform(noise_model)))\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Parameter change magnitude: 0.0",
                "lineage": "23001"
            }
        ],
        "231": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import StandardScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    data = StandardScaler().fit_transform(data)\n    data = np.clip(data, 0, None)\n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.5677230307433033,
                "model_info": "",
                "lineage": "23101"
            }
        ],
        "232": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\n\ndef tuso_model(adata):\n    start_time = time.time()\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    \n    inference_start_time = time.time()\n    W = model.fit_transform(noise_model)\n    H = model.components_\n    inference_latency = time.time() - inference_start_time\n    \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Inference Latency: {inference_latency:.4f} seconds\")\n    print(f\"Model Components: {model.n_components}\")\n    print(f\"Dropout Rate: {dropout_rate}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Inference Latency: 7.1471 seconds\nModel Components: 20\nDropout Rate: [0.87580497 0.98620055 0.99       ... 0.70377185 0.86660534 0.92088316]",
                "lineage": "23201"
            }
        ],
        "233": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn = KNeighborsRegressor(n_neighbors=5)\n    knn.fit(np.arange(adjusted_denoised_data.shape[1]).reshape(-1, 1), adjusted_denoised_data.T)\n    refined_data = knn.predict(np.arange(adjusted_denoised_data.shape[1]).reshape(-1, 1)).T\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7342753857148194,
                "model_info": "",
                "lineage": "23301"
            }
        ],
        "234": [],
        "235": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.calibration import calibration_curve\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    y_true = (data > 0).astype(int).flatten()\n    y_pred = np.clip(adjusted_denoised_data.flatten(), 0, 1)\n    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=10)\n    ece = np.sum(np.abs(prob_true - prob_pred)) / len(prob_true)\n    \n    print(f\"Calibration Error Metric (ECE): {ece:.4f}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Calibration Error Metric (ECE): 0.1397",
                "lineage": "23501"
            }
        ],
        "236": [],
        "237": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn = KNeighborsRegressor(n_neighbors=5)\n    knn.fit(noise_model, adjusted_denoised_data)\n    refined_data = knn.predict(noise_model)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8177846680526775,
                "model_info": "",
                "lineage": "23701"
            }
        ],
        "238": [],
        "239": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import SimpleImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = SimpleImputer(strategy='mean')\n    refined_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "23901"
            }
        ],
        "240": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    validation_metrics = {\n        'reconstruction_error': model.reconstruction_err_,\n        'dropout_rate': dropout_rate\n    }\n    print(validation_metrics)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "{'reconstruction_error': np.float64(4025.3663611136917), 'dropout_rate': array([0.87580497, 0.98620055, 0.99      , ..., 0.70377185, 0.86660534,\n       0.92088316], shape=(15099,))}",
                "lineage": "24001"
            }
        ],
        "241": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import FunctionTransformer\n\ndef log_normalize(X):\n    return np.log1p(X)\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    data = log_normalize(data)\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.745714449099656,
                "model_info": "",
                "lineage": "24101"
            }
        ],
        "242": [],
        "243": [],
        "244": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import SimpleImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    imputer = SimpleImputer(strategy='mean')\n    refined_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "24401"
            }
        ],
        "245": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import SimpleImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = SimpleImputer(strategy='mean')\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "24501"
            }
        ],
        "246": [],
        "247": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.impute import SimpleImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model1 = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    model2 = NMF(n_components=20, init='nndsvd', random_state=1, max_iter=500)\n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n    \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data1 = np.dot(W1, H1) * (1 - dropout_rate)\n    adjusted_denoised_data2 = np.dot(W2, H2) * (1 - dropout_rate)\n    \n    combined_data = np.mean([adjusted_denoised_data1, adjusted_denoised_data2], axis=0)\n    \n    imputer = SimpleImputer(strategy='mean')\n    refined_data = imputer.fit_transform(combined_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171325887754181,
                "model_info": "",
                "lineage": "24701"
            }
        ],
        "248": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n\n    noise_model = np.random.poisson(data)\n    noise_model[noise_model < 0] = 0\n    scaler = StandardScaler()\n    noise_model = scaler.fit_transform(noise_model)\n\n    noise_model = np.maximum(noise_model, 0)\n    model = NMF(n_components=18, init='nndsvd', random_state=0, max_iter=400)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n\n    misclassified_counts = np.sum(noise_model == 0, axis=0)\n    predicted_probabilities = np.dot(W, H) / np.sum(W, axis=1, keepdims=True)\n    misclassified_instances = np.where(misclassified_counts > 0)[0]\n    \n    valid_indices = misclassified_instances[misclassified_instances < predicted_probabilities.shape[0]]\n    \n    print(\"Misclassified Instances:\", valid_indices)\n    print(\"Predicted Probabilities:\", predicted_probabilities[valid_indices])\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.6022314636074249,
                "model_info": "Misclassified Instances: [   0    1    2 ... 1084 1085 1086]\nPredicted Probabilities: [[0.24457721 0.00959233 0.03842796 ... 0.39928506 0.24671894 0.14664307]\n [0.05381088 0.14643646 0.00445276 ... 0.03153145 0.09489609 0.05795792]\n [0.05162126 0.03679642 0.03293416 ... 0.07106382 0.13557759 0.10203078]\n ...\n [0.10524279 0.06536886 0.01974541 ... 0.05620231 0.14737896 0.13580713]\n [0.20769388 0.00957455 0.020266   ... 0.38947243 0.24718876 0.14633088]\n [0.03857659 0.16130944 0.00187806 ... 0.00293197 0.09417558 0.05421493]]",
                "lineage": "24801"
            }
        ],
        "249": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import SimpleImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n\n    imputer = SimpleImputer(strategy='mean')\n    adjusted_denoised_data_imputed = imputer.fit_transform(adjusted_denoised_data)\n\n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    knn_imputer.fit(np.where(adjusted_denoised_data_imputed != 0, adjusted_denoised_data_imputed, 0), adjusted_denoised_data_imputed)\n    refined_data = knn_imputer.predict(adjusted_denoised_data_imputed)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8169398702464666,
                "model_info": "",
                "lineage": "24901"
            }
        ],
        "250": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "25001"
            }
        ],
        "251": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import SimpleImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = SimpleImputer(strategy='mean')\n    refined_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = refined_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171321932791983,
                "model_info": "",
                "lineage": "25101"
            }
        ],
        "252": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import SimpleImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model1 = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    model2 = NMF(n_components=20, init='nndsvd', random_state=1, max_iter=500)\n    \n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n    \n    denoised_data = (np.dot(W1, H1) + np.dot(W2, H2)) / 2\n    \n    imputer = SimpleImputer(strategy='mean')\n    adjusted_denoised_data = imputer.fit_transform(denoised_data)\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data *= (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171325887754181,
                "model_info": "",
                "lineage": "25201"
            }
        ],
        "253": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model1 = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    model2 = NMF(n_components=20, init='nndsvd', random_state=1, max_iter=500)\n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = (np.dot(W1, H1) + np.dot(W2, H2)) / 2 * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171325887754181,
                "model_info": "",
                "lineage": "25301"
            }
        ],
        "254": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model1 = NMF(n_components=20, init='nndsvd', random_state=0)\n    model2 = NMF(n_components=20, init='nndsvd', random_state=1)\n    \n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n    \n    adjusted_denoised_data = (np.dot(W1, H1) + np.dot(W2, H2)) / 2\n    \n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827925285666529,
                "model_info": "",
                "lineage": "25401"
            }
        ],
        "255": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model1 = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n\n    model2 = NMF(n_components=20, init='nndsvd', random_state=1, max_iter=500)\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n\n    adjusted_denoised_data = (np.dot(W1, H1) + np.dot(W2, H2)) / 2\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data *= (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8171325887754181,
                "model_info": "",
                "lineage": "25501"
            }
        ],
        "256": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, solver='mu', max_iter=200, beta_loss='kullback-leibler', tol=1e-4)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8174094363782127,
                "model_info": "",
                "lineage": "25601"
            }
        ],
        "257": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import QuantileTransformer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom scipy.stats import skew, kurtosis\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=15, init='nndsvd', random_state=0, max_iter=400)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    skewness = skew(adjusted_denoised_data, axis=0)\n    kurt = kurtosis(adjusted_denoised_data, axis=0)\n    \n    for i in range(adjusted_denoised_data.shape[1]):\n        print(f\"Feature {i}: Skewness = {skewness[i]:.4f}, Kurtosis = {kurt[i]:.4f}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.8168402433117978,
                "model_info": "Feature 0: Skewness = 2.3743, Kurtosis = 9.5162\nFeature 1: Skewness = 3.2512, Kurtosis = 17.8287\nFeature 2: Skewness = 20.0557, Kurtosis = 455.4613\nFeature 3: Skewness = 1.2040, Kurtosis = 1.0446\nFeature 4: Skewness = 2.8155, Kurtosis = 14.1351\nFeature 5: Skewness = 7.0037, Kurtosis = 95.0497\nFeature 6: Skewness = 4.7087, Kurtosis = 56.2282\nFeature 7: Skewness = 12.1079, Kurtosis = 241.8518\nFeature 8: Skewness = 2.8209, Kurtosis = 33.1172\nFeature 9: Skewness = 12.5415, Kurtosis = 209.9590\nFeature 10: Skewness = 5.3378, Kurtosis = 68.9329\nFeature 11: Skewness = 1.9562, Kurtosis = 8.8657\nFeature 12: Skewness = 16.5770, Kurtosis = 331.5731\nFeature 13: Skewness = 9.9387, Kurtosis = 148.7032\nFeature 14: Skewness = 9.1163, Kurtosis = 153.8116\nFeature 15: Skewness = 8.3205, Kurtosis = 121.4429\nFeature 16: Skewness = 4.6691, Kurtosis = 49.5032\nFeature 17: Skewness = 17.9439, Kurtosis = 448.4975\nFeature 18: Skewness = 1.4257, Kurtosis = 0.7058\nFeature 19: Skewness = 5.2620, Kurtosis = 65.4058\nFeature 20: Skewness = 2.4767, Kurtosis = 6.3576\nFeature 21: Skewness = 1.3555, Kurtosis = 1.1647\nFeature 22: Skewness = 1.4398, Kurtosis = 1.7297\nFeature 23: Skewness = 2.0110, Kurtosis = 3.9455\nFeature 24: Skewness = 1.2628, Kurtosis = 1.2779\nFeature 25: Skewness = 1.5759, Kurtosis = 2.4860\nFeature 26: Skewness = 3.3466, Kurtosis = 29.2634\nFeature 27: Skewness = 1.8779, Kurtosis = 3.6200\nFeature 28: Skewness = 1.7616, Kurtosis = 3.8346\nFeature 29: Skewness = 1.1874, Kurtosis = 1.0432\nFeature 30: Skewness = 9.3918, Kurtosis = 143.8398\nFeature 31: Skewness = 2.0020, Kurtosis = 3.7303\nFeature 32: Skewness = 6.8614, Kurtosis = 101.2241\nFeature 33: Skewness = 10.4029, Kurtosis = 147.7443\nFeature 34: Skewness = 15.6411, Kurtosis = 286.3367\nFeature 35: Skewness = 2.2488, Kurtosis = 11.8222\nFeature 36: Skewness = 1.2086, Kurtosis = 3.4724\nFeature 37: Skewness = 3.5397, Kurtosis = 15.3539\nFeature 38: Skewness = 2.9278, Kurtosis = 12.3196\nFeature 39: Skewness = 12.5823, Kurtosis = 188.2209\nFeat",
                "lineage": "25701"
            }
        ],
        "258": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model1 = NMF(n_components=20, init='nndsvd', random_state=0)\n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n    \n    model2 = NMF(n_components=20, init='nndsvd', random_state=1)\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n\n    denoised_data = (np.dot(W1, H1) + np.dot(W2, H2)) / 2\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170990113806421,
                "model_info": "",
                "lineage": "25801"
            }
        ],
        "259": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    correlation_matrix = np.corrcoef(adjusted_denoised_data, rowvar=False)\n    threshold = 0.8\n    correlated_features = np.where(np.abs(correlation_matrix) > threshold)\n    \n    for i, j in zip(*correlated_features):\n        if i < j:\n            print(f\"Highly correlated features: {i}, {j} with correlation {correlation_matrix[i, j]:.2f}\")\n\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Highly correlated features: 0, 21 with correlation 0.81\nHighly correlated features: 0, 25 with correlation 0.80\nHighly correlated features: 0, 93 with correlation 0.85\nHighly correlated features: 0, 134 with correlation 0.82\nHighly correlated features: 0, 139 with correlation 0.80\nHighly correlated features: 0, 140 with correlation 0.83\nHighly correlated features: 0, 279 with correlation 0.82\nHighly correlated features: 0, 293 with correlation 0.84\nHighly correlated features: 0, 336 with correlation 0.80\nHighly correlated features: 0, 343 with correlation 0.81\nHighly correlated features: 0, 376 with correlation 0.81\nHighly correlated features: 0, 401 with correlation 0.84\nHighly correlated features: 0, 463 with correlation 0.84\nHighly correlated features: 0, 466 with correlation 0.81\nHighly correlated features: 0, 492 with correlation 0.81\nHighly correlated features: 0, 525 with correlation 0.93\nHighly correlated features: 0, 581 with correlation 0.86\nHighly correlated features: 0, 586 with correlation 0.82\nHighly correlated features: 0, 599 with correlation 0.80\nHighly correlated features: 0, 679 with correlation 0.84\nHighly correlated features: 0, 684 with correlation 0.91\nHighly correlated features: 0, 692 with correlation 0.84\nHighly correlated features: 0, 727 with correlation 0.80\nHighly correlated features: 0, 770 with correlation 0.81\nHighly correlated features: 0, 772 with correlation 0.82\nHighly correlated features: 0, 873 with correlation 0.88\nHighly correlated features: 0, 883 with correlation 0.82\nHighly correlated features: 0, 894 with correlation 0.81\nHighly correlated features: 0, 908 with correlation 0.82\nHighly correlated features: 0, 912 with correlation 0.81\nHighly correlated features: 0, 941 with correlation 0.81\nHighly correlated features: 0, 1015 with correlation 0.82\nHighly correlated features: 0, 1052 with correlation 0.83\nHighly correlated features: 0, 1094 with correlation 0.84\nHighly correlated features: 0, 1100 with correlation 0.84\nHigh",
                "lineage": "25901"
            }
        ],
        "260": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model1 = NMF(n_components=20, init='nndsvd', random_state=0)\n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n    \n    model2 = NMF(n_components=20, init='nndsvd', random_state=1)\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n    \n    denoised_data = (np.dot(W1, H1) + np.dot(W2, H2)) / 2\n    \n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827925285666529,
                "model_info": "",
                "lineage": "26001"
            }
        ],
        "261": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import AgglomerativeClustering\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    adjusted_denoised_data = np.dot(W, H)\n    \n    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0.5)\n    cluster_labels = clustering.fit_predict(adjusted_denoised_data)\n    \n    for cluster in np.unique(cluster_labels):\n        cluster_mask = (cluster_labels == cluster)\n        dropout_rate = np.clip(np.mean(noise_model[cluster_mask] == 0, axis=0), 0.01, 0.99)\n        adjusted_denoised_data[cluster_mask] *= (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7983012700446681,
                "model_info": "",
                "lineage": "26101"
            }
        ],
        "262": [],
        "263": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model1 = NMF(n_components=20, init='nndsvd', random_state=0)\n    model2 = NMF(n_components=20, init='nndsvd', random_state=1)\n    \n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n    \n    denoised_data = (np.dot(W1, H1) + np.dot(W2, H2)) / 2\n    \n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827925285666529,
                "model_info": "",
                "lineage": "26301"
            }
        ],
        "264": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model1 = NMF(n_components=20, init='nndsvd', random_state=0)\n    model2 = NMF(n_components=20, init='nndsvd', random_state=1)\n    \n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n\n    denoised_data1 = np.dot(W1, H1)\n    denoised_data2 = np.dot(W2, H2)\n    \n    combined_denoised_data = (denoised_data1 + denoised_data2) / 2\n    \n    knn_imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = knn_imputer.fit_transform(combined_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827925285666529,
                "model_info": "",
                "lineage": "26401"
            }
        ],
        "265": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import RobustScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    scaler = RobustScaler()\n    noise_model_scaled = scaler.fit_transform(noise_model)\n    \n    noise_model_scaled = np.clip(noise_model_scaled, 0, None)\n    \n    model = NMF(n_components=18, init='nndsvd', max_iter=400, random_state=0)\n    W = model.fit_transform(noise_model_scaled)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model_scaled == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Shapes - W: {W.shape}, H: {H.shape}, Denoised: {adjusted_denoised_data.shape}\")\n    print(f\"Data types - W: {W.dtype}, H: {H.dtype}, Denoised: {adjusted_denoised_data.dtype}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.596504698544807,
                "model_info": "Shapes - W: (1087, 18), H: (18, 15099), Denoised: (1087, 15099)\nData types - W: float64, H: float64, Denoised: float64",
                "lineage": "26501"
            }
        ],
        "266": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    model1 = NMF(n_components=20, init='nndsvd', random_state=0)\n    W1 = model1.fit_transform(noise_model)\n    H1 = model1.components_\n\n    model2 = NMF(n_components=20, init='nndsvd', random_state=1)\n    W2 = model2.fit_transform(noise_model)\n    H2 = model2.components_\n\n    denoised_data = (np.dot(W1, H1) + np.dot(W2, H2)) / 2\n    \n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827925285666529,
                "model_info": "",
                "lineage": "26601"
            }
        ],
        "267": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate) + (dropout_rate * np.mean(data, axis=0))\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7691195132830722,
                "model_info": "",
                "lineage": "26701"
            }
        ],
        "268": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827940516218752,
                "model_info": "",
                "lineage": "26801"
            }
        ],
        "269": [],
        "270": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\ndef tuso_model(adata, k=10):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    if 'label' in adata.obs.columns:\n        feature_importances = SelectKBest(score_func=f_classif, k=k).fit(data, adata.obs['label'])\n        top_k_features = feature_importances.get_support(indices=True)\n        print(\"Top-k feature importances:\", top_k_features)\n    else:\n        print(\"Warning: 'label' column not found in adata.obs.\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "Warning: 'label' column not found in adata.obs.",
                "lineage": "27001"
            }
        ],
        "271": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='random', random_state=0, max_iter=200, tol=1e-4)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = np.maximum(adjusted_denoised_data, 0)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8169290976779409,
                "model_info": "",
                "lineage": "27101"
            }
        ],
        "272": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neighbors import KNeighborsRegressor\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    knn_imputer.fit(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1), adjusted_denoised_data)\n    imputed_data = knn_imputer.predict(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1))\n\n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.804792616593059,
                "model_info": "",
                "lineage": "27201"
            }
        ],
        "273": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.7827940516218752,
                "model_info": "",
                "lineage": "27301"
            }
        ],
        "274": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "",
                "lineage": "27401"
            }
        ],
        "275": [],
        "276": [],
        "277": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(data)\n    model = NMF(n_components=15, init='nndsvd', random_state=0, max_iter=400)\n\n    start_time = time.time()\n    print(\"Starting model fitting...\")\n    \n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    for i in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        \n        elapsed_time = time.time() - start_time\n        print(f\"Iteration {i + 1}/5 completed in {elapsed_time:.2f} seconds.\")\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8216738662818659,
                "model_info": "Starting model fitting...\nIteration 1/5 completed in 33.49 seconds.\nIteration 2/5 completed in 49.42 seconds.\nIteration 3/5 completed in 63.43 seconds.\nIteration 4/5 completed in 78.67 seconds.\nIteration 5/5 completed in 94.22 seconds.",
                "lineage": "27701"
            }
        ],
        "278": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n\n    imputer = KNNImputer(n_neighbors=5)\n    denoised_data = imputer.fit_transform(denoised_data)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.7783194834776318,
                "model_info": "",
                "lineage": "27801"
            }
        ],
        "279": [],
        "280": [],
        "281": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom scipy.stats import skew, kurtosis\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    print(\"Skewness:\", skew(data, axis=0))\n    print(\"Kurtosis:\", kurtosis(data, axis=0))\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=15, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.821998599680993,
                "model_info": "Skewness: [ 4.12450097  6.08026188 11.52746348 ...  2.20377489  2.27000248\n  2.71955446]\nKurtosis: [ 30.29719288  38.47724145 130.88241427 ...   5.67970706   5.13692742\n   7.0007622 ]",
                "lineage": "28101"
            }
        ],
        "282": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport networkx as nx\nfrom sklearn.neighbors import NearestNeighbors\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n\n    adata.obsm[\"denoised\"] = denoised_data\n\n    knn = NearestNeighbors(n_neighbors=5, algorithm='auto').fit(adata.obsm[\"denoised\"])\n    distances, indices = knn.kneighbors(adata.obsm[\"denoised\"])\n    imputed_data = np.zeros_like(adata.obsm[\"denoised\"])\n\n    for i in range(adata.obsm[\"denoised\"].shape[0]):\n        imputed_data[i] = np.mean(adata.obsm[\"denoised\"][indices[i]], axis=0)\n\n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.7795977620968342,
                "model_info": "",
                "lineage": "28201"
            }
        ],
        "283": [],
        "284": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_data = data * (1 - dropout_rate)\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(adjusted_data)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    for _ in range(5):\n        W = model.fit_transform(adjusted_data)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.8092520226300748,
                "model_info": "",
                "lineage": "28401"
            }
        ],
        "285": [],
        "286": [],
        "287": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.cluster import AgglomerativeClustering\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    clustering = AgglomerativeClustering(n_clusters=5)\n    cluster_labels = clustering.fit_predict(adjusted_denoised_data)\n\n    for cluster in np.unique(cluster_labels):\n        cluster_mask = (cluster_labels == cluster)\n        cluster_data = adjusted_denoised_data[cluster_mask]\n        cluster_dropout_rate = np.clip(np.mean(noise_model[cluster_mask] == 0, axis=0), 0.01, 0.99)\n        adjusted_denoised_data[cluster_mask] = cluster_data * (1 - cluster_dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.8215892740399361,
                "model_info": "",
                "lineage": "28701"
            }
        ],
        "288": [],
        "289": [],
        "290": [],
        "291": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    if 'batch' in adata.obs.columns:\n        batch_labels = adata.obs['batch'].values\n    else:\n        batch_labels = None\n    \n    data_corrected = data\n    noise_model = np.random.poisson(data_corrected)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "",
                "lineage": "29101"
            }
        ],
        "292": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import normalize\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    data = normalize(data, axis=0)\n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.7560048437472111,
                "model_info": "",
                "lineage": "29201"
            }
        ],
        "293": [],
        "294": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "",
                "lineage": "29401"
            }
        ],
        "295": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom scipy.stats import skew, kurtosis\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    print(\"Dataset Statistics:\")\n    print(f\"Mean: {np.mean(data, axis=0)}\")\n    print(f\"Std Dev: {np.std(data, axis=0)}\")\n    print(f\"Skewness: {skew(data, axis=0)}\")\n    print(f\"Kurtosis: {kurtosis(data, axis=0)}\")\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "Dataset Statistics:\nMean: [0.22539098 0.02943882 0.00735971 ... 0.73413063 0.23735051 0.13707452]\nStd Dev: [0.55413409 0.17439067 0.08547245 ... 1.21178047 0.51541426 0.37465212]\nSkewness: [ 4.12450097  6.08026188 11.52746348 ...  2.20377489  2.27000248\n  2.71955446]\nKurtosis: [ 30.29719288  38.47724145 130.88241427 ...   5.67970706   5.13692742\n   7.0007622 ]",
                "lineage": "29501"
            }
        ],
        "296": [],
        "297": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import StandardScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, solver='mu', max_iter=500, tol=1e-4)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8209517667328718,
                "model_info": "",
                "lineage": "29701"
            }
        ],
        "298": [],
        "299": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    for _ in range(5):\n        W = model.fit_transform(adjusted_denoised_data)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8206226725926292,
                "model_info": "",
                "lineage": "29901"
            }
        ],
        "300": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    for i in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        \n        outliers = np.abs((adjusted_denoised_data - np.mean(adjusted_denoised_data, axis=0)) / np.std(adjusted_denoised_data, axis=0)) > 3\n        print(f\"Iteration {i+1}: Detected outliers count: {np.sum(outliers)}\")\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "Iteration 1: Detected outliers count: 139874\nIteration 2: Detected outliers count: 90861\nIteration 3: Detected outliers count: 57636\nIteration 4: Detected outliers count: 36045\nIteration 5: Detected outliers count: 25037",
                "lineage": "30001"
            }
        ],
        "301": [],
        "302": [],
        "303": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport torch\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n    print(f\"PyTorch version: {torch.__version__}\")\n    print(f\"NMF components: {model.n_components}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "Device: CPU\nPyTorch version: 2.6.0+cu124\nNMF components: 20",
                "lineage": "30301"
            }
        ],
        "304": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neighbors import KNeighborsRegressor\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    knn_imputer.fit(np.arange(adjusted_denoised_data.shape[1]).reshape(-1, 1), adjusted_denoised_data.T)\n    imputed_data = knn_imputer.predict(np.arange(adjusted_denoised_data.shape[1]).reshape(-1, 1)).T\n\n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.7333069388702494,
                "model_info": "",
                "lineage": "30401"
            }
        ],
        "305": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = RobustScaler()\n    data = scaler.fit_transform(data)\n\n    data = np.clip(data, 0, None)\n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.6695355586088365,
                "model_info": "",
                "lineage": "30501"
            }
        ],
        "306": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.7783194834776317,
                "model_info": "",
                "lineage": "30601"
            }
        ],
        "307": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    data = adata.obsm[\"train\"].copy()\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    print(f\"Dataset shape: {data.shape}\")\n    print(f\"Mean expression: {np.mean(data[data > 0])}\")\n    print(f\"Zero count proportion: {np.mean(data == 0)}\")\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=15, init='nndsvd', max_iter=500, random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXX.py",
                "accuracy": 0.821998599680993,
                "model_info": "Dataset shape: (1087, 15099)\nMean expression: 3.242485336102662\nZero count proportion: 0.8629467471145514",
                "lineage": "30701"
            }
        ],
        "308": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(data)\n    \n    noise_model = np.random.poisson(imputed_data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "",
                "lineage": "30801"
            }
        ],
        "309": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n\n    for _ in range(5):\n        noise_model = np.random.poisson(denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n\n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.7783194834776318,
                "model_info": "",
                "lineage": "30901"
            }
        ],
        "310": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0, max_iter=500)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n\n    trainable_params = np.prod(model.components_.shape)\n    print(f\"Trainable Parameters: {trainable_params}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.821655998079153,
                "model_info": "Trainable Parameters: 301980",
                "lineage": "31001"
            }
        ],
        "311": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n\n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.7783194834776318,
                "model_info": "",
                "lineage": "31101"
            }
        ],
        "312": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8191225238706029,
                "model_info": "",
                "lineage": "31201"
            }
        ],
        "313": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n\n    if 'batch' in adata.obs.columns:\n        batch_labels = adata.obs['batch'].values\n        data = data - np.mean(data, axis=0)  # Simple batch effect correction\n\n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "",
                "lineage": "31301"
            }
        ],
        "314": [],
        "315": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n\n    for _ in range(5):\n        noise_model = np.random.poisson(denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.7783194834776317,
                "model_info": "",
                "lineage": "31501"
            }
        ],
        "316": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.7783194834776317,
                "model_info": "",
                "lineage": "31601"
            }
        ],
        "317": [],
        "318": [],
        "319": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    gene_mean = np.mean(data, axis=0)\n    gene_std = np.std(data, axis=0)\n    high_quality_genes = (gene_std > 0) & (gene_mean > 0)\n    data = data[:, high_quality_genes]\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "",
                "lineage": "31901"
            }
        ],
        "320": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    print(f\"Initial dropout rates: {dropout_rate}\")\n    \n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "Initial dropout rates: [0.87580497 0.98620055 0.99       ... 0.70377185 0.86660534 0.92088316]",
                "lineage": "32001"
            }
        ],
        "321": [],
        "322": [],
        "323": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(noise_model)\n    H = model.components_\n\n    denoised_data = np.dot(W, H)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    for _ in range(5):\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXX.py",
                "accuracy": 0.8217531618734775,
                "model_info": "",
                "lineage": "32301"
            }
        ],
        "324": [],
        "325": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "32501"
            }
        ],
        "326": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\n\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.fc2 = nn.Linear(128, input_dim)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    input_tensor = torch.tensor(adjusted_denoised_data, dtype=torch.float32)\n    nn_model = SimpleNN(input_tensor.shape[1])\n    optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001)\n    criterion = nn.MSELoss()\n\n    for epoch in range(100):\n        nn_model.train()\n        optimizer.zero_grad()\n        output = nn_model(input_tensor)\n        loss = criterion(output, input_tensor)\n        loss.backward()\n        optimizer.step()\n\n    denoised_data = output.detach().numpy()\n    adata.obsm[\"denoised\"] = np.maximum(denoised_data, 0)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.5453400883806603,
                "model_info": "",
                "lineage": "32601"
            }
        ],
        "327": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.7791803362609696,
                "model_info": "",
                "lineage": "32701"
            }
        ],
        "328": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        noise_model = np.random.poisson(data)\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.809625914980924,
                "model_info": "",
                "lineage": "32801"
            }
        ],
        "329": [],
        "330": [],
        "331": [],
        "332": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neighbors import NearestNeighbors\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        \n        knn = NearestNeighbors(n_neighbors=5)\n        knn.fit(denoised_data)\n        imputed_data_indices = knn.kneighbors(denoised_data, return_distance=False)\n        \n        adjusted_denoised_data = np.copy(denoised_data)\n        for i in range(denoised_data.shape[0]):\n            adjusted_denoised_data[i, denoised_data[i] == 0] = np.mean(denoised_data[imputed_data_indices[i]], axis=0)[denoised_data[i] == 0]\n        \n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.7788975868925778,
                "model_info": "",
                "lineage": "33201"
            }
        ],
        "333": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neighbors import NearestNeighbors\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0, max_iter=500)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n    \n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    noise_model = np.random.poisson(adjusted_denoised_data)\n\n    knn = NearestNeighbors(n_neighbors=5)\n    knn.fit(adjusted_denoised_data)\n    imputed_values = knn.kneighbors(adjusted_denoised_data, return_distance=False)\n    \n    for i in range(adjusted_denoised_data.shape[1]):\n        zero_indices = np.where(adjusted_denoised_data[:, i] == 0)[0]\n        if len(zero_indices) > 0:\n            adjusted_denoised_data[zero_indices, i] = np.mean(adjusted_denoised_data[imputed_values[zero_indices], i], axis=1)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8171150765435173,
                "model_info": "",
                "lineage": "33301"
            }
        ],
        "334": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neighbors import KNeighborsRegressor\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n    \n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    \n    knn = KNeighborsRegressor(n_neighbors=5, weights='uniform', metric='euclidean')\n    mask = (adjusted_denoised_data == 0)\n    \n    for i in range(adjusted_denoised_data.shape[1]):\n        if np.any(mask[:, i]):\n            knn.fit(np.arange(adjusted_denoised_data.shape[0]).reshape(-1, 1), adjusted_denoised_data[:, i])\n            adjusted_denoised_data[mask[:, i], i] = knn.predict(np.arange(adjusted_denoised_data.shape[0])[mask[:, i]].reshape(-1, 1))\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8168628061815779,
                "model_info": "",
                "lineage": "33401"
            }
        ],
        "335": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import class_weight\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 18)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0, max_iter=500)\n    \n    class_balance_before = np.mean(data != 0, axis=0)\n    print(\"Class balance before resampling:\", class_balance_before)\n\n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    class_balance_after = np.mean(adjusted_denoised_data != 0, axis=0)\n    print(\"Class balance after resampling:\", class_balance_after)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.822842218397878,
                "model_info": "Class balance before resampling: [0.1849126  0.02851886 0.00735971 ... 0.39098436 0.19871205 0.12603496]\nClass balance after resampling: [0.         0.         0.         ... 0.99356026 0.         0.        ]",
                "lineage": "33501"
            }
        ],
        "336": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    epoch_loss = []\n    validation_score = []\n    \n    for epoch in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        \n        loss = model.reconstruction_err_\n        epoch_loss.append(loss)\n        validation_score.append(np.mean((data - adjusted_denoised_data) ** 2))\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    print(f'Epoch Loss: {epoch_loss}, Validation Score: {validation_score}')\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Epoch Loss: [np.float64(4025.3663611136917), np.float64(1908.496672524037), np.float64(1679.6818893013738), np.float64(1574.2266394199048), np.float64(1504.4505441987278)], Validation Score: [np.float64(23.55963910794978), np.float64(36.324061787874165), np.float64(40.28405203485242), np.float64(41.48777288327978), np.float64(41.965435855118635)]",
                "lineage": "33601"
            }
        ],
        "337": [],
        "338": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = data.copy()\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = adjusted_denoised_data.copy()\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.821094114341017,
                "model_info": "",
                "lineage": "33801"
            }
        ],
        "339": [],
        "340": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    noise_model = np.random.poisson(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "34001"
            }
        ],
        "341": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for i in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        print(f\"Iteration {i+1}: Rank={rank}, Dropout Rate={dropout_rate.mean():.4f}, Denoised Shape={adjusted_denoised_data.shape}\")\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Iteration 1: Rank=20, Dropout Rate=0.8979, Denoised Shape=(1087, 15099)\nIteration 2: Rank=20, Dropout Rate=0.8979, Denoised Shape=(1087, 15099)\nIteration 3: Rank=20, Dropout Rate=0.8979, Denoised Shape=(1087, 15099)\nIteration 4: Rank=20, Dropout Rate=0.8979, Denoised Shape=(1087, 15099)\nIteration 5: Rank=20, Dropout Rate=0.8979, Denoised Shape=(1087, 15099)",
                "lineage": "34101"
            }
        ],
        "342": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.metrics import confusion_matrix\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    true_labels = np.argmax(data, axis=1)\n    predicted_labels = np.argmax(adjusted_denoised_data, axis=1)\n    cm = confusion_matrix(true_labels, predicted_labels)\n    print(\"Confusion Matrix:\\n\", cm)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Confusion Matrix:\n [[  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n [  1   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n [  1   1   0   0   0   0   0   0   0   3   0   0   0   0   0   0]\n [  0   0   0   2   0   0   0   0   0   1   0   0   0   0   0   0]\n [  0   0   0   0   7   0   0   0   0   3   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0]\n [  0   1   0   2   0   0   0   0   0   5   0   0   0   0   0   0]\n [  1   0   0   0   0   1   0   0   0   1   0   0   0   0   0   0]\n [  0   1   0   6   2   0   0   0   0 891   0   0   1   0   0   5]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4]\n [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n [  0   1   0   1   1   3   0   0   0  27   0   0   0   0   0   0]\n [  3   1   0   2   3   3   0   0   0  90   0   0   0   0   0   3]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1]]",
                "lineage": "34201"
            }
        ],
        "343": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n    \n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "34301"
            }
        ],
        "344": [],
        "345": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = StandardScaler()\n    data_scaled = scaler.fit_transform(data)\n    \n    data_scaled = np.clip(data_scaled, 0, None)\n    noise_model = np.random.poisson(data_scaled)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data_scaled), 18)\n    model = NMF(n_components=rank, init='nndsvd', max_iter=500, random_state=0)\n    \n    best_hyperparams = {'n_components': rank, 'init': 'nndsvd', 'max_iter': 500, 'random_state': 0}\n    print(f\"Best Hyper-parameter Configuration: {best_hyperparams}\")\n\n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.7249936751313787,
                "model_info": "Best Hyper-parameter Configuration: {'n_components': 18, 'init': 'nndsvd', 'max_iter': 500, 'random_state': 0}",
                "lineage": "34501"
            }
        ],
        "346": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom scipy.stats import zscore\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 18)\n    model = NMF(n_components=rank, init='nndsvd', max_iter=500, random_state=0)\n    \n    scaler = RobustScaler()\n    scaled_data = scaler.fit_transform(noise_model)\n    \n    for _ in range(5):\n        W = model.fit_transform(np.maximum(scaled_data, 0))\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(np.maximum(adjusted_denoised_data, 0))\n    \n    z_scores = zscore(adjusted_denoised_data, axis=0)\n    outliers_count = np.sum(np.abs(z_scores) > 3, axis=0)\n    print(f'Counts of detected outliers based on z-score analysis: {outliers_count}')\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.6210223751463508,
                "model_info": "Counts of detected outliers based on z-score analysis: [ 9 19  4 ... 16 13 14]",
                "lineage": "34601"
            }
        ],
        "347": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    missing_mask = (data == 0)\n    adjusted_denoised_data[missing_mask] = np.nan\n    adata.obsm[\"denoised\"] = np.nan_to_num(adjusted_denoised_data)\n\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8230107623186926,
                "model_info": "",
                "lineage": "34701"
            }
        ],
        "348": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_selection import VarianceThreshold\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    variance_filter = VarianceThreshold(threshold=0.1)\n    filtered_data = variance_filter.fit_transform(data)\n    \n    rank = min(np.linalg.matrix_rank(filtered_data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "34801"
            }
        ],
        "349": [],
        "350": [],
        "351": [],
        "352": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 18)\n    model = NMF(n_components=rank, init='nndsvd', max_iter=500, random_state=0)\n    \n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(data)\n    \n    feature_means_before = np.mean(data, axis=0)\n    feature_stds_before = np.std(data, axis=0)\n    feature_mins_before = np.min(data, axis=0)\n    feature_maxs_before = np.max(data, axis=0)\n\n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    feature_means_after = np.mean(adjusted_denoised_data, axis=0)\n    feature_stds_after = np.std(adjusted_denoised_data, axis=0)\n    feature_mins_after = np.min(adjusted_denoised_data, axis=0)\n    feature_maxs_after = np.max(adjusted_denoised_data, axis=0)\n\n    print(\"Before Scaling - Mean:\", feature_means_before, \"Std:\", feature_stds_before, \"Min:\", feature_mins_before, \"Max:\", feature_maxs_before)\n    print(\"After Scaling - Mean:\", feature_means_after, \"Std:\", feature_stds_after, \"Min:\", feature_mins_after, \"Max:\", feature_maxs_after)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.822842218397878,
                "model_info": "Before Scaling - Mean: [0.22539098 0.02943882 0.00735971 ... 0.73413063 0.23735051 0.13707452] Std: [0.55413409 0.17439067 0.08547245 ... 1.21178047 0.51541426 0.37465212] Min: [0. 0. 0. ... 0. 0. 0.] Max: [7. 2. 1. ... 8. 3. 2.]\nAfter Scaling - Mean: [0.         0.         0.         ... 0.00130419 0.         0.        ] Std: [0.         0.         0.         ... 0.00134932 0.         0.        ] Min: [0. 0. 0. ... 0. 0. 0.] Max: [0.         0.         0.         ... 0.00674024 0.         0.        ]",
                "lineage": "35201"
            }
        ],
        "353": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(data)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "35301"
            }
        ],
        "354": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.cluster import KMeans\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        \n        kmeans = KMeans(n_clusters=5, random_state=0).fit(denoised_data)\n        cluster_labels = kmeans.labels_\n        \n        adjusted_denoised_data = np.zeros_like(denoised_data)\n        for cluster in np.unique(cluster_labels):\n            cluster_mask = (cluster_labels == cluster)\n            cluster_dropout_rate = np.mean(dropout_rate)\n            adjusted_denoised_data[cluster_mask] = denoised_data[cluster_mask] * (1 - cluster_dropout_rate)\n        \n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.7389404010499396,
                "model_info": "",
                "lineage": "35401"
            }
        ],
        "355": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom scipy.stats import skew, kurtosis\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    print(\"Dataset Statistics:\")\n    print(f\"Shape: {data.shape}\")\n    print(f\"Mean: {np.mean(data, axis=0)}\")\n    print(f\"Std Dev: {np.std(data, axis=0)}\")\n    print(f\"Min: {np.min(data, axis=0)}\")\n    print(f\"Max: {np.max(data, axis=0)}\")\n    print(f\"Dropout Rate: {np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)}\")\n    print(f\"Skewness: {skew(data, axis=0)}\")\n    print(f\"Kurtosis: {kurtosis(data, axis=0)}\")\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Dataset Statistics:\nShape: (1087, 15099)\nMean: [0.22539098 0.02943882 0.00735971 ... 0.73413063 0.23735051 0.13707452]\nStd Dev: [0.55413409 0.17439067 0.08547245 ... 1.21178047 0.51541426 0.37465212]\nMin: [0. 0. 0. ... 0. 0. 0.]\nMax: [7. 2. 1. ... 8. 3. 2.]\nDropout Rate: [0.8150874  0.97148114 0.99       ... 0.60901564 0.80128795 0.87396504]\nSkewness: [ 4.12450097  6.08026188 11.52746348 ...  2.20377489  2.27000248\n  2.71955446]\nKurtosis: [ 30.29719288  38.47724145 130.88241427 ...   5.67970706   5.13692742\n   7.0007622 ]",
                "lineage": "35501"
            }
        ],
        "356": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.cluster import AgglomerativeClustering\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    clustering = AgglomerativeClustering(n_clusters=5)\n    clusters = clustering.fit_predict(denoised_data.T)\n    \n    cluster_dropout_rates = np.array([np.mean(adjusted_denoised_data[:, clusters == i] == 0) for i in range(5)])\n    \n    for i in range(5):\n        adjusted_denoised_data[:, clusters == i] *= (1 - cluster_dropout_rates[i])\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8232938503343911,
                "model_info": "",
                "lineage": "35601"
            }
        ],
        "357": [],
        "358": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef layer_normalization(X):\n    mean = np.mean(X, axis=1, keepdims=True)\n    std = np.std(X, axis=1, keepdims=True)\n    return (X - mean) / (std + 1e-8)\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0, max_iter=500)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        adjusted_denoised_data = layer_normalization(adjusted_denoised_data)\n        adjusted_denoised_data = np.clip(adjusted_denoised_data, 0, None)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8187342294011672,
                "model_info": "",
                "lineage": "35801"
            }
        ],
        "359": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n    \n    denoised_data = denoised_data * (1 - dropout_rate)\n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "35901"
            }
        ],
        "360": [],
        "361": [],
        "362": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import FunctionTransformer\n\ndef log_transform(X):\n    return np.log1p(X)\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    transformer = FunctionTransformer(func=log_transform, validate=True)\n    data = transformer.fit_transform(data)\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8091780595599667,
                "model_info": "",
                "lineage": "36201"
            }
        ],
        "363": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.metrics import adjusted_rand_score\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "36301"
            }
        ],
        "364": [],
        "365": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 18)\n    model = NMF(n_components=rank, init='nndsvd', max_iter=500, random_state=0)\n    \n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(data)\n    \n    for epoch in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        \n        if epoch == 0:\n            print(f\"Initial dropout rates: {dropout_rate}\")\n        print(f\"Epoch {epoch + 1}: Reconstruction error = {np.linalg.norm(scaled_data - adjusted_denoised_data)}\")\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.822842218397878,
                "model_info": "Initial dropout rates: [0.87580497 0.98620055 0.99       ... 0.70377185 0.86660534 0.92088316]\nEpoch 1: Reconstruction error = 16933.245665515304\nEpoch 2: Reconstruction error = 15434.153093119585\nEpoch 3: Reconstruction error = 15149.750823089928\nEpoch 4: Reconstruction error = 14998.872912850837\nEpoch 5: Reconstruction error = 14853.348823259152",
                "lineage": "36501"
            }
        ],
        "366": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.cluster import KMeans\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        \n        kmeans = KMeans(n_clusters=5, random_state=0)\n        cluster_labels = kmeans.fit_predict(denoised_data)\n        \n        for cluster in np.unique(cluster_labels):\n            cluster_mask = (cluster_labels == cluster)\n            cluster_dropout_rate = np.clip(np.mean(noise_model[cluster_mask] == 0, axis=0), 0.01, 0.99)\n            adjusted_denoised_data = denoised_data[cluster_mask] * (1 - cluster_dropout_rate)\n            denoised_data[cluster_mask] = adjusted_denoised_data\n        \n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8225918279289438,
                "model_info": "",
                "lineage": "36601"
            }
        ],
        "367": [],
        "368": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        \n        n_clusters = 5\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(denoised_data)\n        cluster_labels = kmeans.labels_\n        \n        adjusted_denoised_data = np.zeros_like(denoised_data)\n        for cluster in range(n_clusters):\n            cluster_indices = np.where(cluster_labels == cluster)[0]\n            cluster_dropout_rate = np.clip(np.mean(noise_model[cluster_indices] == 0, axis=0), 0.01, 0.99)\n            adjusted_denoised_data[cluster_indices] = denoised_data[cluster_indices] * (1 - cluster_dropout_rate)\n        \n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8225918279289438,
                "model_info": "",
                "lineage": "36801"
            }
        ],
        "369": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    print(f\"Assumptions: Data follows Poisson distribution with dropout rates between {dropout_rate}.\")\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Assumptions: Data follows Poisson distribution with dropout rates between [0.87580497 0.98620055 0.99       ... 0.70377185 0.86660534 0.92088316].",
                "lineage": "36901"
            }
        ],
        "370": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(data)\n    \n    noise_model = np.random.poisson(scaled_data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 18)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0, max_iter=500)\n    \n    start_time = time.time()\n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n    end_time = time.time()\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    print(f\"Data loading time: {end_time - start_time:.4f} seconds\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.7559678190952667,
                "model_info": "Data loading time: 33.6375 seconds",
                "lineage": "37001"
            }
        ],
        "371": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(data)\n    \n    noise_model = np.random.poisson(scaled_data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(scaled_data), 20)\n    model = NMF(n_components=rank, init='nndsvd', max_iter=300, random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    feature_importances = np.sum(H, axis=0)\n    top_k_indices = np.argsort(feature_importances)[-10:][::-1]\n    top_k_importances = feature_importances[top_k_indices]\n    \n    print(\"Top-k feature importances:\", dict(zip(top_k_indices, top_k_importances)))\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.7559772374367448,
                "model_info": "Top-k feature importances: {np.int64(13403): np.float64(1.8138274902267784), np.int64(11123): np.float64(1.7188090567897516), np.int64(9972): np.float64(1.5588227519739886), np.int64(11141): np.float64(1.5146836112146767), np.int64(11198): np.float64(1.4686560624958611), np.int64(7809): np.float64(1.430351072830896), np.int64(4661): np.float64(1.4142135623730947), np.int64(11120): np.float64(1.2966561398827996), np.int64(11165): np.float64(1.2660198155638651), np.int64(2618): np.float64(1.1159209237143786)}",
                "lineage": "37101"
            }
        ],
        "372": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    scaler = RobustScaler()\n    data_scaled = scaler.fit_transform(data)\n    \n    rank = min(np.linalg.matrix_rank(data_scaled), 20)\n    model = NMF(n_components=rank, init='nndsvd', max_iter=500, random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    mean_before = np.mean(data, axis=0)\n    std_before = np.std(data, axis=0)\n    min_before = np.min(data, axis=0)\n    max_before = np.max(data, axis=0)\n    \n    mean_after = np.mean(adjusted_denoised_data, axis=0)\n    std_after = np.std(adjusted_denoised_data, axis=0)\n    min_after = np.min(adjusted_denoised_data, axis=0)\n    max_after = np.max(adjusted_denoised_data, axis=0)\n    \n    print(f\"Before scaling: mean={mean_before}, std={std_before}, min={min_before}, max={max_before}\")\n    print(f\"After scaling: mean={mean_after}, std={std_after}, min={min_after}, max={max_after}\")\n\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.8227116938275294,
                "model_info": "Before scaling: mean=[0.22539098 0.02943882 0.00735971 ... 0.73413063 0.23735051 0.13707452], std=[0.55413409 0.17439067 0.08547245 ... 1.21178047 0.51541426 0.37465212], min=[0. 0. 0. ... 0. 0. 0.], max=[7. 2. 1. ... 8. 3. 2.]\nAfter scaling: mean=[8.15375695e-05 0.00000000e+00 0.00000000e+00 ... 1.99117346e-03\n 0.00000000e+00 0.00000000e+00], std=[5.05902921e-05 0.00000000e+00 0.00000000e+00 ... 1.39186233e-03\n 0.00000000e+00 0.00000000e+00], min=[0.         0.         0.         ... 0.00017766 0.         0.        ], max=[0.00042703 0.         0.         ... 0.0121202  0.         0.        ]",
                "lineage": "37201"
            }
        ],
        "373": [],
        "374": [],
        "375": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    logging.info(\"Environment: Device: %s, Library Versions: Numpy %s, Scikit-learn %s\", \n                 \"CPU/GPU\", np.__version__, NMF.__module__)\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for i in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        logging.info(\"Iteration %d: Denoised Data Shape: %s\", i+1, adjusted_denoised_data.shape)\n\n    nan_count = np.isnan(adjusted_denoised_data).sum()\n    inf_count = np.isinf(adjusted_denoised_data).sum()\n    logging.info(\"NaN Count: %d, Inf Count: %d\", nan_count, inf_count)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "37501"
            }
        ],
        "376": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for iteration in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        \n        if iteration % 1 == 0:\n            print(f\"Iteration: {iteration}, Max Update Magnitude: {np.max(np.abs(W @ H - noise_model)):.4f}, Dropout Rate: {np.mean(dropout_rate):.4f}\")\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Iteration: 0, Max Update Magnitude: 9147.3459, Dropout Rate: 0.8979\nIteration: 1, Max Update Magnitude: 2363.8678, Dropout Rate: 0.8979\nIteration: 2, Max Update Magnitude: 589.8520, Dropout Rate: 0.8979\nIteration: 3, Max Update Magnitude: 150.6278, Dropout Rate: 0.8979\nIteration: 4, Max Update Magnitude: 53.0682, Dropout Rate: 0.8979",
                "lineage": "37601"
            }
        ],
        "377": [],
        "378": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.7791803362609696,
                "model_info": "",
                "lineage": "37801"
            }
        ],
        "379": [],
        "380": [],
        "381": [],
        "382": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\nimport resource\n\ndef tuso_model(adata):\n    start_time = time.time()\n    mem_usage_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    end_time = time.time()\n    mem_usage_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n    \n    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n    print(f\"Memory usage: {mem_usage_end - mem_usage_start} KB\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Time taken: 48.22 seconds\nMemory usage: 1012180 KB",
                "lineage": "38201"
            }
        ],
        "383": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.impute import SimpleImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0, max_iter=500)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    imputer = SimpleImputer(strategy='mean')\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n\n    knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n    knn.fit(adjusted_denoised_data)\n    imputed_values = knn.kneighbors(adjusted_denoised_data, return_distance=False)\n    \n    for i in range(adjusted_denoised_data.shape[1]):\n        if np.isnan(adjusted_denoised_data[:, i]).any():\n            adjusted_denoised_data[np.isnan(adjusted_denoised_data[:, i]), i] = np.nanmean(adjusted_denoised_data[imputed_values[:, i], i])\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8227116938275294,
                "model_info": "",
                "lineage": "38301"
            }
        ],
        "384": [],
        "385": [],
        "386": [],
        "387": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for iteration in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        missing_counts = np.sum(adjusted_denoised_data == 0, axis=0)\n        low_confidence_percentage = np.mean(adjusted_denoised_data < 1e-3) * 100\n        logging.info(f'Iteration {iteration + 1}: Missing values per feature: {missing_counts}, Low-confidence predictions: {low_confidence_percentage:.2f}%')\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "38701"
            }
        ],
        "388": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    logging.info(\"Starting model optimization for single cell RNA-seq imputation.\")\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    correlated_features = np.where(np.corrcoef(data, rowvar=False) > 0.9)\n    logging.info(f\"Highly correlated features: {correlated_features}\")\n\n    logging.info(\"Denoised data stored in adata.obsm['denoised'].\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "38801"
            }
        ],
        "389": [],
        "390": [],
        "391": [],
        "392": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "39201"
            }
        ],
        "393": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom sklearn.impute import KNNImputer\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "39301"
            }
        ],
        "394": [],
        "395": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    imputer = KNNImputer(n_neighbors=5)\n    final_imputed_data = imputer.fit_transform(adjusted_denoised_data)\n    adata.obsm[\"denoised\"] = final_imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "39501"
            }
        ],
        "396": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(data)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = np.clip(denoised_data, 0, None)\n        data = adjusted_denoised_data\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.7830612276837786,
                "model_info": "",
                "lineage": "39601"
            }
        ],
        "397": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n\n    if 'batch' in adata.obs:\n        batch_labels = adata.obs['batch'].values\n        pca = PCA(n_components=min(50, data.shape[1]))\n        data_pca = pca.fit_transform(data)\n        batch_means = np.array([data_pca[batch_labels == b].mean(axis=0) for b in np.unique(batch_labels)])\n        data_pca_corrected = data_pca - batch_means[batch_labels]\n        data = pca.inverse_transform(data_pca_corrected)\n\n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "39701"
            }
        ],
        "398": [],
        "399": [],
        "400": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import StandardScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0, max_iter=1000)\n    \n    low_confidence_threshold = 0.1\n    low_confidence_count = np.sum(dropout_rate > low_confidence_threshold)\n    total_genes = dropout_rate.shape[0]\n    low_confidence_percentage = (low_confidence_count / total_genes) * 100\n    print(f\"Low-confidence predictions: {low_confidence_percentage:.2f}%\")\n\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(noise_model)\n\n    for _ in range(5):\n        W = model.fit_transform(np.maximum(scaled_data, 0))\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.6375946311661653,
                "model_info": "Low-confidence predictions: 99.19%",
                "lineage": "40001"
            }
        ],
        "401": [],
        "402": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "40201"
            }
        ],
        "403": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n\n    knn_imputer = KNeighborsRegressor(n_neighbors=5)\n    nan_mask = np.isnan(adjusted_denoised_data)\n    if np.any(nan_mask):\n        X_train = adjusted_denoised_data[~nan_mask]\n        y_train = adjusted_denoised_data[~nan_mask]\n        knn_imputer.fit(X_train, y_train)\n        adjusted_denoised_data[nan_mask] = knn_imputer.predict(adjusted_denoised_data[nan_mask])\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "40301"
            }
        ],
        "404": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import QuantileTransformer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    transformer = QuantileTransformer(output_distribution='normal')\n    data = transformer.fit_transform(data)\n    \n    data = np.clip(data, 0, None)\n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        adjusted_denoised_data = np.clip(adjusted_denoised_data, 0, None)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.6884292639416452,
                "model_info": "",
                "lineage": "40401"
            }
        ],
        "405": [],
        "406": [],
        "407": [],
        "408": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = np.dot(denoised_data, np.diag(1 - dropout_rate))\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = np.maximum(adjusted_denoised_data, 0)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "40801"
            }
        ],
        "409": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neighbors import kneighbors_graph\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    adjacency_matrix = kneighbors_graph(data, n_neighbors=10, mode='connectivity', include_self=True)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "40901"
            }
        ],
        "410": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0, solver='mu', max_iter=500, tol=1e-4)\n\n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8220080316927583,
                "model_info": "",
                "lineage": "41001"
            }
        ],
        "411": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import QuantileTransformer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)\n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    transformer = QuantileTransformer(output_distribution='uniform')\n    adjusted_denoised_data = transformer.fit_transform(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.5237451140718091,
                "model_info": "",
                "lineage": "41101"
            }
        ],
        "412": [],
        "413": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 18)\n    model = NMF(n_components=rank, init='nndsvd', max_iter=500, random_state=0)\n    \n    scaler = RobustScaler()\n    scaled_data = scaler.fit_transform(data)\n    \n    for i in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        print(f\"Iteration {i+1}: W shape {W.shape}, H shape {H.shape}, adjusted_denoised_data shape {adjusted_denoised_data.shape}\")\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.822842218397878,
                "model_info": "Iteration 1: W shape (1087, 18), H shape (18, 15099), adjusted_denoised_data shape (1087, 15099)\nIteration 2: W shape (1087, 18), H shape (18, 15099), adjusted_denoised_data shape (1087, 15099)\nIteration 3: W shape (1087, 18), H shape (18, 15099), adjusted_denoised_data shape (1087, 15099)\nIteration 4: W shape (1087, 18), H shape (18, 15099), adjusted_denoised_data shape (1087, 15099)\nIteration 5: W shape (1087, 18), H shape (18, 15099), adjusted_denoised_data shape (1087, 15099)",
                "lineage": "41301"
            }
        ],
        "414": [],
        "415": [],
        "416": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\nimport platform\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    logging.info(f\"Environment: {platform.platform()}\")\n    logging.info(f\"Python version: {platform.python_version()}\")\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "41601"
            }
        ],
        "417": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for iteration in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        if iteration > 0:\n            param_change = np.linalg.norm(W - prev_W) + np.linalg.norm(H - prev_H)\n            print(f\"Iteration {iteration}: Parameter change magnitude = {param_change:.4f}\")\n        prev_W, prev_H = W, H\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Iteration 1: Parameter change magnitude = 704.5732\nIteration 2: Parameter change magnitude = 528.7963\nIteration 3: Parameter change magnitude = 374.9690\nIteration 4: Parameter change magnitude = 400.8555",
                "lineage": "41701"
            }
        ],
        "418": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import RobustScaler\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0, max_iter=500)\n    \n    scaler = RobustScaler()\n    scaled_data = scaler.fit_transform(noise_model)\n    \n    for _ in range(5):\n        W = model.fit_transform(np.maximum(scaled_data, 0))\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(np.maximum(adjusted_denoised_data, 0))\n        \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.6210545140687838,
                "model_info": "",
                "lineage": "41801"
            }
        ],
        "419": [],
        "420": [],
        "421": [],
        "422": [],
        "423": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neighbors import NearestNeighbors\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n\n    knn = NearestNeighbors(n_neighbors=5)\n    knn.fit(adjusted_denoised_data)\n    imputed_data = knn.kneighbors_graph(adjusted_denoised_data, mode='connectivity').toarray()\n    \n    for i in range(adjusted_denoised_data.shape[0]):\n        if np.any(np.isnan(adjusted_denoised_data[i])):\n            neighbors = np.where(imputed_data[i] > 0)[1]\n            adjusted_denoised_data[i, np.isnan(adjusted_denoised_data[i])] = np.mean(adjusted_denoised_data[neighbors, :][:, np.isnan(adjusted_denoised_data[i])], axis=0)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "42301"
            }
        ],
        "424": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import SimpleImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    imputer = SimpleImputer(strategy='mean')\n    imputed_data = imputer.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "42401"
            }
        ],
        "425": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    trainable_params = model.components_.size\n    frozen_params = 0\n    print(f\"Trainable vs Frozen Parameters Ratio: {trainable_params / (trainable_params + frozen_params):.2f}\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Trainable vs Frozen Parameters Ratio: 1.00",
                "lineage": "42501"
            }
        ],
        "426": [],
        "427": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels):\n        super(ResidualBlock, self).__init__()\n        self.linear1 = nn.Linear(in_channels, in_channels)\n        self.linear2 = nn.Linear(in_channels, in_channels)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        residual = x\n        x = self.relu(self.linear1(x))\n        x = self.linear2(x)\n        x += residual\n        return self.relu(x)\n\nclass Autoencoder(nn.Module):\n    def __init__(self, input_dim):\n        super(Autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            ResidualBlock(128),\n            nn.Linear(128, 64),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            ResidualBlock(128),\n            nn.Linear(128, input_dim),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    input_dim = data.shape[1]\n    model = Autoencoder(input_dim)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.MSELoss()\n    data_tensor = torch.FloatTensor(data)\n\n    for epoch in range(100):\n        optimizer.zero_grad()\n        output = model(data_tensor)\n        loss = criterion(output, data_tensor)\n        loss.backward()\n        optimizer.step()\n\n    denoised_data = output.detach().numpy()\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n    adata.obsm[\"denoised\"] = np.maximum(adjusted_denoised_data, 0)\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.6414638308349779,
                "model_info": "",
                "lineage": "42701"
            }
        ],
        "428": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport time\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    stage_summaries = []\n    for i in range(5):\n        start_time = time.time()\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n        stage_summaries.append(f\"Stage {i+1}: Denoised Data Shape: {adjusted_denoised_data.shape}, Time Taken: {time.time() - start_time:.4f} seconds\")\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    print(\"\\n\".join(stage_summaries))\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Stage 1: Denoised Data Shape: (1087, 15099), Time Taken: 9.2242 seconds\nStage 2: Denoised Data Shape: (1087, 15099), Time Taken: 10.0302 seconds\nStage 3: Denoised Data Shape: (1087, 15099), Time Taken: 9.1226 seconds\nStage 4: Denoised Data Shape: (1087, 15099), Time Taken: 8.5535 seconds\nStage 5: Denoised Data Shape: (1087, 15099), Time Taken: 9.0576 seconds",
                "lineage": "42801"
            }
        ],
        "429": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    W = model.fit_transform(noise_model)\n    H = model.components_\n    denoised_data = np.dot(W, H)\n    adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8170983081223212,
                "model_info": "",
                "lineage": "42901"
            }
        ],
        "430": [],
        "431": [],
        "432": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.neighbors import kneighbors_graph\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    k_neighbors = 15\n    adjacency_matrix = kneighbors_graph(data, n_neighbors=k_neighbors, mode='connectivity', include_self=False)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "43201"
            }
        ],
        "433": [],
        "434": [],
        "435": [],
        "436": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        dropout_rate = np.clip(np.mean(adjusted_denoised_data == 0, axis=0), 0.01, 0.99)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.8119563682010876,
                "model_info": "",
                "lineage": "43601"
            }
        ],
        "437": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='random', random_state=0, max_iter=200, tol=1e-4)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82272579196378,
                "model_info": "",
                "lineage": "43701"
            }
        ],
        "438": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import QuantileTransformer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        adjusted_denoised_data = denoised_data * (1 - dropout_rate)\n        noise_model = np.random.poisson(adjusted_denoised_data)\n\n    qt = QuantileTransformer(output_distribution='uniform')\n    adjusted_denoised_data = qt.fit_transform(adjusted_denoised_data)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.5237451140718091,
                "model_info": "",
                "lineage": "43801"
            }
        ],
        "439": [],
        "440": [],
        "441": [],
        "442": [],
        "443": [],
        "444": [],
        "445": [],
        "446": [],
        "447": [],
        "448": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "44801"
            }
        ],
        "449": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(data)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "44901"
            }
        ],
        "450": [],
        "451": [],
        "452": [],
        "453": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    batch_labels = a.obs['batch'].values if 'batch' in a.obs else None\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "45301"
            }
        ],
        "454": [],
        "455": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    original_mean = np.mean(data, axis=0)\n    original_std = np.std(data, axis=0)\n    original_min = np.min(data, axis=0)\n    original_max = np.max(data, axis=0)\n\n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    denoised_mean = np.mean(denoised_data, axis=0)\n    denoised_std = np.std(denoised_data, axis=0)\n    denoised_min = np.min(denoised_data, axis=0)\n    denoised_max = np.max(denoised_data, axis=0)\n\n    print(f\"Original Mean: {original_mean}, Denoised Mean: {denoised_mean}\")\n    print(f\"Original Std: {original_std}, Denoised Std: {denoised_std}\")\n    print(f\"Original Min: {original_min}, Denoised Min: {denoised_min}\")\n    print(f\"Original Max: {original_max}, Denoised Max: {denoised_max}\")\n\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "Original Mean: [0.22539098 0.02943882 0.00735971 ... 0.73413063 0.23735051 0.13707452], Denoised Mean: [0.00015518 0.         0.         ... 0.00287987 0.         0.        ]\nOriginal Std: [0.55413409 0.17439067 0.08547245 ... 1.21178047 0.51541426 0.37465212], Denoised Std: [0.00011563 0.         0.         ... 0.00225296 0.         0.        ]\nOriginal Min: [0. 0. 0. ... 0. 0. 0.], Denoised Min: [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.15209104e-05\n 0.00000000e+00 0.00000000e+00]\nOriginal Max: [7. 2. 1. ... 8. 3. 2.], Denoised Max: [0.00084969 0.         0.         ... 0.01778752 0.         0.        ]",
                "lineage": "45501"
            }
        ],
        "456": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport matplotlib.pyplot as plt\nimport time\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    inference_latencies = []\n    for _ in range(5):\n        start_time = time.time()\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        inference_latencies.append(time.time() - start_time)\n        \n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    plt.hist(inference_latencies, bins=10)\n    plt.title('Inference Latency Distribution')\n    plt.xlabel('Latency (seconds)')\n    plt.ylabel('Frequency')\n    plt.show()\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "45601"
            }
        ],
        "457": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nfrom sklearn.preprocessing import RobustScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = RobustScaler()\n    data = scaler.fit_transform(data)\n\n    data[data < 0] = 0\n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 18)\n    model = NMF(n_components=rank, init='nndsvd', max_iter=500, random_state=0)\n    \n    print(f\"Data shape: {data.shape}, Rank: {rank}, Dropout rate: {dropout_rate}\")\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXXX.py",
                "accuracy": 0.573493507281263,
                "model_info": "Data shape: (1087, 15099), Rank: 18, Dropout rate: [0.87304508 0.98160074 0.99       ... 0.70653174 0.87028519 0.93284269]",
                "lineage": "45701"
            }
        ],
        "458": [],
        "459": [],
        "460": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0, beta_loss='frobenius', max_iter=200)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        denoised_data = np.maximum(denoised_data, 0)\n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "46001"
            }
        ],
        "461": [],
        "462": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    print(\"High-level configuration: NMF Rank=20, Dropout Rate Range=[0.01, 0.99]\")\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        noise_model = np.random.poisson(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "High-level configuration: NMF Rank=20, Dropout Rate Range=[0.01, 0.99]",
                "lineage": "46201"
            }
        ],
        "463": [],
        "464": [],
        "465": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import FunctionTransformer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    for _ in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        noise_model = np.random.poisson(denoised_data)\n\n    def apply_knn_imputation(data):\n        knn = KNeighborsRegressor(n_neighbors=5)\n        imputed_data = data.copy()\n        mask = np.isnan(imputed_data)\n        if np.any(mask):\n            knn.fit(np.arange(data.shape[0]).reshape(-1, 1), data)\n            imputed_data[mask] = knn.predict(np.where(mask)[0].reshape(-1, 1))\n        return imputed_data\n\n    denoised_data = apply_knn_imputation(denoised_data)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "46501"
            }
        ],
        "466": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\nimport logging\n\ndef tuso_model(adata):\n    logging.basicConfig(level=logging.INFO)\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=0)\n    \n    logging.info(f'Number of trainable parameters: {rank * (data.shape[1] + rank)}')\n    \n    for i in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        noise_model = np.random.poisson(denoised_data)\n        logging.info(f'Iteration {i + 1}: W norm = {np.linalg.norm(W)}, H norm = {np.linalg.norm(H)}')\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXXX.py",
                "accuracy": 0.82273259326227,
                "model_info": "",
                "lineage": "46601"
            }
        ],
        "467": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata, learning_rate_schedule=None, random_seed=None, verbose=False):\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise_model = np.random.poisson(data)  \n    dropout_rate = np.clip(np.mean(noise_model == 0, axis=0), 0.01, 0.99)\n    \n    rank = min(np.linalg.matrix_rank(data), 20)\n    model = NMF(n_components=rank, init='nndsvd', random_state=random_seed)\n    \n    print(f\"Number of trainable parameters (components): {model.n_components * (data.shape[1] + 1)}\")\n\n    for i in range(5):\n        W = model.fit_transform(noise_model)\n        H = model.components_\n        denoised_data = np.dot(W, H)\n        denoised_data *= (1 - dropout_rate)\n        noise_model = np.random.poisson(denoised_data)\n        \n        if learning_rate_schedule is not None:\n            print(f\"Update {i+1}: Learning rate = {learning_rate_schedule[i]}\")\n        \n        if verbose:\n            print(f\"Iteration {i+1}: W shape = {W.shape}, H shape = {H.shape}, Denoised data shape = {denoised_data.shape}\")\n\n    adata.obsm[\"denoised\"] = denoised_data\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXXXXXXXXXXX.py",
                "accuracy": 0.8226818053331596,
                "model_info": "Number of trainable parameters (components): 302000",
                "lineage": "46701"
            }
        ],
        "468": []
    },
    "2": {
        "0": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    pca = PCA(n_components=min(a.shape)-1)\n    pca.fit(a.X)\n    denoised_data = pca.inverse_transform(pca.transform(a.X))\n    \n    out = denoised_data\n    adata.obsm[\"denoised\"] = out\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round12_AutoClass_model_for_.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "denoise_tusoml_round12_AutoClass_model_for_"
            }
        ],
        "1": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import Binarizer\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    binarizer = Binarizer(threshold=0.5)\n    binarized_data = binarizer.fit_transform(a.X)\n    \n    pca = PCA(n_components=min(binarized_data.shape)-1)\n    pca.fit(binarized_data)\n    denoised_data = pca.inverse_transform(pca.transform(binarized_data))\n    \n    out = denoised_data\n    adata.obsm[\"denoised\"] = out\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round12_AutoClass_model_for_X.py",
                "accuracy": 0.523814299188935,
                "model_info": "",
                "lineage": "121"
            }
        ],
        "2": [
            {
                "code": "import numpy as np\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    X = a.X.toarray() if hasattr(a.X, 'toarray') else a.X\n    mask = np.isnan(X) if isinstance(X, np.ndarray) and np.issubdtype(X.dtype, np.floating) else np.zeros(X.shape, dtype=bool)\n    X_filled = X.copy()\n    \n    for i in range(X.shape[1]):\n        if np.any(mask[:, i]):\n            knn = KNeighborsRegressor(n_neighbors=5)\n            knn.fit(np.arange(X.shape[0])[~mask[:, i]].reshape(-1, 1), X[~mask[:, i], i])\n            X_filled[mask[:, i], i] = knn.predict(np.arange(X.shape[0])[mask[:, i]].reshape(-1, 1))\n    \n    adata.obsm[\"denoised\"] = X_filled\n    missing_counts = np.sum(np.isnan(X), axis=0)\n    print(\"Missing values post-imputation per feature:\", missing_counts)\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round10_k_nearest_neighbors_X.py",
                "accuracy": 0.7290257138611496,
                "model_info": "Missing values post-imputation per feature: [0 0 0 ... 0 0 0]",
                "lineage": "221"
            }
        ],
        "3": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    X = a.X.toarray() if hasattr(a.X, 'toarray') else a.X\n    mask = np.isnan(X) if isinstance(X, np.ndarray) and np.issubdtype(X.dtype, np.floating) else np.zeros(X.shape, dtype=bool)\n    X_filled = X.copy()\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(X_filled)\n    H = model.components_\n    X_denoised = np.dot(W, H)\n    \n    for i in range(X.shape[1]):\n        if np.any(mask[:, i]):\n            X_filled[mask[:, i], i] = X_denoised[mask[:, i], i]\n    \n    adata.obsm[\"denoised\"] = X_filled\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round10_k_nearest_neighbors_X.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "321"
            }
        ],
        "4": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    X = a.X.toarray() if hasattr(a.X, 'toarray') else a.X\n    mask = np.isnan(X) if isinstance(X, np.ndarray) and np.issubdtype(X.dtype, np.floating) else np.zeros(X.shape, dtype=bool)\n    X_filled = X.copy()\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(X_filled)\n    H = model.components_\n    X_denoised = np.dot(W, H)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    X_filled[mask] = imputer.fit_transform(X_denoised)[mask]\n    \n    adata.obsm[\"denoised\"] = X_filled\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round10_k_nearest_neighbors_XX.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "421"
            }
        ],
        "5": [
            {
                "code": "import numpy as np\nfrom anndata import AnnData\nfrom sklearn.impute import KNNImputer\nfrom sklearn.decomposition import NMF\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    model = NMF(n_components=10, init='random', random_state=0)\n    W = model.fit_transform(a.X.toarray())\n    H = model.components_\n    denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    \n    knn_imputer = KNNImputer(n_neighbors=5)\n    imputed_data = knn_imputer.fit_transform(denoised_data)\n    \n    adata.obsm[\"imputed\"] = imputed_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round16_scImputeX.py",
                "accuracy": 0.7827745549253231,
                "model_info": "",
                "lineage": "521"
            }
        ]
    },
    "3": {
        "0": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    model = NMF(n_components=10, init='random', random_state=0)\n    W = model.fit_transform(a.X)\n    H = model.components_\n    out = np.dot(W, H)\n    adata.obsm[\"denoised\"] = out\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round13_matrix_factorization.py",
                "accuracy": 0.7827745549253231,
                "model_info": "",
                "lineage": "denoise_tusoml_round13_matrix_factorization"
            }
        ],
        "1": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(a.X)\n    H = model.components_\n    out = np.dot(W, H)\n    adata.obsm[\"denoised\"] = out\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round13_matrix_factorizationX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "131"
            }
        ],
        "2": [],
        "3": [
            {
                "code": "import numpy as np\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\n\nclass DeepGenerativeModel(nn.Module):\n    def __init__(self, input_dim):\n        super(DeepGenerativeModel, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 256),\n            nn.ReLU(),\n            nn.Linear(256, input_dim),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    if issparse(a.X):\n        a.X = a.X.toarray()\n    \n    scaler = StandardScaler()\n    a.X = scaler.fit_transform(a.X)\n    \n    input_dim = a.X.shape[1]\n    model = DeepGenerativeModel(input_dim)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    data_tensor = torch.FloatTensor(a.X)\n    model.train()\n    for epoch in range(100):\n        optimizer.zero_grad()\n        output = model(data_tensor)\n        loss = criterion(output, data_tensor)\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        denoised_data = model(data_tensor).numpy()\n\n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round15_deep_generative_modeXX.py",
                "accuracy": 0.6879589205132093,
                "model_info": "",
                "lineage": "331"
            }
        ],
        "4": [],
        "5": [],
        "6": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom anndata import AnnData\nfrom sklearn.preprocessing import StandardScaler\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    X = a.X.toarray() if hasattr(a.X, 'toarray') else a.X\n    mask = np.isnan(X) if isinstance(X, np.ndarray) and np.issubdtype(X.dtype, np.floating) else np.zeros(X.shape, dtype=bool)\n    X_filled = X.copy()\n\n    lib_size = X_filled.sum(axis=1, keepdims=True)\n    X_normalized = (X_filled / lib_size) * np.mean(lib_size)\n\n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(X_normalized)\n    H = model.components_\n    X_denoised = np.dot(W, H)\n    \n    for i in range(X.shape[1]):\n        if np.any(mask[:, i]):\n            X_filled[mask[:, i], i] = X_denoised[mask[:, i], i]\n    \n    adata.obsm[\"denoised\"] = X_filled\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round10_k_nearest_neighbors_XX.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "631"
            }
        ]
    },
    "5": {
        "0": [
            {
                "code": "import numpy as np\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass SimpleAutoencoder(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleAutoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, input_dim),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    input_dim = a.X.shape[1]\n    model = SimpleAutoencoder(input_dim)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    data_tensor = torch.FloatTensor(a.X.toarray())\n    model.train()\n    for epoch in range(100):\n        optimizer.zero_grad()\n        output = model(data_tensor)\n        loss = criterion(output, data_tensor)\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        denoised_data = model(data_tensor).numpy()\n\n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round15_deep_generative_mode.py",
                "accuracy": 0.5801760631769032,
                "model_info": "",
                "lineage": "denoise_tusoml_round15_deep_generative_mode"
            }
        ],
        "1": [],
        "2": [
            {
                "code": "import numpy as np\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass DeepGenerativeModel(nn.Module):\n    def __init__(self, input_dim):\n        super(DeepGenerativeModel, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 256),\n            nn.ReLU(),\n            nn.Linear(256, input_dim),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    input_dim = a.X.shape[1]\n    model = DeepGenerativeModel(input_dim)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    data_tensor = torch.FloatTensor(a.X.toarray())\n    model.train()\n    for epoch in range(100):\n        optimizer.zero_grad()\n        output = model(data_tensor)\n        loss = criterion(output, data_tensor)\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        denoised_data = model(data_tensor).numpy()\n\n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round15_deep_generative_modeX.py",
                "accuracy": 0.5859996063920121,
                "model_info": "",
                "lineage": "251"
            }
        ],
        "3": [
            {
                "code": "import numpy as np\nfrom anndata import AnnData\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(a.X.toarray())\n    H = model.components_\n    denoised_data = np.dot(W, H)\n    \n    knn_imputer = KNNImputer(n_neighbors=5)\n    imputed_data = knn_imputer.fit_transform(denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round16_scImputeX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "351"
            }
        ],
        "4": [
            {
                "code": "import numpy as np\nfrom anndata import AnnData\nfrom sklearn.decomposition import NMF\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.linear_model import Ridge\n\ndef dropout(X):\n    mask = np.random.rand(*X.shape) < 0.8\n    return X * mask\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    model = make_pipeline(FunctionTransformer(dropout), NMF(n_components=20, init='nndsvd', random_state=0, solver='mu', beta_loss='frobenius'))\n    W = model.fit_transform(a.X.toarray())\n    H = model.named_steps['nmf'].components_\n    denoised_data = np.dot(W, H)\n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round16_scImputeXX.py",
                "accuracy": 0.7800449245923864,
                "model_info": "",
                "lineage": "451"
            }
        ],
        "5": [
            {
                "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    noise = np.random.normal(0, 0.1, data.shape)\n    noisy_data = data + noise\n    \n    n_clusters = min(10, noisy_data.shape[0])\n    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n    clusters = kmeans.fit_predict(noisy_data)\n    \n    denoised_data = np.zeros_like(data)\n    for cluster in np.unique(clusters):\n        cluster_data = noisy_data[clusters == cluster]\n        denoised_data[clusters == cluster] = np.mean(cluster_data, axis=0)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteX.py",
                "accuracy": 0.7793712177566474,
                "model_info": "",
                "lineage": "551"
            }
        ],
        "6": []
    },
    "6": {
        "0": [
            {
                "code": "import numpy as np\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    denoised_data = a.X.toarray()  # Convert sparse matrix to dense array\n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round16_scImpute.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "denoise_tusoml_round16_scImpute"
            }
        ],
        "1": [],
        "2": [],
        "3": [],
        "4": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    scaler = StandardScaler()\n    data = scaler.fit_transform(data)\n    \n    model = KNeighborsRegressor(n_neighbors=5)\n    imputed_data = model.fit(data[~np.isnan(data).any(axis=1)], data[~np.isnan(data).any(axis=1)]).predict(data)\n    \n    imputed_data = np.maximum(imputed_data, 0)\n    \n    model_nmf = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model_nmf.fit_transform(imputed_data)\n    H = model_nmf.components_\n    denoised_data = np.dot(W, H)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXX.py",
                "accuracy": 0.5043132839411243,
                "model_info": "",
                "lineage": "461"
            }
        ]
    },
    "10": {
        "0": [
            {
                "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    n_clusters = min(10, data.shape[0])\n    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n    clusters = kmeans.fit_predict(data)\n    \n    denoised_data = np.zeros_like(data)\n    for cluster in np.unique(clusters):\n        cluster_data = data[clusters == cluster]\n        denoised_data[clusters == cluster] = np.mean(cluster_data, axis=0)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_cluste.py",
                "accuracy": 0.7794477400256117,
                "model_info": "",
                "lineage": "denoise_tusoml_round110_co_occurrence_cluste"
            }
        ],
        "1": [
            {
                "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_selection import VarianceThreshold\nfrom scipy.sparse import csr_matrix\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    variance_threshold = VarianceThreshold(threshold=0.1)\n    filtered_data = variance_threshold.fit_transform(data)\n    \n    n_clusters = min(10, filtered_data.shape[0])\n    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n    clusters = kmeans.fit_predict(filtered_data)\n    \n    denoised_data = np.zeros_like(data)\n    for cluster in np.unique(clusters):\n        cluster_data = data[clusters == cluster]\n        denoised_data[clusters == cluster] = np.mean(cluster_data, axis=0)\n    \n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteX.py",
                "accuracy": 0.7794455253125829,
                "model_info": "",
                "lineage": "1101"
            }
        ]
    },
    "11": {
        "0": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom scipy.sparse import issparse\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    model = NMF(n_components=10, init='random', random_state=0)\n    W = model.fit_transform(a.X)\n    H = model.components_\n    out = np.dot(W, H)\n    out = out.toarray() if issparse(out) else out\n    adata.obsm[\"denoised\"] = out\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round111_low_rank_matrix_appr.py",
                "accuracy": 0.7827745549253231,
                "model_info": "",
                "lineage": "denoise_tusoml_round111_low_rank_matrix_appr"
            }
        ],
        "1": []
    },
    "12": {
        "0": [
            {
                "code": "import numpy as np\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    if issparse(a.X):\n        out = np.where(a.X.toarray() > 0, a.X.toarray(), 0)\n    else:\n        out = np.where(a.X > 0, a.X, 0)\n    \n    adata.obsm[\"denoised\"] = out\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round112_STAR_aligner_for_map.py",
                "accuracy": 0.7290257138611496,
                "model_info": "",
                "lineage": "denoise_tusoml_round112_STAR_aligner_for_map"
            }
        ],
        "1": []
    },
    "1": {
        "2": [],
        "3": [
            {
                "code": "import numpy as np\nfrom anndata import AnnData\nfrom sklearn.decomposition import NMF\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(a.X.toarray())\n    H = model.components_\n    dropout_rate = np.random.uniform(0.1, 0.3, size=W.shape)  # Vary dropout rates\n    W *= dropout_rate\n    denoised_data = np.dot(W, H)\n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round16_scImputeXX.py",
                "accuracy": 0.782930072491145,
                "model_info": "",
                "lineage": "311"
            }
        ],
        "4": [
            {
                "code": "import numpy as np\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import NMF\n\nclass DeepGenerativeModel(nn.Module):\n    def __init__(self, input_dim):\n        super(DeepGenerativeModel, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 256),\n            nn.ReLU(),\n            nn.Linear(256, input_dim),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    if issparse(a.X):\n        a.X = a.X.toarray()\n    \n    scaler = StandardScaler()\n    a.X = scaler.fit_transform(a.X)\n    \n    input_dim = a.X.shape[1]\n    model = DeepGenerativeModel(input_dim)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    data_tensor = torch.FloatTensor(a.X)\n    model.train()\n    for epoch in range(100):\n        optimizer.zero_grad()\n        output = model(data_tensor)\n        loss = criterion(output, data_tensor)\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        denoised_data = model(data_tensor).numpy()\n    \n    nmf = NMF(n_components=64, init='random', random_state=0)\n    nmf_features = nmf.fit_transform(denoised_data)\n    denoised_data = nmf.inverse_transform(nmf_features)\n\n    adata.obsm[\"denoised\"] = denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round15_deep_generative_modeXXX.py",
                "accuracy": 0.585584145531594,
                "model_info": "",
                "lineage": "411"
            }
        ],
        "5": [
            {
                "code": "import numpy as np\nfrom anndata import AnnData\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(a.X.toarray())\n    H = model.components_\n    denoised_data = np.dot(W, H)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(denoised_data)\n    adata.obsm[\"denoised\"] = imputed_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round16_scImputeXX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "511"
            }
        ],
        "6": [],
        "7": [],
        "8": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    adjusted_denoised_data = imputer.fit_transform(adjusted_denoised_data)\n\n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "811"
            }
        ]
    },
    "4": {
        "2": [],
        "3": [],
        "4": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom scipy.sparse import issparse\nfrom anndata import AnnData\nimport time\nimport resource\n\ndef tuso_model(adata):\n    start_time = time.time()\n    mem_before = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n    \n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    pca = PCA(n_components=min(a.shape)-1)\n    pca.fit(a.X)\n    denoised_data = pca.inverse_transform(pca.transform(a.X))\n    \n    out = denoised_data\n    adata.obsm[\"denoised\"] = out\n    \n    end_time = time.time()\n    mem_after = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n    \n    print(f\"Run-time: {end_time - start_time:.4f} seconds\")\n    print(f\"Memory usage: {mem_after - mem_before} KB\")\n    \n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round12_AutoClass_model_for_X.py",
                "accuracy": 0.7290257138611496,
                "model_info": "Run-time: 90.0709 seconds\nMemory usage: 498132 KB",
                "lineage": "441"
            }
        ],
        "5": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.impute import KNNImputer\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n    denoised_data = np.dot(W, H)\n    \n    imputer = KNNImputer(n_neighbors=5)\n    imputed_data = imputer.fit_transform(denoised_data)\n    \n    adata.obsm[\"denoised\"] = imputed_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXX.py",
                "accuracy": 0.7836744359101816,
                "model_info": "",
                "lineage": "541"
            }
        ],
        "6": [
            {
                "code": "import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import KMeans\nfrom scipy.sparse import csr_matrix\nfrom anndata import AnnData\n\ndef tuso_model(adata):\n    a = AnnData(\n        X=adata.obsm[\"train\"].copy(),\n        obs=adata.obs.copy(),\n        var=adata.var.copy()\n    )\n    \n    data = a.X\n    if isinstance(data, csr_matrix):\n        data = data.toarray()\n    \n    model = NMF(n_components=20, init='nndsvd', random_state=0)\n    W = model.fit_transform(data)\n    H = model.components_\n\n    dropout_rate = np.clip(np.mean(data == 0, axis=0), 0.01, 0.99)\n    adjusted_denoised_data = np.dot(W, H) * (1 - dropout_rate)\n    \n    adata.obsm[\"denoised\"] = adjusted_denoised_data\n    return adata",
                "file": "/projects/zhanglab/users/alistair/tusoml/denoise_tusoml_round110_co_occurrence_clusteXX.py",
                "accuracy": 0.8106343832655596,
                "model_info": "",
                "lineage": "641"
            }
        ]
    },
    "7": {
        "2": []
    }
}