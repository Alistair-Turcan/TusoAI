{
    "0": {
        "0": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(32 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_Neu.py",
                "accuracy": 0.80834,
                "model_info": "",
                "lineage": "satellite_initial_8250_1D_Convolutional_Neu"
            }
        ],
        "1": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(32 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\nclass MultiTaskCNN1D(nn.Module):\n    def __init__(self):\n        super(MultiTaskCNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(32 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = MultiTaskCNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuX.py",
                "accuracy": 0.80834,
                "model_info": "",
                "lineage": "101"
            }
        ],
        "2": [],
        "3": [],
        "4": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(32 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    class_counts = torch.bincount(label_tensor)\n    class_weights = 1.0 / class_counts.float()\n    weighted_loss = class_weights[label_tensor]\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuX.py",
                "accuracy": 0.70983,
                "model_info": "",
                "lineage": "401"
            }
        ],
        "5": [],
        "6": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom sklearn.model_selection import StratifiedKFold\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(32 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    skf = StratifiedKFold(n_splits=5)\n\n    for train_index, _ in skf.split(train_tensor.cpu(), label_tensor.cpu()):\n        train_subset = torch.utils.data.Subset(dataset, train_index)\n        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuX.py",
                "accuracy": 0.79259,
                "model_info": "",
                "lineage": "601"
            }
        ],
        "7": [],
        "8": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuX.py",
                "accuracy": 0.82855,
                "model_info": "",
                "lineage": "801"
            }
        ],
        "9": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef custom_loss_function(outputs, labels, class_weights):\n    loss = nn.NLLLoss(weight=class_weights.to(outputs.device))\n    return loss(outputs, labels)\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    class_counts = torch.bincount(torch.tensor(train_label, dtype=torch.long), minlength=24)\n    class_weights = 1.0 / class_counts.float()\n    class_weights = class_weights / class_weights.sum()\n    \n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = custom_loss_function(outputs, labels, class_weights)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXX.py",
                "accuracy": 0.72706,
                "model_info": "",
                "lineage": "901"
            }
        ],
        "10": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass CNN1DWithAttention(nn.Module):\n    def __init__(self):\n        super(CNN1DWithAttention, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        attention_weights = torch.softmax(x, dim=1)\n        x = attention_weights * x\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1DWithAttention().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXX.py",
                "accuracy": 0.75197,
                "model_info": "",
                "lineage": "1001"
            }
        ],
        "11": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    skf = StratifiedKFold(n_splits=5)\n    for train_index, val_index in skf.split(train_tensor.cpu(), label_tensor.cpu()):\n        train_subset = train_tensor[train_index]\n        label_subset = label_tensor[train_index]\n        \n        dataset = TensorDataset(train_subset, label_subset)\n        train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXX.py",
                "accuracy": 0.82503,
                "model_info": "",
                "lineage": "1101"
            }
        ],
        "12": [],
        "13": [],
        "14": [],
        "15": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom scipy.stats import skew, kurtosis\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    if np.any(np.array(train_data) < 0) or np.any(np.array(train_data) > 1):\n        print(\"Warning: Input data contains values outside the expected range [0, 1].\")\n    \n    skewness = skew(train_data, axis=0)\n    kurt = kurtosis(train_data, axis=0)\n    for i in range(len(skewness)):\n        print(f\"Feature {i}: Skewness = {skewness[i]}, Kurtosis = {kurt[i]}\")\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXX.py",
                "accuracy": 0.82855,
                "model_info": "Warning: Input data contains values outside the expected range [0, 1].\nFeature 0: Skewness = 0.33958789706230164, Kurtosis = -0.24428796768188477\nFeature 1: Skewness = 0.24421650171279907, Kurtosis = -0.6993136405944824\nFeature 2: Skewness = 0.13461434841156006, Kurtosis = -0.9540939331054688\nFeature 3: Skewness = 0.08161312341690063, Kurtosis = -1.0302248001098633\nFeature 4: Skewness = -0.0004137173236813396, Kurtosis = -1.0999956130981445\nFeature 5: Skewness = -0.07856988906860352, Kurtosis = -1.157874345779419\nFeature 6: Skewness = -0.34995830059051514, Kurtosis = -1.4130364656448364\nFeature 7: Skewness = -0.39597058296203613, Kurtosis = -1.4260790348052979\nFeature 8: Skewness = -0.40969061851501465, Kurtosis = -1.445096492767334\nFeature 9: Skewness = -0.3910859525203705, Kurtosis = -1.4526749849319458\nFeature 10: Skewness = -0.34885135293006897, Kurtosis = -1.4612054824829102\nFeature 11: Skewness = -0.34712088108062744, Kurtosis = -1.4739696979522705\nFeature 12: Skewness = -0.013812951743602753, Kurtosis = -1.17056143283844\nFeature 13: Skewness = 0.2050139307975769, Kurtosis = -0.81892991065979\nFeature 14: Skewness = 0.5340203046798706, Kurtosis = -0.3467264175415039\nFeature 15: Skewness = 0.32271718978881836, Kurtosis = -0.6790461540222168\nFeature 16: Skewness = 0.11973690986633301, Kurtosis = -1.1583318710327148\nFeature 17: Skewness = 0.018600905314087868, Kurtosis = -1.2863292694091797\nFeature 18: Skewness = -0.023042723536491394, Kurtosis = -1.367784023284912\nFeature 19: Skewness = 0.03399716317653656, Kurtosis = -1.4192849397659302\nFeature 20: Skewness = 0.07509662955999374, Kurtosis = -1.4706027507781982\nFeature 21: Skewness = 0.15956494212150574, Kurtosis = -1.492492914199829\nFeature 22: Skewness = 0.19429774582386017, Kurtosis = -1.5180882215499878\nFeature 23: Skewness = 0.16170769929885864, Kurtosis = -1.525130033493042\nFeature 24: Skewness = 0.17512960731983185, Kurtosis = -1.5307402610778809\nFeature 25: Skewness = 0.17832662165164948, Kurtosis = -1.53",
                "lineage": "1501"
            }
        ],
        "16": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss(reduction='none')\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            class_weights = 1.0 / (torch.bincount(labels, minlength=24).float() + 1e-5)\n            weighted_loss = (loss * class_weights[labels]).mean()\n            weighted_loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXX.py",
                "accuracy": 0.77655,
                "model_info": "",
                "lineage": "1601"
            }
        ],
        "17": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.dropout(self.relu(self.fc1(x)))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXX.py",
                "accuracy": 0.81005,
                "model_info": "",
                "lineage": "1701"
            }
        ],
        "18": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n    model.train()\n    for epoch in range(15):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    print(f\"Train Data Shape: {train_tensor.shape}, Label Shape: {label_tensor.shape}\")\n    print(f\"Validation Data Shape: {val_tensor.shape}\")\n    print(f\"NaN Counts: {torch.isnan(train_tensor).sum().item()}, {torch.isnan(label_tensor).sum().item()}, {torch.isnan(val_tensor).sum().item()}\")\n    print(f\"Inf Counts: {torch.isinf(train_tensor).sum().item()}, {torch.isinf(label_tensor).sum().item()}, {torch.isinf(val_tensor).sum().item()}\")\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.818,
                "model_info": "Train Data Shape: torch.Size([800000, 1, 46]), Label Shape: torch.Size([800000])\nValidation Data Shape: torch.Size([100000, 1, 46])\nNaN Counts: 0, 0, 0\nInf Counts: 0, 0, 0",
                "lineage": "1801"
            }
        ],
        "19": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXX.py",
                "accuracy": 0.85118,
                "model_info": "",
                "lineage": "1901"
            }
        ],
        "20": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D_LSTM(nn.Module):\n    def __init__(self):\n        super(CNN1D_LSTM, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.lstm = nn.LSTM(64, 64, batch_first=True)\n        self.fc1 = nn.Linear(64, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.permute(0, 2, 1)\n        x, _ = self.lstm(x)\n        x = x[:, -1, :]\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D_LSTM().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.80646,
                "model_info": "",
                "lineage": "2001"
            }
        ],
        "21": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport logging\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            logging.info(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.85118,
                "model_info": "",
                "lineage": "2101"
            }
        ],
        "22": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.81319,
                "model_info": "",
                "lineage": "2201"
            }
        ],
        "23": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef apply_fourier_transform(data):\n    transformed_data = np.fft.fft(data, axis=1)\n    return np.abs(transformed_data)\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_data = apply_fourier_transform(train_data)\n    val_data = apply_fourier_transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.69947,
                "model_info": "",
                "lineage": "2301"
            }
        ],
        "24": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef create_time_lagged_features(data, lag=1):\n    return np.array([data[i-lag] if i >= lag else np.zeros(data.shape[1]) for i in range(data.shape[0])])\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_data_lagged = create_time_lagged_features(train_data)\n    val_data_lagged = create_time_lagged_features(val_data)\n\n    train_tensor = torch.tensor(train_data_lagged, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data_lagged, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.24017,
                "model_info": "",
                "lineage": "2401"
            }
        ],
        "25": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.85214,
                "model_info": "",
                "lineage": "2501"
            }
        ],
        "26": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss(reduction='none')\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            class_weights = torch.tensor([1.0 if i in range(1, 25) else 0.1 for i in labels.cpu().numpy()]).to(device)\n            weighted_loss = (loss * class_weights).mean()\n            weighted_loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.84522,
                "model_info": "",
                "lineage": "2601"
            }
        ],
        "27": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom collections import Counter\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    class_counts = Counter(train_label)\n    total_samples = len(train_label)\n    class_distribution = {k: v / total_samples for k, v in class_counts.items()}\n    print(f\"Class distribution: {class_distribution}\")\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.85118,
                "model_info": "Class distribution: {7: 0.0645625, 0: 0.23828, 13: 0.070195, 9: 0.01320875, 1: 0.1661875, 2: 0.03259875, 8: 0.1510175, 18: 0.01934125, 5: 0.093515, 4: 0.0376075, 16: 0.01844625, 6: 0.0482325, 19: 0.00247, 17: 0.004335, 11: 0.02455375, 14: 0.00639375, 12: 0.0020625, 3: 0.0043025, 10: 0.00105875, 22: 0.00044125, 15: 0.0005825, 21: 0.0003225, 20: 0.00018375, 23: 0.00010125}",
                "lineage": "2701"
            }
        ],
        "28": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.81319,
                "model_info": "",
                "lineage": "2801"
            }
        ],
        "29": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.pool = nn.AdaptiveAvgPool1d(46)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.85118,
                "model_info": "",
                "lineage": "2901"
            }
        ],
        "30": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    skf = StratifiedKFold(n_splits=5)\n    y_pred_list = []\n\n    for train_index, valid_index in skf.split(train_tensor.cpu(), label_tensor.cpu()):\n        train_subset, valid_subset = train_tensor[train_index], train_tensor[valid_index]\n        label_subset, label_valid = label_tensor[train_index], label_tensor[valid_index]\n\n        dataset = TensorDataset(train_subset, label_subset)\n        train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        model.eval()\n        with torch.no_grad():\n            val_outputs = model(valid_subset)\n            _, y_pred = torch.max(val_outputs, 1)\n            y_pred_list.append(y_pred.cpu().numpy())\n\n    y_pred_final = np.concatenate(y_pred_list)\n    return y_pred_final[:len(val_data)].tolist()",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.13564,
                "model_info": "",
                "lineage": "3001"
            }
        ],
        "31": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=512):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n    model.train()\n    for epoch in range(15):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            print(f'Epoch {epoch}, Loss: {loss.item()}, Grad Norm: {torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)}')\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.8448,
                "model_info": "Epoch 0, Loss: 3.1817562580108643, Grad Norm: 0.7653359770774841\nEpoch 0, Loss: 2.967373847961426, Grad Norm: 1.0957986116409302\nEpoch 0, Loss: 2.7225916385650635, Grad Norm: 1.4202848672866821\nEpoch 0, Loss: 2.512896776199341, Grad Norm: 1.5029563903808594\nEpoch 0, Loss: 2.3910648822784424, Grad Norm: 1.474089503288269\nEpoch 0, Loss: 2.297334671020508, Grad Norm: 1.617136001586914\nEpoch 0, Loss: 2.1043813228607178, Grad Norm: 1.6395398378372192\nEpoch 0, Loss: 2.07585072517395, Grad Norm: 1.6455810070037842\nEpoch 0, Loss: 2.1177170276641846, Grad Norm: 2.2003016471862793\nEpoch 0, Loss: 1.9769341945648193, Grad Norm: 2.006077289581299\nEpoch 0, Loss: 1.8442081212997437, Grad Norm: 1.6027021408081055\nEpoch 0, Loss: 1.833332896232605, Grad Norm: 1.3923161029815674\nEpoch 0, Loss: 1.7740105390548706, Grad Norm: 1.4556519985198975\nEpoch 0, Loss: 1.865786075592041, Grad Norm: 1.4173377752304077\nEpoch 0, Loss: 1.6334326267242432, Grad Norm: 1.2534457445144653\nEpoch 0, Loss: 1.6776708364486694, Grad Norm: 1.191196322441101\nEpoch 0, Loss: 1.5946483612060547, Grad Norm: 1.2675397396087646\nEpoch 0, Loss: 1.5362217426300049, Grad Norm: 1.103925347328186\nEpoch 0, Loss: 1.4478501081466675, Grad Norm: 0.9627434611320496\nEpoch 0, Loss: 1.468652367591858, Grad Norm: 1.1463053226470947\nEpoch 0, Loss: 1.4255073070526123, Grad Norm: 0.9284903407096863\nEpoch 0, Loss: 1.5663279294967651, Grad Norm: 0.9241393804550171\nEpoch 0, Loss: 1.3383866548538208, Grad Norm: 1.1920545101165771\nEpoch 0, Loss: 1.3924490213394165, Grad Norm: 1.0488035678863525\nEpoch 0, Loss: 1.309531807899475, Grad Norm: 1.6257295608520508\nEpoch 0, Loss: 1.3654730319976807, Grad Norm: 0.9599491953849792\nEpoch 0, Loss: 1.3354411125183105, Grad Norm: 0.853731095790863\nEpoch 0, Loss: 1.3946800231933594, Grad Norm: 1.1935256719589233\nEpoch 0, Loss: 1.4693862199783325, Grad Norm: 1.055777668952942\nEpoch 0, Loss: 1.259926199913025, Grad Norm: 0.8820977210998535\nEpoch 0, Loss: 1.2289602756500244, Grad Norm: 1.1016616821289062\nEp",
                "lineage": "3101"
            }
        ],
        "32": [],
        "33": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXX.py",
                "accuracy": 0.85118,
                "model_info": "",
                "lineage": "3301"
            }
        ],
        "34": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.fc1 = nn.Linear(64, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.71173,
                "model_info": "",
                "lineage": "3401"
            }
        ],
        "35": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    if len(train_data) < 1000:\n        print(\"Warning: Insufficient training data volume.\")\n    \n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    print(f\"Model configuration: {model}\")\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.85118,
                "model_info": "Model configuration: CNN1D(\n  (conv1): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n  (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n  (fc1): Linear(in_features=2944, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=24, bias=True)\n  (relu): ReLU()\n  (softmax): LogSoftmax(dim=1)\n)",
                "lineage": "3501"
            }
        ],
        "36": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.85118,
                "model_info": "",
                "lineage": "3601"
            }
        ],
        "37": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass PretrainedCNN1D(nn.Module):\n    def __init__(self, pretrained_weights_path=None):\n        super(PretrainedCNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n        if pretrained_weights_path is not None:\n            self.load_pretrained_weights(pretrained_weights_path)\n\n    def load_pretrained_weights(self, path):\n        pretrained_weights = torch.load(path)\n        self.load_state_dict(pretrained_weights)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032, pretrained_weights_path=None):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = PretrainedCNN1D(pretrained_weights_path).to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.85118,
                "model_info": "",
                "lineage": "3701"
            }
        ],
        "38": [],
        "39": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Total trainable parameters: {total_params}\")\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.85118,
                "model_info": "Total trainable parameters: 387896",
                "lineage": "3901"
            }
        ],
        "40": [],
        "41": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            grad_norms = [torch.norm(param.grad).item() for param in model.parameters() if param.grad is not None]\n            print(f'Epoch {epoch}, Grad Norms: {grad_norms}')\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.85118,
                "model_info": "Epoch 0, Grad Norms: [0.007456608582288027, 0.004246624186635017, 0.056751932948827744, 0.014490029774606228, 0.07234004884958267, 0.036209870129823685, 0.48923459649086, 0.11699086427688599, 0.11032336950302124, 0.31096741557121277]\nEpoch 0, Grad Norms: [0.07295282930135727, 0.03568188101053238, 0.2650785744190216, 0.0700005516409874, 0.23724442720413208, 0.13104087114334106, 0.4825511574745178, 0.12009178102016449, 0.2361183613538742, 0.30487510561943054]\nEpoch 0, Grad Norms: [0.15092802047729492, 0.07339504361152649, 0.530015766620636, 0.14251424372196198, 0.45148852467536926, 0.2536686360836029, 0.48393169045448303, 0.11175370961427689, 0.412919282913208, 0.2787865698337555]\nEpoch 0, Grad Norms: [0.24905532598495483, 0.12565471231937408, 0.8541298508644104, 0.23695167899131775, 0.7157984375953674, 0.40095263719558716, 0.531489372253418, 0.11207752674818039, 0.6710877418518066, 0.27549391984939575]\nEpoch 0, Grad Norms: [0.35497546195983887, 0.1810847520828247, 1.185412883758545, 0.3277224004268646, 0.972987949848175, 0.5214496850967407, 0.5657083988189697, 0.10287263989448547, 0.9595987200737, 0.25797122716903687]\nEpoch 0, Grad Norms: [0.42996400594711304, 0.22324058413505554, 1.3857190608978271, 0.39094576239585876, 1.1217570304870605, 0.5862370133399963, 0.5440168380737305, 0.08734562993049622, 1.1273345947265625, 0.21504031121730804]\nEpoch 0, Grad Norms: [0.45840713381767273, 0.23401108384132385, 1.4188785552978516, 0.3910410404205322, 1.1171544790267944, 0.5357179045677185, 0.4771259129047394, 0.06414201855659485, 1.1379059553146362, 0.1578207165002823]\nEpoch 0, Grad Norms: [0.38586828112602234, 0.19769178330898285, 1.165440559387207, 0.31581851840019226, 0.8976593613624573, 0.3929315507411957, 0.38084283471107483, 0.04600352421402931, 1.0059212446212769, 0.11826251447200775]\nEpoch 0, Grad Norms: [0.2234782725572586, 0.10256967693567276, 0.6412725448608398, 0.1498543620109558, 0.514517605304718, 0.16797257959842682, 0.30722108483314514, 0.03669894114136696, 0",
                "lineage": "4101"
            }
        ],
        "42": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    class_weights = compute_class_weight('balanced', classes=np.unique(train_label), y=train_label)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n    criterion = nn.NLLLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.77579,
                "model_info": "",
                "lineage": "4201"
            }
        ],
        "43": [],
        "44": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=512):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            print(f\"Epoch: {epoch}, Loss: {loss.item()}, Gradient Norm: {torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)}\")\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.8452,
                "model_info": "Epoch: 0, Loss: 3.1817562580108643, Gradient Norm: 0.7653359770774841\nEpoch: 0, Loss: 2.967373847961426, Gradient Norm: 0.9999991655349731\nEpoch: 0, Loss: 2.7225916385650635, Gradient Norm: 0.9999993443489075\nEpoch: 0, Loss: 2.512896776199341, Gradient Norm: 0.9999993443489075\nEpoch: 0, Loss: 2.3910648822784424, Gradient Norm: 0.9999993443489075\nEpoch: 0, Loss: 2.297334671020508, Gradient Norm: 0.9999994039535522\nEpoch: 0, Loss: 2.1043813228607178, Gradient Norm: 0.999999463558197\nEpoch: 0, Loss: 2.07585072517395, Gradient Norm: 0.999999463558197\nEpoch: 0, Loss: 2.1177170276641846, Gradient Norm: 0.9999996423721313\nEpoch: 0, Loss: 1.9769341945648193, Gradient Norm: 0.9999994039535522\nEpoch: 0, Loss: 1.8442081212997437, Gradient Norm: 0.999999463558197\nEpoch: 0, Loss: 1.833332896232605, Gradient Norm: 0.9999993443489075\nEpoch: 0, Loss: 1.7740105390548706, Gradient Norm: 0.9999992847442627\nEpoch: 0, Loss: 1.865786075592041, Gradient Norm: 0.9999994039535522\nEpoch: 0, Loss: 1.6334326267242432, Gradient Norm: 0.9999991655349731\nEpoch: 0, Loss: 1.6776708364486694, Gradient Norm: 0.9999991655349731\nEpoch: 0, Loss: 1.5946483612060547, Gradient Norm: 0.9999992251396179\nEpoch: 0, Loss: 1.5362217426300049, Gradient Norm: 0.9999989867210388\nEpoch: 0, Loss: 1.4478501081466675, Gradient Norm: 0.9627434611320496\nEpoch: 0, Loss: 1.468652367591858, Gradient Norm: 0.9999991655349731\nEpoch: 0, Loss: 1.4255073070526123, Gradient Norm: 0.9284903407096863\nEpoch: 0, Loss: 1.5663279294967651, Gradient Norm: 0.9241393804550171\nEpoch: 0, Loss: 1.3383866548538208, Gradient Norm: 0.9999991655349731\nEpoch: 0, Loss: 1.3924490213394165, Gradient Norm: 0.9999989867210388\nEpoch: 0, Loss: 1.309531807899475, Gradient Norm: 0.999999463558197\nEpoch: 0, Loss: 1.3654730319976807, Gradient Norm: 0.9599491953849792\nEpoch: 0, Loss: 1.3354411125183105, Gradient Norm: 0.853731095790863\nEpoch: 0, Loss: 1.3946800231933594, Gradient Norm: 0.9999992251396179\nEpoch: 0, Loss: 1.4693862199783325, Gradient Norm: 0.9",
                "lineage": "4401"
            }
        ],
        "45": [],
        "46": [],
        "47": [],
        "48": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_data = train_data / train_data.max(axis=1, keepdims=True)\n    val_data = val_data / val_data.max(axis=1, keepdims=True)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.82751,
                "model_info": "",
                "lineage": "4801"
            }
        ],
        "49": [],
        "50": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport time\nimport resource\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=512):\n    start_time = time.time()\n    mem_usage_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n    model.train()\n    for epoch in range(15):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n\n    end_time = time.time()\n    mem_usage_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n    print(f\"Memory usage: {mem_usage_end - mem_usage_start} KB\")\n\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.84451,
                "model_info": "Training time: 162.37 seconds\nMemory usage: 438852 KB",
                "lineage": "5001"
            }
        ],
        "51": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=512):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n    model.train()\n    for epoch in range(20):\n        print(f\"Epoch {epoch + 1}/20\")\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            print(f\"Training loss: {loss.item():.4f}\")\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.84603,
                "model_info": "Epoch 1/20\nTraining loss: 3.1818\nTraining loss: 2.9674\nTraining loss: 2.7230\nTraining loss: 2.5124\nTraining loss: 2.3894\nTraining loss: 2.2926\nTraining loss: 2.0951\nTraining loss: 2.0610\nTraining loss: 2.0933\nTraining loss: 1.9408\nTraining loss: 1.8042\nTraining loss: 1.7991\nTraining loss: 1.7410\nTraining loss: 1.8275\nTraining loss: 1.6120\nTraining loss: 1.6492\nTraining loss: 1.5732\nTraining loss: 1.5183\nTraining loss: 1.4326\nTraining loss: 1.4586\nTraining loss: 1.4166\nTraining loss: 1.5662\nTraining loss: 1.3348\nTraining loss: 1.3943\nTraining loss: 1.3113\nTraining loss: 1.3681\nTraining loss: 1.3388\nTraining loss: 1.3966\nTraining loss: 1.4743\nTraining loss: 1.2633\nTraining loss: 1.2355\nTraining loss: 1.3543\nTraining loss: 1.2871\nTraining loss: 1.2397\nTraining loss: 1.1920\nTraining loss: 1.3351\nTraining loss: 1.2529\nTraining loss: 1.3074\nTraining loss: 1.2880\nTraining loss: 1.2422\nTraining loss: 1.3354\nTraining loss: 1.1836\nTraining loss: 1.2675\nTraining loss: 1.1887\nTraining loss: 1.2753\nTraining loss: 1.1539\nTraining loss: 1.2523\nTraining loss: 1.2185\nTraining loss: 1.0883\nTraining loss: 1.1804\nTraining loss: 1.1535\nTraining loss: 1.2855\nTraining loss: 1.2238\nTraining loss: 1.1768\nTraining loss: 1.0756\nTraining loss: 1.2509\nTraining loss: 1.3119\nTraining loss: 1.1802\nTraining loss: 1.0842\nTraining loss: 1.1867\nTraining loss: 1.1179\nTraining loss: 1.0087\nTraining loss: 1.2112\nTraining loss: 1.1293\nTraining loss: 1.1369\nTraining loss: 1.1259\nTraining loss: 1.1881\nTraining loss: 1.0082\nTraining loss: 1.0945\nTraining loss: 1.2482\nTraining loss: 1.0380\nTraining loss: 1.0642\nTraining loss: 1.0915\nTraining loss: 1.2024\nTraining loss: 1.0779\nTraining loss: 1.0941\nTraining loss: 1.0427\nTraining loss: 1.0020\nTraining loss: 1.0903\nTraining loss: 1.0202\nTraining loss: 1.0170\nTraining loss: 1.0728\nTraining loss: 1.0999\nTraining loss: 0.9580\nTraining loss: 1.1991\nTraining loss: 0.9406\nTraining loss: 1.1760\nTraining loss: 1.0472\nTraining loss: 1.0232\nTraining loss: 1.0358\nTraining ",
                "lineage": "5101"
            }
        ],
        "52": [],
        "53": [],
        "54": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=512):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    class_counts = np.bincount(train_label, minlength=24)\n    class_balance = class_counts / len(train_label)\n    print(f'Class Balance: {class_balance}')\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss(weight=torch.tensor(class_balance, dtype=torch.float32).to(device))\n    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.81747,
                "model_info": "Class Balance: [2.382800e-01 1.661875e-01 3.259875e-02 4.302500e-03 3.760750e-02\n 9.351500e-02 4.823250e-02 6.456250e-02 1.510175e-01 1.320875e-02\n 1.058750e-03 2.455375e-02 2.062500e-03 7.019500e-02 6.393750e-03\n 5.825000e-04 1.844625e-02 4.335000e-03 1.934125e-02 2.470000e-03\n 1.837500e-04 3.225000e-04 4.412500e-04 1.012500e-04]",
                "lineage": "5401"
            }
        ],
        "55": [],
        "56": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(64 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            print(f'Epoch: {epoch}, Batch Loss: {loss.item()}')\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.85118,
                "model_info": "Epoch: 0, Batch Loss: 3.179513454437256\nEpoch: 0, Batch Loss: 3.081185817718506\nEpoch: 0, Batch Loss: 2.977156162261963\nEpoch: 0, Batch Loss: 2.821729898452759\nEpoch: 0, Batch Loss: 2.6255927085876465\nEpoch: 0, Batch Loss: 2.415761709213257\nEpoch: 0, Batch Loss: 2.18546199798584\nEpoch: 0, Batch Loss: 1.9955437183380127\nEpoch: 0, Batch Loss: 1.869529366493225\nEpoch: 0, Batch Loss: 1.8662453889846802\nEpoch: 0, Batch Loss: 1.7523856163024902\nEpoch: 0, Batch Loss: 1.7966418266296387\nEpoch: 0, Batch Loss: 1.7475913763046265\nEpoch: 0, Batch Loss: 1.6381425857543945\nEpoch: 0, Batch Loss: 1.52604079246521\nEpoch: 0, Batch Loss: 1.5967133045196533\nEpoch: 0, Batch Loss: 1.5360238552093506\nEpoch: 0, Batch Loss: 1.5103269815444946\nEpoch: 0, Batch Loss: 1.376840353012085\nEpoch: 0, Batch Loss: 1.4332945346832275\nEpoch: 0, Batch Loss: 1.4579373598098755\nEpoch: 0, Batch Loss: 1.3351857662200928\nEpoch: 0, Batch Loss: 1.2719855308532715\nEpoch: 0, Batch Loss: 1.3037129640579224\nEpoch: 0, Batch Loss: 1.32504403591156\nEpoch: 0, Batch Loss: 1.2049589157104492\nEpoch: 0, Batch Loss: 1.236661434173584\nEpoch: 0, Batch Loss: 1.2437082529067993\nEpoch: 0, Batch Loss: 1.2466986179351807\nEpoch: 0, Batch Loss: 1.1779062747955322\nEpoch: 0, Batch Loss: 1.1804801225662231\nEpoch: 0, Batch Loss: 1.1870150566101074\nEpoch: 0, Batch Loss: 1.151028037071228\nEpoch: 0, Batch Loss: 1.1741880178451538\nEpoch: 0, Batch Loss: 1.142722725868225\nEpoch: 0, Batch Loss: 1.1784257888793945\nEpoch: 0, Batch Loss: 1.0660336017608643\nEpoch: 0, Batch Loss: 1.0736560821533203\nEpoch: 0, Batch Loss: 1.0726854801177979\nEpoch: 0, Batch Loss: 1.078661322593689\nEpoch: 0, Batch Loss: 1.076577067375183\nEpoch: 0, Batch Loss: 1.1014093160629272\nEpoch: 0, Batch Loss: 1.085339903831482\nEpoch: 0, Batch Loss: 1.0640029907226562\nEpoch: 0, Batch Loss: 1.0090086460113525\nEpoch: 0, Batch Loss: 1.064518690109253\nEpoch: 0, Batch Loss: 1.006173849105835\nEpoch: 0, Batch Loss: 0.964717447757721\nEpoch: 0, Batch Loss: 1.0466409921646118\nEpoch: 0, Bat",
                "lineage": "5601"
            }
        ],
        "57": [],
        "58": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXX.py",
                "accuracy": 0.86169,
                "model_info": "",
                "lineage": "5801"
            }
        ],
        "59": [],
        "60": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass MultiTaskCNN1D(nn.Module):\n    def __init__(self):\n        super(MultiTaskCNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = MultiTaskCNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86169,
                "model_info": "",
                "lineage": "6001"
            }
        ],
        "61": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_data = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    val_data = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_data, torch.tensor(train_label, dtype=torch.long).to(device))\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_data)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.85118,
                "model_info": "",
                "lineage": "6101"
            }
        ],
        "62": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            grad_norm = torch.norm(torch.cat([p.grad.view(-1) for p in model.parameters() if p.grad is not None]))\n            optimizer.step()\n            print(f\"Epoch {epoch}, Grad Norm: {grad_norm.item()}\")\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86169,
                "model_info": "Epoch 0, Grad Norm: 0.5022761821746826\nEpoch 0, Grad Norm: 0.8605166673660278\nEpoch 0, Grad Norm: 1.4895706176757812\nEpoch 0, Grad Norm: 2.1184542179107666\nEpoch 0, Grad Norm: 1.6192725896835327\nEpoch 0, Grad Norm: 2.217729330062866\nEpoch 0, Grad Norm: 2.732384443283081\nEpoch 0, Grad Norm: 2.7236227989196777\nEpoch 0, Grad Norm: 1.883602261543274\nEpoch 0, Grad Norm: 1.3097822666168213\nEpoch 0, Grad Norm: 1.6579524278640747\nEpoch 0, Grad Norm: 1.5799061059951782\nEpoch 0, Grad Norm: 1.4417977333068848\nEpoch 0, Grad Norm: 1.4767917394638062\nEpoch 0, Grad Norm: 1.2591192722320557\nEpoch 0, Grad Norm: 1.042314052581787\nEpoch 0, Grad Norm: 0.9458178877830505\nEpoch 0, Grad Norm: 1.438741683959961\nEpoch 0, Grad Norm: 1.0993207693099976\nEpoch 0, Grad Norm: 1.289058804512024\nEpoch 0, Grad Norm: 1.035102128982544\nEpoch 0, Grad Norm: 0.9651024341583252\nEpoch 0, Grad Norm: 1.0339524745941162\nEpoch 0, Grad Norm: 1.5356364250183105\nEpoch 0, Grad Norm: 1.4236328601837158\nEpoch 0, Grad Norm: 1.787165641784668\nEpoch 0, Grad Norm: 1.1343035697937012\nEpoch 0, Grad Norm: 1.5017833709716797\nEpoch 0, Grad Norm: 1.625458836555481\nEpoch 0, Grad Norm: 1.4552760124206543\nEpoch 0, Grad Norm: 0.7484363913536072\nEpoch 0, Grad Norm: 1.5362321138381958\nEpoch 0, Grad Norm: 1.0823427438735962\nEpoch 0, Grad Norm: 1.0911179780960083\nEpoch 0, Grad Norm: 1.0664138793945312\nEpoch 0, Grad Norm: 0.9917938709259033\nEpoch 0, Grad Norm: 1.1237841844558716\nEpoch 0, Grad Norm: 1.0939621925354004\nEpoch 0, Grad Norm: 0.8828855156898499\nEpoch 0, Grad Norm: 1.2622718811035156\nEpoch 0, Grad Norm: 1.430379033088684\nEpoch 0, Grad Norm: 1.2712916135787964\nEpoch 0, Grad Norm: 1.5103521347045898\nEpoch 0, Grad Norm: 1.6698346138000488\nEpoch 0, Grad Norm: 1.5814827680587769\nEpoch 0, Grad Norm: 1.4019293785095215\nEpoch 0, Grad Norm: 2.055100917816162\nEpoch 0, Grad Norm: 1.9070415496826172\nEpoch 0, Grad Norm: 1.1885360479354858\nEpoch 0, Grad Norm: 1.411605715751648\nEpoch 0, Grad Norm: 1.2948541641235352\nEpoch 0, Grad Norm: 0.6",
                "lineage": "6201"
            }
        ],
        "63": [],
        "64": [],
        "65": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_data = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    val_data = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n\n    dataset = TensorDataset(train_data, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_data)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.85118,
                "model_info": "",
                "lineage": "6501"
            }
        ],
        "66": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.attention = nn.Linear(128, 1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        attention_weights = torch.sigmoid(self.attention(x.transpose(1, 2)))\n        x = x * attention_weights.transpose(1, 2)\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86173,
                "model_info": "",
                "lineage": "6601"
            }
        ],
        "67": [],
        "68": [],
        "69": [],
        "70": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils.class_weight import compute_class_weight\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    class_weights = compute_class_weight('balanced', classes=np.unique(train_label), y=train_label)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n    criterion = nn.NLLLoss(weight=class_weights)\n    \n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.81162,
                "model_info": "",
                "lineage": "7001"
            }
        ],
        "71": [],
        "72": [],
        "73": [],
        "74": [],
        "75": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86169,
                "model_info": "",
                "lineage": "7501"
            }
        ],
        "76": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.85118,
                "model_info": "",
                "lineage": "7601"
            }
        ],
        "77": [],
        "78": [],
        "79": [],
        "80": [],
        "81": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    cm = confusion_matrix(val_label, y_pred_labels)\n    print(\"Confusion Matrix:\\n\", cm)\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86169,
                "model_info": "Confusion Matrix:\n [[    0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0]\n [23644    31     2     1    28    28     1    11   121    56     2     4\n      0    59    21     0     2     3     1     2     0     0     0     0\n      0]\n [   40 15534    21     1    36   151     7    62   482     6     0    35\n      2    48     2     0     4     0    43     0     0     0     0     0\n      0]\n [    2    18  2348    33   574    50     4    13   202     2     7     7\n      1    11     0     2     0     0     4     1     0     2     1     0\n      0]\n [    2    13   207   110    75     9     0     0    23     0     2     0\n      0    11     0     0     1     0     1     1     0     2     0     0\n      0]\n [   26    22   661    28  2125   305    47   125   363     2     0    26\n      4    46     0     1     0     0     8     0     0     0     0     0\n      0]\n [   55   139    75     3   402  6936    22   235  1071     5     2   286\n      6    52    10     0     6     2    12     0     0     0     0     0\n      0]\n [    1     5     2     0    32    15  3821   721    73     0     0    10\n     18     0     0     1     0     0     0     0     2     0     0     0\n      0]\n [   12    35     8     0    89   130   494  5316   444     2     0    91\n     13     6     1     0     1     0     1     0     1     0     0     0\n      0]\n [  143   293   218     9   343   615    95   658 12180    12     1   360\n      1   124     5     0    23     1    32     3     1     0     0     0\n      0]\n [   42     7     0     1     1     7     3     0    21  1230     0     0\n      0     7     0     0     0     2     0     0     0     0     0     0\n      0]\n [   10     0     3     9     4     0     1     0     2     0    62     0\n      0     5     0     0     0     0     0     0     0     0     0     3\n      0]\n [    8    33    30     1    37   128    19   114   318     1     0  1712\n      0     7     0    ",
                "lineage": "8101"
            }
        ],
        "82": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(256 * 46, 512)\n        self.fc2 = nn.Linear(512, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = self.relu(self.conv5(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86136,
                "model_info": "",
                "lineage": "8201"
            }
        ],
        "83": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86169,
                "model_info": "",
                "lineage": "8301"
            }
        ],
        "84": [],
        "85": [],
        "86": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef extract_temporal_trends(data):\n    return np.array([np.convolve(data[i], np.ones(3)/3, mode='same') for i in range(data.shape[0])])\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_data = extract_temporal_trends(train_data)\n    val_data = extract_temporal_trends(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.8585,
                "model_info": "",
                "lineage": "8601"
            }
        ],
        "87": [],
        "88": [],
        "89": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.gru = nn.GRU(128, 64, batch_first=True)\n        self.fc1 = nn.Linear(64, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.transpose(1, 2)\n        x, _ = self.gru(x)\n        x = x[:, -1, :]\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.81709,
                "model_info": "",
                "lineage": "8901"
            }
        ],
        "90": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    if len(train_data) < 1000:\n        print(\"Warning: Insufficient training data volume. Consider augmenting data.\")\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86201,
                "model_info": "",
                "lineage": "9001"
            }
        ],
        "91": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(256 * 46, 512)\n        self.fc2 = nn.Linear(512, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=512, confidence_threshold=0.5):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss(weight=torch.tensor([1.0] * 24)).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n    model.train()\n    for epoch in range(15):\n        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}'):\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n        confidence = torch.exp(val_outputs).max(dim=1)[0]\n        low_confidence_count = (confidence < confidence_threshold).sum().item()\n        total_count = confidence.size(0)\n        low_confidence_percentage = (low_confidence_count / total_count) * 100\n        print(f'Low-confidence predictions: {low_confidence_percentage:.2f}%')\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.84346,
                "model_info": "Low-confidence predictions: 10.98%",
                "lineage": "9101"
            }
        ],
        "92": [],
        "93": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_trend = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_trend\n    val_data = val_data - seasonal_trend\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86184,
                "model_info": "",
                "lineage": "9301"
            }
        ],
        "94": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1DWithGRU(nn.Module):\n    def __init__(self):\n        super(CNN1DWithGRU, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.gru = nn.GRU(64, 64, batch_first=True)\n        self.fc1 = nn.Linear(64, 256)\n        self.fc2 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = x.permute(0, 2, 1)\n        x, _ = self.gru(x)\n        x = x[:, -1, :]\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1DWithGRU().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.81126,
                "model_info": "",
                "lineage": "9401"
            }
        ],
        "95": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXX.py",
                "accuracy": 0.86584,
                "model_info": "",
                "lineage": "9501"
            }
        ],
        "96": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef custom_loss_function(outputs, labels):\n    class_weights = torch.tensor([1.0] * 24).to(outputs.device)\n    class_weights[0] = 2.0  # Example: Heavier penalty for class 1\n    loss = nn.NLLLoss(weight=class_weights)(outputs, labels)\n    return loss\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = custom_loss_function(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.86604,
                "model_info": "",
                "lineage": "9601"
            }
        ],
        "97": [],
        "98": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import class_weight\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_label), y=train_label)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.81859,
                "model_info": "",
                "lineage": "9801"
            }
        ],
        "99": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.AdaptiveAvgPool1d(46)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.86584,
                "model_info": "",
                "lineage": "9901"
            }
        ],
        "100": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n\n    class_weights = torch.tensor([1.0] * 24).to(device)\n    criterion = nn.NLLLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.86584,
                "model_info": "",
                "lineage": "10001"
            }
        ],
        "101": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1DWithAttention(nn.Module):\n    def __init__(self):\n        super(CNN1DWithAttention, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1DWithAttention().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.86584,
                "model_info": "",
                "lineage": "10101"
            }
        ],
        "102": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.86584,
                "model_info": "",
                "lineage": "10201"
            }
        ],
        "103": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    z_scores = np.abs((val_data - np.mean(val_data, axis=0)) / np.std(val_data, axis=0))\n    outliers_count = np.sum(z_scores > 3)\n    print(f\"Detected outliers count: {outliers_count}\")\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.86584,
                "model_info": "Detected outliers count: 701",
                "lineage": "10301"
            }
        ],
        "104": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.gru = nn.GRU(128, 64, batch_first=True)\n        self.fc1 = nn.Linear(64, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.transpose(1, 2)\n        x, _ = self.gru(x)\n        x = x[:, -1, :]\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.82208,
                "model_info": "",
                "lineage": "10401"
            }
        ],
        "105": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXX.py",
                "accuracy": 0.86715,
                "model_info": "",
                "lineage": "10501"
            }
        ],
        "106": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport time\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    y_pred_labels = []\n    with torch.no_grad():\n        for inputs in DataLoader(val_tensor, batch_size=batch_size):\n            val_outputs = model(inputs)\n            _, y_pred = torch.max(val_outputs, 1)\n            y_pred_labels.extend(y_pred.cpu().numpy().tolist())\n\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXX.py",
                "accuracy": 0.86717,
                "model_info": "",
                "lineage": "10601"
            }
        ],
        "107": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    feature_selector = SelectKBest(f_classif, k=10)\n    feature_selector.fit(train_data, train_label)\n    top_k_indices = feature_selector.get_support(indices=True)\n    top_k_importances = feature_selector.scores_[top_k_indices]\n    \n    for idx, importance in zip(top_k_indices, top_k_importances):\n        print(f\"Feature index: {idx}, Importance: {importance}\")\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXX.py",
                "accuracy": 0.86715,
                "model_info": "Feature index: 6, Importance: 157131.94205912983\nFeature index: 7, Importance: 163037.34381765474\nFeature index: 8, Importance: 183437.92145528493\nFeature index: 9, Importance: 180611.08700534355\nFeature index: 10, Importance: 160652.7079916367\nFeature index: 11, Importance: 143121.6515835849\nFeature index: 23, Importance: 132399.16309989154\nFeature index: 24, Importance: 134182.47256578735\nFeature index: 27, Importance: 131151.53260669523\nFeature index: 28, Importance: 133472.0652613878",
                "lineage": "10701"
            }
        ],
        "108": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.3)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv2(x))\n        x = self.dropout(x)\n        x = self.relu(self.conv3(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=512):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n    model.train()\n    for epoch in range(20):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXX.py",
                "accuracy": 0.86036,
                "model_info": "",
                "lineage": "10801"
            }
        ],
        "109": [],
        "110": [],
        "111": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_data = np.diff(train_data, axis=0, prepend=train_data[0:1])  \n    val_data = np.diff(val_data, axis=0, prepend=val_data[0:1])  \n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXX.py",
                "accuracy": 0.73042,
                "model_info": "",
                "lineage": "11101"
            }
        ],
        "112": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    class_weights = compute_class_weight('balanced', classes=np.unique(train_label), y=train_label)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss(weight=class_weights)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXX.py",
                "accuracy": 0.81683,
                "model_info": "",
                "lineage": "11201"
            }
        ],
        "113": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    \n    neighborhood_size = 3\n    enriched_predictions = []\n    for i in range(len(y_pred_labels)):\n        start = max(0, i - neighborhood_size)\n        end = min(len(y_pred_labels), i + neighborhood_size + 1)\n        neighborhood = y_pred_labels[start:end]\n        most_common = np.bincount(neighborhood).argmax()\n        enriched_predictions.append(most_common)\n\n    return enriched_predictions",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXX.py",
                "accuracy": 0.33718,
                "model_info": "",
                "lineage": "11301"
            }
        ],
        "114": [],
        "115": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import StratifiedKFold\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXX.py",
                "accuracy": 0.88673,
                "model_info": "",
                "lineage": "11501"
            }
        ],
        "116": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXX.py",
                "accuracy": 0.88673,
                "model_info": "",
                "lineage": "11601"
            }
        ],
        "117": [],
        "118": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef custom_loss_function(outputs, labels):\n    class_weights = torch.tensor([1.0] * 24).to(outputs.device)\n    class_weights[0] = 2.0  # Heavily penalize false positives for critical land cover\n    loss = nn.NLLLoss(weight=class_weights)\n    return loss(outputs, labels)\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = custom_loss_function(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88487,
                "model_info": "",
                "lineage": "11801"
            }
        ],
        "119": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv1d(128, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = self.relu(self.conv5(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88563,
                "model_info": "",
                "lineage": "11901"
            }
        ],
        "120": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport warnings\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    if not np.all(np.isfinite(train_data)) or not np.all(np.isfinite(val_data)):\n        warnings.warn(\"Data contains non-finite values.\")\n\n    print(\"Dataset Statistics: \")\n    print(f\"Training data shape: {train_data.shape}, Labels shape: {train_label.shape}\")\n    print(f\"Validation data shape: {val_data.shape}\")\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXXX.py",
                "accuracy": 0.88673,
                "model_info": "Dataset Statistics: \nTraining data shape: (800000, 46), Labels shape: (800000,)\nValidation data shape: (100000, 46)",
                "lineage": "12001"
            }
        ],
        "121": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.attention = nn.Sequential(\n            nn.Conv1d(128, 128, kernel_size=1),\n            nn.ReLU(),\n            nn.Conv1d(128, 128, kernel_size=1),\n            nn.Softmax(dim=-1)\n        )\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        attention_weights = self.attention(x)\n        x = x * attention_weights\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.8832,
                "model_info": "",
                "lineage": "12101"
            }
        ],
        "122": [],
        "123": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1DWithAttention(nn.Module):\n    def __init__(self):\n        super(CNN1DWithAttention, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def attention(self, x):\n        attn_weights = torch.mean(x, dim=1, keepdim=True)\n        return x * attn_weights\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = self.attention(x)\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1DWithAttention().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88089,
                "model_info": "",
                "lineage": "12301"
            }
        ],
        "124": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter1d\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_data = gaussian_filter1d(train_data, sigma=2, axis=0)\n    val_data = gaussian_filter1d(val_data, sigma=2, axis=0)\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.40352,
                "model_info": "",
                "lineage": "12401"
            }
        ],
        "125": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for model_idx in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            epoch_loss = 0\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n                epoch_loss += loss.item()\n            print(f'Model {model_idx + 1}, Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader):.4f}')\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88673,
                "model_info": "Model 1, Epoch 1, Loss: 0.6690\nModel 1, Epoch 2, Loss: 0.4705\nModel 1, Epoch 3, Loss: 0.4214\nModel 1, Epoch 4, Loss: 0.3899\nModel 1, Epoch 5, Loss: 0.3637\nModel 1, Epoch 6, Loss: 0.3412\nModel 1, Epoch 7, Loss: 0.3201\nModel 1, Epoch 8, Loss: 0.3005\nModel 1, Epoch 9, Loss: 0.2817\nModel 1, Epoch 10, Loss: 0.2627\nModel 2, Epoch 1, Loss: 0.6636\nModel 2, Epoch 2, Loss: 0.4699\nModel 2, Epoch 3, Loss: 0.4189\nModel 2, Epoch 4, Loss: 0.3860\nModel 2, Epoch 5, Loss: 0.3596\nModel 2, Epoch 6, Loss: 0.3364\nModel 2, Epoch 7, Loss: 0.3144\nModel 2, Epoch 8, Loss: 0.2943\nModel 2, Epoch 9, Loss: 0.2741\nModel 2, Epoch 10, Loss: 0.2543\nModel 3, Epoch 1, Loss: 0.6493\nModel 3, Epoch 2, Loss: 0.4647\nModel 3, Epoch 3, Loss: 0.4189\nModel 3, Epoch 4, Loss: 0.3870\nModel 3, Epoch 5, Loss: 0.3612\nModel 3, Epoch 6, Loss: 0.3372\nModel 3, Epoch 7, Loss: 0.3162\nModel 3, Epoch 8, Loss: 0.2964\nModel 3, Epoch 9, Loss: 0.2767\nModel 3, Epoch 10, Loss: 0.2578\nModel 4, Epoch 1, Loss: 0.6459\nModel 4, Epoch 2, Loss: 0.4646\nModel 4, Epoch 3, Loss: 0.4160\nModel 4, Epoch 4, Loss: 0.3809\nModel 4, Epoch 5, Loss: 0.3529\nModel 4, Epoch 6, Loss: 0.3270\nModel 4, Epoch 7, Loss: 0.3035\nModel 4, Epoch 8, Loss: 0.2816\nModel 4, Epoch 9, Loss: 0.2586\nModel 4, Epoch 10, Loss: 0.2371\nModel 5, Epoch 1, Loss: 0.6550\nModel 5, Epoch 2, Loss: 0.4659\nModel 5, Epoch 3, Loss: 0.4186\nModel 5, Epoch 4, Loss: 0.3854\nModel 5, Epoch 5, Loss: 0.3589\nModel 5, Epoch 6, Loss: 0.3358\nModel 5, Epoch 7, Loss: 0.3154\nModel 5, Epoch 8, Loss: 0.2946\nModel 5, Epoch 9, Loss: 0.2753\nModel 5, Epoch 10, Loss: 0.2558",
                "lineage": "12501"
            }
        ],
        "126": [],
        "127": [],
        "128": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef custom_loss(outputs, labels, class_weights):\n    return nn.NLLLoss(weight=class_weights)(outputs, labels)\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    class_counts = np.bincount(train_label)\n    class_weights = torch.tensor(1.0 / class_counts, dtype=torch.float32).to(device)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = custom_loss(outputs, labels, class_weights)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.83881,
                "model_info": "",
                "lineage": "12801"
            }
        ],
        "129": [],
        "130": [],
        "131": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_data_diff = np.diff(train_data, axis=0)\n    train_data_diff = np.vstack([train_data_diff[0], train_data_diff])\n    val_data_diff = np.diff(val_data, axis=0)\n    val_data_diff = np.vstack([val_data_diff[0], val_data_diff])\n\n    train_tensor = torch.tensor(train_data_diff, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data_diff, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.75299,
                "model_info": "",
                "lineage": "13101"
            }
        ],
        "132": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    class_weights = compute_class_weight('balanced', classes=np.unique(train_label), y=train_label)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss(weight=class_weights)\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.83943,
                "model_info": "",
                "lineage": "13201"
            }
        ],
        "133": [],
        "134": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.AdaptiveAvgPool1d(46)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88673,
                "model_info": "",
                "lineage": "13401"
            }
        ],
        "135": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.5)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.86873,
                "model_info": "",
                "lineage": "13501"
            }
        ],
        "136": [],
        "137": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88673,
                "model_info": "",
                "lineage": "13701"
            }
        ],
        "138": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom collections import Counter\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    class_counts_before = Counter(train_label)\n    print(f\"Class balance before resampling: {class_counts_before}\")\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    class_counts_after = Counter(y_pred.cpu().numpy())\n    print(f\"Class balance after resampling: {class_counts_after}\")\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88673,
                "model_info": "Class balance before resampling: Counter({0: 190624, 1: 132950, 8: 120814, 5: 74812, 13: 56156, 7: 51650, 6: 38586, 4: 30086, 2: 26079, 11: 19643, 18: 15473, 16: 14757, 9: 10567, 14: 5115, 17: 3468, 3: 3442, 19: 1976, 12: 1650, 10: 847, 15: 466, 22: 353, 21: 258, 20: 147, 23: 81})\nClass balance after resampling: Counter({0: 24205, 1: 16266, 8: 15542, 5: 8992, 13: 7039, 7: 6756, 6: 5169, 4: 3682, 2: 3543, 11: 2003, 16: 1871, 18: 1794, 9: 1280, 14: 580, 17: 414, 3: 269, 19: 220, 12: 187, 10: 92, 22: 28, 20: 22, 21: 21, 15: 14, 23: 11})",
                "lineage": "13801"
            }
        ],
        "139": [],
        "140": [],
        "141": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.87814,
                "model_info": "",
                "lineage": "14101"
            }
        ],
        "142": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom scipy.stats import skew, kurtosis\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    skewness = skew(train_data, axis=0)\n    kurt = kurtosis(train_data, axis=0)\n\n    for i in range(len(skewness)):\n        print(f\"Feature {i}: Skewness = {skewness[i]:.4f}, Kurtosis = {kurt[i]:.4f}\")\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88673,
                "model_info": "Feature 0: Skewness = 0.3398, Kurtosis = -0.2448\nFeature 1: Skewness = 0.2445, Kurtosis = -0.7005\nFeature 2: Skewness = 0.1344, Kurtosis = -0.9536\nFeature 3: Skewness = 0.0814, Kurtosis = -1.0301\nFeature 4: Skewness = -0.0003, Kurtosis = -1.0997\nFeature 5: Skewness = -0.0782, Kurtosis = -1.1576\nFeature 6: Skewness = -0.3496, Kurtosis = -1.4120\nFeature 7: Skewness = -0.3961, Kurtosis = -1.4260\nFeature 8: Skewness = -0.4096, Kurtosis = -1.4450\nFeature 9: Skewness = -0.3911, Kurtosis = -1.4525\nFeature 10: Skewness = -0.3490, Kurtosis = -1.4602\nFeature 11: Skewness = -0.3470, Kurtosis = -1.4738\nFeature 12: Skewness = -0.0141, Kurtosis = -1.1706\nFeature 13: Skewness = 0.2051, Kurtosis = -0.8189\nFeature 14: Skewness = 0.5340, Kurtosis = -0.3484\nFeature 15: Skewness = 0.3228, Kurtosis = -0.6782\nFeature 16: Skewness = 0.1198, Kurtosis = -1.1590\nFeature 17: Skewness = 0.0187, Kurtosis = -1.2863\nFeature 18: Skewness = -0.0232, Kurtosis = -1.3669\nFeature 19: Skewness = 0.0340, Kurtosis = -1.4180\nFeature 20: Skewness = 0.0742, Kurtosis = -1.4711\nFeature 21: Skewness = 0.1599, Kurtosis = -1.4922\nFeature 22: Skewness = 0.1950, Kurtosis = -1.5175\nFeature 23: Skewness = 0.1622, Kurtosis = -1.5244\nFeature 24: Skewness = 0.1753, Kurtosis = -1.5310\nFeature 25: Skewness = 0.1786, Kurtosis = -1.5327\nFeature 26: Skewness = 0.1902, Kurtosis = -1.5384\nFeature 27: Skewness = 0.2075, Kurtosis = -1.5339\nFeature 28: Skewness = 0.2281, Kurtosis = -1.5322\nFeature 29: Skewness = 0.1770, Kurtosis = -1.5220\nFeature 30: Skewness = 0.0330, Kurtosis = -1.4540\nFeature 31: Skewness = -0.0160, Kurtosis = -1.3795\nFeature 32: Skewness = -0.0214, Kurtosis = -1.3194\nFeature 33: Skewness = -0.0165, Kurtosis = -1.2532\nFeature 34: Skewness = -0.3795, Kurtosis = -0.8405\nFeature 35: Skewness = -0.4270, Kurtosis = -0.7458\nFeature 36: Skewness = -0.2925, Kurtosis = -0.8869\nFeature 37: Skewness = -0.1332, Kurtosis = -1.1598\nFeature 38: Skewness = -0.0642, Kurtosis = -1.3642\nFeature 39: Skewness = -0.0195, Kurtosis =",
                "lineage": "14201"
            }
        ],
        "143": [],
        "144": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88647,
                "model_info": "",
                "lineage": "14401"
            }
        ],
        "145": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport time\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(128 * 46, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.softmax(self.fc3(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    start_time = time.time()\n    scaler = StandardScaler()\n    train_data = scaler.fit_transform(train_data)\n    val_data = scaler.transform(val_data)\n\n    seasonal_mean = np.mean(train_data, axis=0)\n    train_data = train_data - seasonal_mean\n    val_data = val_data - seasonal_mean\n\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    models = []\n    for _ in range(5):\n        model = CNN1D().to(device)\n        criterion = nn.NLLLoss()\n        optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n        model.train()\n        for epoch in range(10):\n            for inputs, labels in train_loader:\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n        models.append(model)\n\n    model.eval()\n    val_outputs = []\n    with torch.no_grad():\n        for model in models:\n            outputs = model(val_tensor)\n            val_outputs.append(outputs)\n\n    val_outputs = torch.mean(torch.stack(val_outputs), dim=0)\n    _, y_pred = torch.max(val_outputs, 1)\n\n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    end_time = time.time()\n    print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuXXXXXXXXX.py",
                "accuracy": 0.88673,
                "model_info": "Total training time: 389.47 seconds",
                "lineage": "14501"
            }
        ],
        "146": [],
        "147": []
    },
    "1": {
        "0": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass LSTMModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(LSTMModel, self).__init__()\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        out = self.fc(lstm_out[:, -1, :])\n        return out\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_data_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    train_label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_data_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_data_tensor, train_label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    input_size = 46\n    hidden_size = 128\n    output_size = 24\n    model = LSTMModel(input_size, hidden_size, output_size).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_data_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8251_Recurrent_Neural_Net.py",
                "accuracy": 0.75415,
                "model_info": "",
                "lineage": "satellite_initial_8251_Recurrent_Neural_Net"
            }
        ],
        "1": [],
        "2": [
            {
                "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass CNN1D(nn.Module):\n    def __init__(self):\n        super(CNN1D, self).__init__()\n        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(32 * 46, 128)\n        self.fc2 = nn.Linear(128, 24)\n        self.relu = nn.ReLU()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        x = self.softmax(self.fc2(x))\n        return x\n\ndef tuso_model(train_data, train_label, val_data, device, batch_size=1032):\n    train_tensor = torch.tensor(train_data, dtype=torch.float32).unsqueeze(1).to(device)\n    label_tensor = torch.tensor(train_label, dtype=torch.long).to(device)\n    val_tensor = torch.tensor(val_data, dtype=torch.float32).unsqueeze(1).to(device)\n\n    dataset = TensorDataset(train_tensor, label_tensor)\n    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    model = CNN1D().to(device)\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(10):\n        for inputs, labels in train_loader:\n            noise = torch.normal(0, 0.1, inputs.size()).to(device)\n            inputs_noisy = inputs + noise\n            optimizer.zero_grad()\n            outputs = model(inputs_noisy)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        val_outputs = model(val_tensor)\n        _, y_pred = torch.max(val_outputs, 1)\n    \n    y_pred_labels = y_pred.cpu().numpy().tolist()\n    return y_pred_labels",
                "file": "/projects/zhanglab/users/alistair/tusoml/satellite_initial_8250_1D_Convolutional_NeuX.py",
                "accuracy": 0.74377,
                "model_info": "",
                "lineage": "211"
            }
        ]
    }
}